{"title":"Word2Vec Playground","markdown":{"yaml":{"title":"Word2Vec Playground","description":"My first post - so be nice :P","author":"Bernardo Cruz","date":"June, 7 2023","categories":["nlp","word2vec","food-data","German"],"jupyter":"python3"},"headingText":"Objective","containsRefs":false,"markdown":"\n\nI have crawled Netdoktor for my thesis at [HSLU](https://www.hslu.ch/en/lucerne-school-of-business/degree-programmes/master/applied-information-and-data-science/). The task at hand was to use Netdoktor as an additional source to the main data source to the one provided by [IML](https://www.iml.unibe.ch/). Unfortunatelly, I cannot share this confidential information, because the IML data consists of Multiple Choice Questions for medical students - and yes, I am talking about exam questions :P \n\nHowever, I am therefore forced to create a Word2Vec model using public available data. Therefore, a data set is obtained by web crawling of Netdoktor^[<https://www.netdoktor.ch/>]. Netdoktor is a free internet platform for medical information: It provides information about diseases and symptoms in German and other languages. The website is a part of the German media company Hubert Burda Media^[<https://www.burda.com/en/imprint/>] and was founded by  Dr. Carl Brandt and Rune Bech.\n\n\nLet's start to code :) \n\n# Code\nFirst, the necessary libraries are imported. We use Pandas, Matplotlib and Seaborn and use only the columns `disease`, `description` and `symptoms`.\n\n## Import Libraries and Data\n\n```{python}\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nsns.set(rc={'figure.figsize':(16, 8)})\nplt.rcParams['figure.figsize'] = (16, 8)\n\n\nfrom IPython.display import display, Markdown\n\ndf = (\n    pd.read_pickle(\n        '../data/corpus.pkl', \n        compression = {'method': 'gzip'},\n    )\n    # Select only columns 'disease', 'description', 'symptoms'\n    [['disease','description','symptoms']]\n)\n\n\ndf.head()\n```\n\n```{python}\n#| output: true\n#| echo: false\n\ndisplay(Markdown(f'The data consists of {df.shape[0]} diseases and {df.shape[1]} columns.'))\n```\n\n## Exploration\nFirst we perform some basic text exploration that includes: for each column we calculate the text length and we calculate of the number of tokens. We use the `.str.split()` methods from Pandas without any fancy library in the first step.\n\n```{python}\ndf = (\n    df\n    .assign(\n        len_description = lambda df: df.description.apply(len),\n        len_symptoms = lambda df: df.symptoms.apply(len),\n        tokens_description = lambda df: df.description.str.split(),\n        tokens_symptoms = lambda df: df.symptoms.str.split(),\n        n_tokens_description = lambda df: df.tokens_description.apply(len),\n        n_tokens_symptom = lambda df: df.tokens_symptoms.apply(len),\n    )\n)\n\ndf_melted = (\n    df\n    .melt(\n        id_vars='disease', \n        value_vars = ['len_description','len_symptoms','n_tokens_description','n_tokens_symptom']\n    )\n)\n```\n\n```{python}\n#| label: fig-text_length_description_and_symptoms\n#| fig-cap: Distribution of text length of columns \"description\" and \"symptoms\"\n\nplt.figure()\ng = sns.displot(\n    data = df_melted.query('variable != \"n_tokens_description\" & variable != \"n_tokens_symptom\"'),\n    x = 'value',\n    hue = 'variable',\n    multiple = \"stack\",\n);\nplt.title('Distribution of Number of Tokens of \"symptoms\" and \"description\"')\nplt.xlabel('Text length')\nplt.ylabel('Count of occurance')\nplt.show(g)\n```\n\nThe figure above shows the distribution of the description and symptoms of the Netdoktor dataset. \n\n```{python}\n#| label: fig-text_number_of_tokens_description_and_symptoms\n#| fig-cap: Distribution of number of tokens of columns \"description\" and \"symptoms\"\n\nplt.figure()\ng = sns.displot(\n    data = df_melted.query('variable == \"n_tokens_description\" | variable == \"n_tokens_symptom\"'),\n    x = 'value',\n    hue = 'variable',\n    multiple = \"stack\",\n);\nplt.title('Distribution of Text length')\nplt.xlabel('Text length')\nplt.ylabel('Count of occurance')\nplt.show(g)\n```\n\nOn the left (figure above) shows the distribution of the length of `description` and on the right shows the distribution of the length of `symptoms`. \n\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":true,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"email-obfuscation":"javascript","output-file":"Word2Vec.html"},"language":{"code-summary":"Show the code"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.475","theme":{"light":"flatly","dark":"darkly"},"search":true,"links":[{"icon":"twitter","text":"twitter","href":"https://twitter.com"},{"icon":"github","text":"Github","href":"https://github.com"},{"icon":"linkedin","text":"LinkedIn","href":"https://www.linkedin.com/in/bernardo-freire-barboza-da-cruz/"}],"title":"Word2Vec Playground","description":"My first post - so be nice :P","author":"Bernardo Cruz","date":"June, 7 2023","categories":["nlp","word2vec","food-data","German"],"jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}}}