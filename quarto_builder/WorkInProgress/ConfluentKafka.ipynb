{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: What is Kafka?\n",
    "author: Bernardo Freire\n",
    "date: '2023-10-05'\n",
    "\n",
    "code-fold: true\n",
    "code-line-numbers: true\n",
    "highlight-style: github\n",
    "\n",
    "theme:\n",
    "  light: flatly\n",
    "  dark: darkly\n",
    "\n",
    "toc: true\n",
    "\n",
    "categories:\n",
    "  - Confluent\n",
    "  - Kafka\n",
    "  - Data Engineering\n",
    "  - Data Streaming\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: import\n",
    "#| echo: false\n",
    "#| include: true\n",
    "#|Â code-fold: false\n",
    "\n",
    "## General imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Data manipulation imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Display imports\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "## Plot imports\n",
    "import matplotlib.style as style\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (5,5/2.5)\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_theme()\n",
    "sns.set_context(\n",
    "    \"paper\", \n",
    "    rc={\n",
    "        \"figsize\"       :   plt.rcParams['figure.figsize'],\n",
    "        'font_scale'    :   1.25,\n",
    "    }\n",
    ")\n",
    "height = plt.rcParams['figure.figsize'][0]\n",
    "aspect = plt.rcParams['figure.figsize'][0] / plt.rcParams['figure.figsize'][1] / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "Kafka can refer to two different things: a writer and a software platform. If you think about Franz Kafka, a German-speaking Bohemian novelist and short-story writer based in Prague this article may not be the right fit for you. However, if you are interested in Kafka, the writer, you can read more about him [here](https://en.wikipedia.org/wiki/Franz_Kafka). We are going to talk about Kafka, the software platform.\n",
    "\n",
    "Apache Kafka, is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications^[https://kafka.apache.org/].\n",
    "\n",
    "Why is it important? It is important because it allows you to publish and subscribe to streams of records. In this way, you can store streams of records in a fault-tolerant durable way. It is also fast, scalable, and distributed by design^[https://kafka.apache.org/intro]. In my current work Kafka is used to store data from different sources and then process it.\n",
    "\n",
    "Yes, I am talking about ðŸš‚. A modern train in a complex system consisting of many different components (e.g. bogies; doors; heating and ventilation; air compressors; toilets; entertainment and information system; any many more). The data of this components are processed by control units and send landside to servers where they are stored. \n",
    "\n",
    "In this tutorial we are going to review and reproduce the steps of the [Confluent Kafka Tutorial](https://docs.confluent.io/platform/current/platform-quickstart.html). Confluent is a company founded by the creators of Apache Kafka. It offers a comprehensive platform built around Kafka, facilitating real-time data integration, processing, and streaming. Confluent's solutions serve businesses by making it easier to build and manage event-driven architectures at scale.^[https://developer.confluent.io/]. The tutorial contains the following steps:  \n",
    "\n",
    "1. Install and run Confluent Platform and Apache KafkaÂ®.  \n",
    "1. Generate real-time mock data.  \n",
    "1. Create topics to store your data.  \n",
    "1. Create real-time streams on your data.  \n",
    "1. Query and join streams with SQL statements.  \n",
    "1. Build a view that updates as new events arrive.  \n",
    "1. Visualize the topology of your streaming app.  \n",
    "\n",
    "The aim of reproducing these steps is to get a better understanding of Kafka, its components and how to get started with it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the setup of our environment we use docker. In particular there is a docker-compose file from the Confluent Platform. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
