<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Bernardo Freire">
<meta name="dcterms.date" content="2023-09-10">

<title>Bernardo Cruz - Datacamp Airflow Course</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"headline",
  "consent_type":"express",
  "palette":"dark",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  });
});
</script> 
  


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Bernardo Cruz</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../blog.html">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../cv.html">
 <span class="menu-text">CV</span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#summary" id="toc-summary" class="nav-link active" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#section-1-introduction-to-airflow" id="toc-section-1-introduction-to-airflow" class="nav-link" data-scroll-target="#section-1-introduction-to-airflow">Section 1: Introduction to Airflow</a>
  <ul class="collapse">
  <li><a href="#what-is-a-workflow" id="toc-what-is-a-workflow" class="nav-link" data-scroll-target="#what-is-a-workflow">What is a workflow?</a></li>
  <li><a href="#what-is-airflow" id="toc-what-is-airflow" class="nav-link" data-scroll-target="#what-is-airflow">What is Airflow?</a></li>
  <li><a href="#quick-introduction-to-dags" id="toc-quick-introduction-to-dags" class="nav-link" data-scroll-target="#quick-introduction-to-dags">Quick introduction to DAGs</a></li>
  <li><a href="#dag-code-example" id="toc-dag-code-example" class="nav-link" data-scroll-target="#dag-code-example">DAG code example</a></li>
  <li><a href="#running-a-workflow-in-airflow" id="toc-running-a-workflow-in-airflow" class="nav-link" data-scroll-target="#running-a-workflow-in-airflow">Running a workflow in Airflow</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a>
  <ul class="collapse">
  <li><a href="#exercise-1-running-a-task-in-airflow" id="toc-exercise-1-running-a-task-in-airflow" class="nav-link" data-scroll-target="#exercise-1-running-a-task-in-airflow">Exercise 1: Running a task in Airflow</a></li>
  <li><a href="#exercise-2-examining-airflow-commands" id="toc-exercise-2-examining-airflow-commands" class="nav-link" data-scroll-target="#exercise-2-examining-airflow-commands">Exercise 2: Examining Airflow commands</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-2-airflow-dags" id="toc-section-2-airflow-dags" class="nav-link" data-scroll-target="#section-2-airflow-dags">Section 2: Airflow DAGs</a>
  <ul class="collapse">
  <li><a href="#dag-in-airflow" id="toc-dag-in-airflow" class="nav-link" data-scroll-target="#dag-in-airflow">DAG in Airflow</a></li>
  <li><a href="#define-a-dag" id="toc-define-a-dag" class="nav-link" data-scroll-target="#define-a-dag">Define a DAG</a></li>
  <li><a href="#dags-on-the-command-line" id="toc-dags-on-the-command-line" class="nav-link" data-scroll-target="#dags-on-the-command-line">DAGs on the command line</a></li>
  <li><a href="#command-line-vs-python" id="toc-command-line-vs-python" class="nav-link" data-scroll-target="#command-line-vs-python">Command line vs Python</a></li>
  <li><a href="#exercises-1" id="toc-exercises-1" class="nav-link" data-scroll-target="#exercises-1">Exercises</a>
  <ul class="collapse">
  <li><a href="#exercise-1-defining-a-simple-dag" id="toc-exercise-1-defining-a-simple-dag" class="nav-link" data-scroll-target="#exercise-1-defining-a-simple-dag">Exercise 1: Defining a simple DAG</a></li>
  <li><a href="#exercise-2-working-with-dags-and-the-airflow-shell" id="toc-exercise-2-working-with-dags-and-the-airflow-shell" class="nav-link" data-scroll-target="#exercise-2-working-with-dags-and-the-airflow-shell">Exercise 2: Working with DAGs and the Airflow shell</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-3-airflow-web-interface" id="toc-section-3-airflow-web-interface" class="nav-link" data-scroll-target="#section-3-airflow-web-interface">Section 3: Airflow web interface</a>
  <ul class="collapse">
  <li><a href="#dags-view-dags" id="toc-dags-view-dags" class="nav-link" data-scroll-target="#dags-view-dags">DAGs view DAGs</a></li>
  <li><a href="#dag-detail-view" id="toc-dag-detail-view" class="nav-link" data-scroll-target="#dag-detail-view">DAG detail view</a></li>
  <li><a href="#dag-graph-view" id="toc-dag-graph-view" class="nav-link" data-scroll-target="#dag-graph-view">DAG graph view</a></li>
  <li><a href="#dag-code-view" id="toc-dag-code-view" class="nav-link" data-scroll-target="#dag-code-view">DAG code view</a></li>
  <li><a href="#logs" id="toc-logs" class="nav-link" data-scroll-target="#logs">Logs</a></li>
  <li><a href="#web-ui-vs-command-line" id="toc-web-ui-vs-command-line" class="nav-link" data-scroll-target="#web-ui-vs-command-line">Web UI vs command line</a></li>
  <li><a href="#exercises-2" id="toc-exercises-2" class="nav-link" data-scroll-target="#exercises-2">Exercises</a>
  <ul class="collapse">
  <li><a href="#exercise-1-examining-dags-with-the-airflow-ui" id="toc-exercise-1-examining-dags-with-the-airflow-ui" class="nav-link" data-scroll-target="#exercise-1-examining-dags-with-the-airflow-ui">Exercise 1: Examining DAGs with the Airflow UI</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-4-airflow-operators" id="toc-section-4-airflow-operators" class="nav-link" data-scroll-target="#section-4-airflow-operators">Section 4: Airflow operators</a>
  <ul class="collapse">
  <li><a href="#bashoperator" id="toc-bashoperator" class="nav-link" data-scroll-target="#bashoperator">BashOperator</a></li>
  <li><a href="#bashoperator-examples" id="toc-bashoperator-examples" class="nav-link" data-scroll-target="#bashoperator-examples">BashOperator examples</a></li>
  <li><a href="#operator-gotchas" id="toc-operator-gotchas" class="nav-link" data-scroll-target="#operator-gotchas">Operator gotchas</a></li>
  <li><a href="#exercises-3" id="toc-exercises-3" class="nav-link" data-scroll-target="#exercises-3">Exercises</a>
  <ul class="collapse">
  <li><a href="#exericse-1-defining-a-bashoperator-task" id="toc-exericse-1-defining-a-bashoperator-task" class="nav-link" data-scroll-target="#exericse-1-defining-a-bashoperator-task">Exericse 1: Defining a BashOperator task</a></li>
  <li><a href="#exercise-2-multiple-bashoperators" id="toc-exercise-2-multiple-bashoperators" class="nav-link" data-scroll-target="#exercise-2-multiple-bashoperators">Exercise 2: Multiple BashOperators</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-5-airflow-tasks" id="toc-section-5-airflow-tasks" class="nav-link" data-scroll-target="#section-5-airflow-tasks">Section 5: Airflow tasks</a>
  <ul class="collapse">
  <li><a href="#task-dependencies" id="toc-task-dependencies" class="nav-link" data-scroll-target="#task-dependencies">Task dependencies</a></li>
  <li><a href="#upstream-vs-downstream" id="toc-upstream-vs-downstream" class="nav-link" data-scroll-target="#upstream-vs-downstream">Upstream vs Downstream</a></li>
  <li><a href="#simple-task-dependency" id="toc-simple-task-dependency" class="nav-link" data-scroll-target="#simple-task-dependency">Simple task dependency</a></li>
  <li><a href="#task-dependencies-in-the-airflow-ui" id="toc-task-dependencies-in-the-airflow-ui" class="nav-link" data-scroll-target="#task-dependencies-in-the-airflow-ui">Task dependencies in the Airflow UI</a></li>
  <li><a href="#multiple-dependencies" id="toc-multiple-dependencies" class="nav-link" data-scroll-target="#multiple-dependencies">Multiple dependencies</a></li>
  <li><a href="#exercises-4" id="toc-exercises-4" class="nav-link" data-scroll-target="#exercises-4">Exercises</a>
  <ul class="collapse">
  <li><a href="#exercise-1-define-order-of-bashoperators" id="toc-exercise-1-define-order-of-bashoperators" class="nav-link" data-scroll-target="#exercise-1-define-order-of-bashoperators">Exercise 1: Define order of BashOperators</a></li>
  <li><a href="#exercise-2-determining-the-order-of-tasks" id="toc-exercise-2-determining-the-order-of-tasks" class="nav-link" data-scroll-target="#exercise-2-determining-the-order-of-tasks">Exercise 2: Determining the order of tasks</a></li>
  <li><a href="#exercise-3-troubleshooting-dag-dependencies" id="toc-exercise-3-troubleshooting-dag-dependencies" class="nav-link" data-scroll-target="#exercise-3-troubleshooting-dag-dependencies">Exercise 3: Troubleshooting DAG dependencies</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-6-additional-airflow-operators" id="toc-section-6-additional-airflow-operators" class="nav-link" data-scroll-target="#section-6-additional-airflow-operators">Section 6: Additional Airflow operators</a>
  <ul class="collapse">
  <li><a href="#pythonoperator" id="toc-pythonoperator" class="nav-link" data-scroll-target="#pythonoperator">PythonOperator</a></li>
  <li><a href="#arguments" id="toc-arguments" class="nav-link" data-scroll-target="#arguments">Arguments</a></li>
  <li><a href="#op_kwargs-example" id="toc-op_kwargs-example" class="nav-link" data-scroll-target="#op_kwargs-example">op_kwargs example</a></li>
  <li><a href="#emailoperator" id="toc-emailoperator" class="nav-link" data-scroll-target="#emailoperator">EmailOperator</a></li>
  <li><a href="#emailoperator-example" id="toc-emailoperator-example" class="nav-link" data-scroll-target="#emailoperator-example">EmailOperator example</a></li>
  <li><a href="#exercises-5" id="toc-exercises-5" class="nav-link" data-scroll-target="#exercises-5">Exercises</a>
  <ul class="collapse">
  <li><a href="#exercise-1-using-the-pythonoperator" id="toc-exercise-1-using-the-pythonoperator" class="nav-link" data-scroll-target="#exercise-1-using-the-pythonoperator">Exercise 1: Using the PythonOperator</a></li>
  <li><a href="#exercise-2-more-pythonoperators" id="toc-exercise-2-more-pythonoperators" class="nav-link" data-scroll-target="#exercise-2-more-pythonoperators">Exercise 2: More PythonOperators</a></li>
  <li><a href="#exercise-3-emailoperator-and-dependencies" id="toc-exercise-3-emailoperator-and-dependencies" class="nav-link" data-scroll-target="#exercise-3-emailoperator-and-dependencies">Exercise 3: EmailOperator and dependencies</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-7-airflow-scheduling" id="toc-section-7-airflow-scheduling" class="nav-link" data-scroll-target="#section-7-airflow-scheduling">Section 7: Airflow Scheduling</a>
  <ul class="collapse">
  <li><a href="#dag-runs-view" id="toc-dag-runs-view" class="nav-link" data-scroll-target="#dag-runs-view">DAG Runs view</a></li>
  <li><a href="#schedule-details" id="toc-schedule-details" class="nav-link" data-scroll-target="#schedule-details">Schedule details</a></li>
  <li><a href="#schedule-interval" id="toc-schedule-interval" class="nav-link" data-scroll-target="#schedule-interval">Schedule interval</a></li>
  <li><a href="#cron-syntax" id="toc-cron-syntax" class="nav-link" data-scroll-target="#cron-syntax">cron syntax</a></li>
  <li><a href="#cron-examples" id="toc-cron-examples" class="nav-link" data-scroll-target="#cron-examples">cron examples</a></li>
  <li><a href="#airflow-scheduler-presets" id="toc-airflow-scheduler-presets" class="nav-link" data-scroll-target="#airflow-scheduler-presets">Airflow scheduler presets</a></li>
  <li><a href="#special-presets" id="toc-special-presets" class="nav-link" data-scroll-target="#special-presets">Special presets</a></li>
  <li><a href="#exercises-6" id="toc-exercises-6" class="nav-link" data-scroll-target="#exercises-6">Exercises</a>
  <ul class="collapse">
  <li><a href="#exercise-1-schedule-a-dag-via-python" id="toc-exercise-1-schedule-a-dag-via-python" class="nav-link" data-scroll-target="#exercise-1-schedule-a-dag-via-python">Exercise 1: Schedule a DAG via Python</a></li>
  <li><a href="#exercise-2-deciphering-airflow-schedules" id="toc-exercise-2-deciphering-airflow-schedules" class="nav-link" data-scroll-target="#exercise-2-deciphering-airflow-schedules">Exercise 2: Deciphering Airflow schedules</a></li>
  <li><a href="#exercise-3-troubleshooting-dag-runs" id="toc-exercise-3-troubleshooting-dag-runs" class="nav-link" data-scroll-target="#exercise-3-troubleshooting-dag-runs">Exercise 3: Troubleshooting DAG runs</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-8-airflow-sensors" id="toc-section-8-airflow-sensors" class="nav-link" data-scroll-target="#section-8-airflow-sensors">Section 8: Airflow sensors</a>
  <ul class="collapse">
  <li><a href="#sensor-details" id="toc-sensor-details" class="nav-link" data-scroll-target="#sensor-details">Sensor details</a></li>
  <li><a href="#file-sensor" id="toc-file-sensor" class="nav-link" data-scroll-target="#file-sensor">File sensor</a></li>
  <li><a href="#other-sensors" id="toc-other-sensors" class="nav-link" data-scroll-target="#other-sensors">Other sensors</a></li>
  <li><a href="#why-sensors" id="toc-why-sensors" class="nav-link" data-scroll-target="#why-sensors">Why sensors?</a></li>
  <li><a href="#exercises-7" id="toc-exercises-7" class="nav-link" data-scroll-target="#exercises-7">Exercises</a>
  <ul class="collapse">
  <li><a href="#exercise-1-sensors-vs-operators" id="toc-exercise-1-sensors-vs-operators" class="nav-link" data-scroll-target="#exercise-1-sensors-vs-operators">Exercise 1: Sensors vs operators</a></li>
  <li><a href="#exercise-2-sensory-deprivation" id="toc-exercise-2-sensory-deprivation" class="nav-link" data-scroll-target="#exercise-2-sensory-deprivation">Exercise 2: Sensory deprivation</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-9-airflow-executors" id="toc-section-9-airflow-executors" class="nav-link" data-scroll-target="#section-9-airflow-executors">Section 9: Airflow executors</a>
  <ul class="collapse">
  <li><a href="#what-is-an-executor" id="toc-what-is-an-executor" class="nav-link" data-scroll-target="#what-is-an-executor">What is an executor?</a></li>
  <li><a href="#sequentialexecutor" id="toc-sequentialexecutor" class="nav-link" data-scroll-target="#sequentialexecutor">SequentialExecutor</a></li>
  <li><a href="#localexecutor" id="toc-localexecutor" class="nav-link" data-scroll-target="#localexecutor">LocalExecutor</a></li>
  <li><a href="#celeryexecutor" id="toc-celeryexecutor" class="nav-link" data-scroll-target="#celeryexecutor">CeleryExecutor</a></li>
  <li><a href="#determine-your-executor" id="toc-determine-your-executor" class="nav-link" data-scroll-target="#determine-your-executor">Determine your executor</a></li>
  <li><a href="#determine-your-executor-2" id="toc-determine-your-executor-2" class="nav-link" data-scroll-target="#determine-your-executor-2">Determine your executor #2</a></li>
  <li><a href="#exercises-8" id="toc-exercises-8" class="nav-link" data-scroll-target="#exercises-8">Exercises</a>
  <ul class="collapse">
  <li><a href="#exercise-1-determining-the-executor" id="toc-exercise-1-determining-the-executor" class="nav-link" data-scroll-target="#exercise-1-determining-the-executor">Exercise 1: Determining the executor</a></li>
  <li><a href="#exercise-2-executor-implications" id="toc-exercise-2-executor-implications" class="nav-link" data-scroll-target="#exercise-2-executor-implications">Exercise 2: Executor implications</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-10-debugging-and-troubleshooting-in-airflow" id="toc-section-10-debugging-and-troubleshooting-in-airflow" class="nav-link" data-scroll-target="#section-10-debugging-and-troubleshooting-in-airflow">Section 10: Debugging and troubleshooting in Airflow</a>
  <ul class="collapse">
  <li><a href="#typical-issues" id="toc-typical-issues" class="nav-link" data-scroll-target="#typical-issues">Typical issues…</a></li>
  <li><a href="#dag-wont-run-on-schedule" id="toc-dag-wont-run-on-schedule" class="nav-link" data-scroll-target="#dag-wont-run-on-schedule">DAG won’t run on schedule</a></li>
  <li><a href="#dag-wont-run-on-schedule-1" id="toc-dag-wont-run-on-schedule-1" class="nav-link" data-scroll-target="#dag-wont-run-on-schedule-1">DAG won’t run on schedule</a></li>
  <li><a href="#dag-wont-load" id="toc-dag-wont-load" class="nav-link" data-scroll-target="#dag-wont-load">DAG won’t load</a></li>
  <li><a href="#syntax-errors" id="toc-syntax-errors" class="nav-link" data-scroll-target="#syntax-errors">Syntax errors</a></li>
  <li><a href="#airflow-list_dags" id="toc-airflow-list_dags" class="nav-link" data-scroll-target="#airflow-list_dags">airflow list_dags</a></li>
  <li><a href="#running-the-python-interpreter" id="toc-running-the-python-interpreter" class="nav-link" data-scroll-target="#running-the-python-interpreter">Running the Python interpreter</a></li>
  <li><a href="#exercises-9" id="toc-exercises-9" class="nav-link" data-scroll-target="#exercises-9">Exercises</a>
  <ul class="collapse">
  <li><a href="#exercise-1-dags-in-the-bag" id="toc-exercise-1-dags-in-the-bag" class="nav-link" data-scroll-target="#exercise-1-dags-in-the-bag">Exercise 1: DAGs in the bag</a></li>
  <li><a href="#exercise-2-missing-dag" id="toc-exercise-2-missing-dag" class="nav-link" data-scroll-target="#exercise-2-missing-dag">Exercise 2: Missing DAG</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-11-slas" id="toc-section-11-slas" class="nav-link" data-scroll-target="#section-11-slas">Section 11: SLAs</a>
  <ul class="collapse">
  <li><a href="#sla-misses" id="toc-sla-misses" class="nav-link" data-scroll-target="#sla-misses">SLA Misses</a></li>
  <li><a href="#defining-slas" id="toc-defining-slas" class="nav-link" data-scroll-target="#defining-slas">Defining SLAs</a></li>
  <li><a href="#timedelta-object" id="toc-timedelta-object" class="nav-link" data-scroll-target="#timedelta-object">timedelta object</a></li>
  <li><a href="#general-reporting" id="toc-general-reporting" class="nav-link" data-scroll-target="#general-reporting">General reporting</a></li>
  <li><a href="#exercises-10" id="toc-exercises-10" class="nav-link" data-scroll-target="#exercises-10">Exercises</a>
  <ul class="collapse">
  <li><a href="#exercise-1-defining-an-sla" id="toc-exercise-1-defining-an-sla" class="nav-link" data-scroll-target="#exercise-1-defining-an-sla">Exercise 1: Defining an SLA</a></li>
  <li><a href="#exercise-2-defining-a-task-sla" id="toc-exercise-2-defining-a-task-sla" class="nav-link" data-scroll-target="#exercise-2-defining-a-task-sla">Exercise 2: Defining a task SLA</a></li>
  <li><a href="#exercise-3-generate-and-email-a-report" id="toc-exercise-3-generate-and-email-a-report" class="nav-link" data-scroll-target="#exercise-3-generate-and-email-a-report">Exercise 3: Generate and email a report</a></li>
  <li><a href="#exercise-4-adding-status-emails" id="toc-exercise-4-adding-status-emails" class="nav-link" data-scroll-target="#exercise-4-adding-status-emails">Exercise 4: Adding status emails</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-12-working-with-templates" id="toc-section-12-working-with-templates" class="nav-link" data-scroll-target="#section-12-working-with-templates">Section 12: Working with templates</a>
  <ul class="collapse">
  <li><a href="#what-are-templates" id="toc-what-are-templates" class="nav-link" data-scroll-target="#what-are-templates">What are templates?</a></li>
  <li><a href="#non-templated-bashoperator-example" id="toc-non-templated-bashoperator-example" class="nav-link" data-scroll-target="#non-templated-bashoperator-example">Non-Templated BashOperator example</a></li>
  <li><a href="#templated-bashoperator-example" id="toc-templated-bashoperator-example" class="nav-link" data-scroll-target="#templated-bashoperator-example">Templated BashOperator example</a></li>
  <li><a href="#templated-bashoperator-example-continued" id="toc-templated-bashoperator-example-continued" class="nav-link" data-scroll-target="#templated-bashoperator-example-continued">Templated BashOperator example (continued)</a></li>
  <li><a href="#exercises-11" id="toc-exercises-11" class="nav-link" data-scroll-target="#exercises-11">Exercises</a>
  <ul class="collapse">
  <li><a href="#exercise-1-creating-a-templated-bashoperator" id="toc-exercise-1-creating-a-templated-bashoperator" class="nav-link" data-scroll-target="#exercise-1-creating-a-templated-bashoperator">Exercise 1: Creating a templated BashOperator</a></li>
  <li><a href="#exercise-2-templates-with-multiple-arguments" id="toc-exercise-2-templates-with-multiple-arguments" class="nav-link" data-scroll-target="#exercise-2-templates-with-multiple-arguments">Exercise 2: Templates with multiple arguments</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-13-more-templates" id="toc-section-13-more-templates" class="nav-link" data-scroll-target="#section-13-more-templates">Section 13: More Templates</a>
  <ul class="collapse">
  <li><a href="#more-advanced-template" id="toc-more-advanced-template" class="nav-link" data-scroll-target="#more-advanced-template">More advanced template</a></li>
  <li><a href="#variables" id="toc-variables" class="nav-link" data-scroll-target="#variables">Variables</a></li>
  <li><a href="#macros" id="toc-macros" class="nav-link" data-scroll-target="#macros">Macros</a></li>
  <li><a href="#exercises-12" id="toc-exercises-12" class="nav-link" data-scroll-target="#exercises-12">Exercises</a>
  <ul class="collapse">
  <li><a href="#exercise-1-using-lists-with-templates" id="toc-exercise-1-using-lists-with-templates" class="nav-link" data-scroll-target="#exercise-1-using-lists-with-templates">Exercise 1: Using lists with templates</a></li>
  <li><a href="#exercise-2-understanding-parameter-options" id="toc-exercise-2-understanding-parameter-options" class="nav-link" data-scroll-target="#exercise-2-understanding-parameter-options">Exercise 2: Understanding parameter options</a></li>
  <li><a href="#exercise-3-sending-templated-emails" id="toc-exercise-3-sending-templated-emails" class="nav-link" data-scroll-target="#exercise-3-sending-templated-emails">Exercise 3: Sending templated emails</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-14-branching" id="toc-section-14-branching" class="nav-link" data-scroll-target="#section-14-branching">Section 14: Branching</a>
  <ul class="collapse">
  <li><a href="#branching-example" id="toc-branching-example" class="nav-link" data-scroll-target="#branching-example">Branching example</a></li>
  <li><a href="#branching-example-1" id="toc-branching-example-1" class="nav-link" data-scroll-target="#branching-example-1">Branching example</a></li>
  <li><a href="#branching-graph-view" id="toc-branching-graph-view" class="nav-link" data-scroll-target="#branching-graph-view">Branching graph view</a></li>
  <li><a href="#branching-even-days" id="toc-branching-even-days" class="nav-link" data-scroll-target="#branching-even-days">Branching even days</a></li>
  <li><a href="#branching-odd-days" id="toc-branching-odd-days" class="nav-link" data-scroll-target="#branching-odd-days">Branching odd days</a></li>
  <li><a href="#exercises-13" id="toc-exercises-13" class="nav-link" data-scroll-target="#exercises-13">Exercises</a>
  <ul class="collapse">
  <li><a href="#exercise-1-define-a-branchpythonoperator" id="toc-exercise-1-define-a-branchpythonoperator" class="nav-link" data-scroll-target="#exercise-1-define-a-branchpythonoperator">Exercise 1: Define a BranchPythonOperator</a></li>
  <li><a href="#exercise-2-branch-troubleshooting" id="toc-exercise-2-branch-troubleshooting" class="nav-link" data-scroll-target="#exercise-2-branch-troubleshooting">Exercise 2: Branch troubleshooting</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-15-creating-a-production-pipeline" id="toc-section-15-creating-a-production-pipeline" class="nav-link" data-scroll-target="#section-15-creating-a-production-pipeline">Section 15: Creating a production pipeline</a>
  <ul class="collapse">
  <li><a href="#running-dags-tasks" id="toc-running-dags-tasks" class="nav-link" data-scroll-target="#running-dags-tasks">Running DAGs &amp; Tasks</a></li>
  <li><a href="#operators-reminder" id="toc-operators-reminder" class="nav-link" data-scroll-target="#operators-reminder">Operators reminder</a></li>
  <li><a href="#template-reminders" id="toc-template-reminders" class="nav-link" data-scroll-target="#template-reminders">Template reminders</a></li>
  <li><a href="#template-documentation-example" id="toc-template-documentation-example" class="nav-link" data-scroll-target="#template-documentation-example">Template documentation example</a></li>
  <li><a href="#exercises-14" id="toc-exercises-14" class="nav-link" data-scroll-target="#exercises-14">Exercises</a>
  <ul class="collapse">
  <li><a href="#exercise-1-creating-a-production-pipeline-1" id="toc-exercise-1-creating-a-production-pipeline-1" class="nav-link" data-scroll-target="#exercise-1-creating-a-production-pipeline-1">Exercise 1: Creating a production pipeline #1</a></li>
  <li><a href="#exercise-2-creating-a-production-pipeline-2" id="toc-exercise-2-creating-a-production-pipeline-2" class="nav-link" data-scroll-target="#exercise-2-creating-a-production-pipeline-2">Exercise 2: Creating a production pipeline #2</a></li>
  <li><a href="#exercise-3-adding-the-final-changes-to-your-pipeline" id="toc-exercise-3-adding-the-final-changes-to-your-pipeline" class="nav-link" data-scroll-target="#exercise-3-adding-the-final-changes-to-your-pipeline">Exercise 3: Adding the final changes to your pipeline</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#congratulations" id="toc-congratulations" class="nav-link" data-scroll-target="#congratulations">Congratulations!</a>
  <ul class="collapse">
  <li><a href="#what-weve-learned" id="toc-what-weve-learned" class="nav-link" data-scroll-target="#what-weve-learned">What we’ve learned</a></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps">Next steps</a></li>
  <li><a href="#thank-you" id="toc-thank-you" class="nav-link" data-scroll-target="#thank-you">Thank you!</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Datacamp Airflow Course</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Apache Airflow</div>
    <div class="quarto-category">DAG</div>
    <div class="quarto-category">Python</div>
    <div class="quarto-category">Workflow</div>
    <div class="quarto-category">ETL</div>
    <div class="quarto-category">Data Engineering</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Bernardo Freire </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 10, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="summary" class="level1">
<h1>Summary</h1>
<p>This post is about a Datacamp course on Airflow which I took recently. I share the course and personal notes. I will also share some of the code I wrote for the exercises. This course covers information about: (1) DAGs; (2) Web Interface; (3) Operator; (4) Task; (5) Scheduling; (6) Sensor; (7) Executor; (8) Debugging; (9) SL; (10) Template; (11) Macro; (12) Branching; and (13) Production.</p>
<p>The course is called <a href="https://learn.datacamp.com/courses/introduction-to-airflow-in-python">Introduction to Airflow in Python</a> and is part of the Data Engineering track.</p>
</section>
<section id="section-1-introduction-to-airflow" class="level1">
<h1>Section 1: Introduction to Airflow</h1>
<p>Apache Airflow is a platform to program workflows (general), including the creation, scheduling, and monitoring of said workflows. Airflow can use various tools and languages, but the actual workflow code is written with Python. Airflow implements workflows as DAGs, or Directed Acyclic Graphs. Airflow can be accessed and controlled via code, via the command-line, or via a built-in web interface.</p>
<section id="what-is-a-workflow" class="level2">
<h2 class="anchored" data-anchor-id="what-is-a-workflow">What is a workflow?</h2>
<p>Before we can really discuss Airflow, we need to talk about workflows. A workflow is a set of steps to accomplish a given data engineering task. These can include any given task, such as downloading a file, copying data, filtering information, writing to a database, and so forth. A workflow is of varying levels of complexity. Some workflows may only have 2 or 3 steps, while others consist of hundreds of components.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../tutorials/0X20.png" class="img-fluid figure-img" style="width:40.0%"></p>
<p></p><figcaption class="figure-caption">Workflow example containing 5 steps</figcaption><p></p>
</figure>
</div>
<p>The complexity of a workflow is completely dependent on the needs of the user. We show an example of a possible workflow to the right. It’s important to note that we’re defining a workflow here in a general data engineering sense. This is an informal definition to introduce the concept. As you’ll see later, workflow can have specific meaning within specific tools.</p>
</section>
<section id="what-is-airflow" class="level2">
<h2 class="anchored" data-anchor-id="what-is-airflow">What is Airflow?</h2>
<p>Airflow is a platform to program workflows (general), including the creation, scheduling, and monitoring of said workflows.</p>
<p>Airflow can use various tools and languages, but the actual workflow code is written with Python. Airflow implements workflows as DAGs, or Directed Acyclic Graphs. We’ll discuss exactly what this means throughout this course, but for now think of it as a set of tasks and the dependencies between them. Airflow can be accessed and controlled via code, via the command-line, or via a built-in web interface. We’ll look at all these options later on.</p>
</section>
<section id="quick-introduction-to-dags" class="level2">
<h2 class="anchored" data-anchor-id="quick-introduction-to-dags">Quick introduction to DAGs</h2>
<p>A DAG stands for a Directed Acyclic Graph. In Airflow, this represents the set of tasks that make up your workflow. It consists of the tasks and the dependencies between tasks.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../tutorials/0X48.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Example of DAG consisting of five set of tasks</figcaption><p></p>
</figure>
</div>
<p>DAGs are created with various details about the DAG, including the name, start date, owner, email alerting options, etc.</p>
</section>
<section id="dag-code-example" class="level2">
<h2 class="anchored" data-anchor-id="dag-code-example">DAG code example</h2>
<p>We will go into further detail in the next lesson but a very simple DAG is defined using the following code. A new DAG is created with the dag_id of etl_pipeline and a default_args dictionary containing a start_date for the DAG.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a>etl_dag <span class="op">=</span> DAG(</span>
<span id="cb1-2"><a href="#cb1-2"></a>    dag_id <span class="op">=</span> <span class="st">'etl_pipeline'</span>,    </span>
<span id="cb1-3"><a href="#cb1-3"></a>    default_args <span class="op">=</span> {<span class="st">"start_date"</span>: <span class="st">"2020-01-08"</span>},</span>
<span id="cb1-4"><a href="#cb1-4"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note that within any Python code, this is referred to via the variable identifier, etl_dag, but within the Airflow shell command, you must use the dag_id.</p>
</div>
</div>
</div>
</section>
<section id="running-a-workflow-in-airflow" class="level2">
<h2 class="anchored" data-anchor-id="running-a-workflow-in-airflow">Running a workflow in Airflow</h2>
<p>To get started, let’s look at how to run a component of an Airflow workflow. These components are called tasks and simply represent a portion of the workflow. We’ll go into further detail in later chapters. There are several ways to run a task, but one of the simplest is using the airflow run shell command.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1"></a><span class="ex">airflow</span> run <span class="op">&lt;</span>dag_id<span class="op">&gt;</span> <span class="op">&lt;</span>task_id<span class="op">&gt;</span> <span class="op">&lt;</span>start_date<span class="op">&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Airflow run takes three arguments, a dag_id, a task_id, and a start_date. All of these arguments have specific meaning and will make more sense later in the course. For our example, we’ll use a dag_id of example-etl, a task named download-file, and a start date of 2020-01-10. This task would simply download a specific file, perhaps a daily update from a remote source. Our command as such is airflow run example-etl download-file 2020-01-10. This will then run the specified task within Airflow.</p>
</section>
<section id="exercises" class="level2">
<h2 class="anchored" data-anchor-id="exercises">Exercises</h2>
<p>We’ve looked at Airflow and some of the basic aspects of why you’d use it. We’ve also looked at how to run a task within Airflow from the command-line. Let’s practice what we’ve learned.</p>
<section id="exercise-1-running-a-task-in-airflow" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1-running-a-task-in-airflow">Exercise 1: Running a task in Airflow</h3>
<p>You’ve just started looking at using Airflow within your company and would like to try to run a task within the Airflow platform. You remember that you can use the <code>airflow run</code> command to execute a specific task within a workflow.</p>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note that an error while using <code>airflow run</code> will return <code>airflow.exceptions.AirflowException:</code> on the last line of output.</p>
</div>
</div>
</div>
<p>An Airflow DAG is set up for you with a dag_id of <code>etl_pipeline</code>. The <code>task_id</code> is <code>download_file</code> and the <code>start_date</code> is <code>2020-01-08</code>. All other components needed are defined for you.</p>
<p>Which command would you enter in the console to run the desired task?</p>
<ul class="task-list">
<li><input type="checkbox" disabled="">airflow run dag task 2020-01-08<br>
</li>
<li><input type="checkbox" disabled="">airflow run etl_pipeline task 2020-01-08<br>
</li>
<li><input type="checkbox" disabled="">airflow run etl_pipeline download_file 2020-01-08</li>
</ul>
</section>
<section id="exercise-2-examining-airflow-commands" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-examining-airflow-commands">Exercise 2: Examining Airflow commands</h3>
<p>While researching how to use Airflow, you start to wonder about the airflow command in general. You realize that by simply running airflow you can get further information about various sub-commands that are available.</p>
<p>Which of the following is NOT an Airflow sub-command?</p>
<ul class="task-list">
<li><input type="checkbox" disabled="">list_dags</li>
<li><input type="checkbox" disabled="">edit_dag</li>
<li><input type="checkbox" disabled="">test</li>
<li><input type="checkbox" disabled="">scheduler</li>
</ul>
</section>
</section>
</section>
<section id="section-2-airflow-dags" class="level1">
<h1>Section 2: Airflow DAGs</h1>
<p>Our first question is what is a DAG? Beyond any specific mathematical meaning, a DAG, or Directed Acyclic Graph, has the following attributes:</p>
<ul>
<li><p>It is <strong>Directed</strong>, meaning there is an inherent flow representing the dependencies or order between execution of components. These dependencies (even implicit ones) provide context to the tools on how to order the running of components.</p></li>
<li><p>A DAG is also <strong>Acyclic</strong> - it does not loop or repeat. This does not imply that the entire DAG cannot be rerun, only that the individual components are executed once per run.</p></li>
<li><p>In this case, a <strong>Graph</strong> represents the components and the relationships (or dependencies) between them.</p></li>
</ul>
<p>The term DAG is found often in data engineering, not just in Airflow but also Apache Spark, Luigi, and others<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p><img src="../imgs/0X78.png" class="img-fluid"></p>
<section id="dag-in-airflow" class="level2">
<h2 class="anchored" data-anchor-id="dag-in-airflow">DAG in Airflow</h2>
<p>As we’re working with Airflow, let’s look at its implementation of the DAG concept. Within Airflow, DAGs are written in Python, but can use components written in other languages or technologies. This means we’ll define the DAG using Python, but we could include Bash scripts, other executables, Spark jobs, and so on. Airflow DAGs are made up of components to be executed, such as operators, sensors, etc. Airflow typically refers to these as tasks. We’ll cover these in much greater depth later on, but for now think of a task as a thing within the workflow that needs to be done. Airflow DAGs contain dependencies that are defined, either explicitly or implicitly. These dependencies define the execution order so Airflow knows which components should be run at what point within the workflow. For example, you would likely want to copy a file to a server prior to trying to import it to a database.</p>
</section>
<section id="define-a-dag" class="level2">
<h2 class="anchored" data-anchor-id="define-a-dag">Define a DAG</h2>
<p>Let’s look at defining a simple DAG within Airflow. When defining the DAG in Python, you must first import the DAG object from airflow dot models. Once imported, we create a default arguments dictionary consisting of attributes that will be applied to the components of our DAG. These attributes are optional, but provide a lot of power to define the runtime behavior of Airflow.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb3-3"><a href="#cb3-3"></a></span>
<span id="cb3-4"><a href="#cb3-4"></a>default_arguments <span class="op">=</span> {</span>
<span id="cb3-5"><a href="#cb3-5"></a>    <span class="st">'owner'</span>         : <span class="st">'jdoe'</span>,</span>
<span id="cb3-6"><a href="#cb3-6"></a>    <span class="st">'email'</span>         : <span class="st">'jdoe@email.com'</span>, </span>
<span id="cb3-7"><a href="#cb3-7"></a>    <span class="st">'start_date'</span>    : datetime(<span class="dv">2020</span>, <span class="dv">1</span>, <span class="dv">20</span>)</span>
<span id="cb3-8"><a href="#cb3-8"></a>}</span>
<span id="cb3-9"><a href="#cb3-9"></a></span>
<span id="cb3-10"><a href="#cb3-10"></a>etl_dag <span class="op">=</span> DAG(</span>
<span id="cb3-11"><a href="#cb3-11"></a>    <span class="st">'etl_workflow'</span>, </span>
<span id="cb3-12"><a href="#cb3-12"></a>    default_args <span class="op">=</span> default_arguments</span>
<span id="cb3-13"><a href="#cb3-13"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Here we define the owner name as jdoe, an email address for any alerting, and specify the start date of the DAG. The start date represents the earliest datetime that a DAG could be run. Finally, we define our DAG object with the first argument using a name for the DAG, etl underscore workflow, and assign the default arguments dictionary to the default underscore args argument. There are many other optional configurations we will use later on.</p>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note that the entire DAG is assigned to a variable called etl underscore dag. This will be used later when defining the components of the DAG, but the variable name etl underscore dag does not actually appear in the Airflow interfaces. Note, DAG is case sensitive in Python code.</p>
</div>
</div>
</div>
</section>
<section id="dags-on-the-command-line" class="level2">
<h2 class="anchored" data-anchor-id="dags-on-the-command-line">DAGs on the command line</h2>
<p>When working with DAGs (and Airflow in general), you’ll often want to use the airflow command line tool. The airflow command line program contains many subcommands that handle various aspects of running Airflow. You’ve used a couple of these already in previous exercises. Use the</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1"></a><span class="ex">airflow</span> <span class="at">-h</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>command for help and descriptions of the subcommands. Many of these subcommands are related to DAGs. You can use the</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1"></a><span class="ex">airflow</span> list_dags</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>option to see all recognized DAGs in an installation. When in doubt, try a few different commands to find the information you’re looking for.</p>
</section>
<section id="command-line-vs-python" class="level2">
<h2 class="anchored" data-anchor-id="command-line-vs-python">Command line vs Python</h2>
<p>You may be wondering when to use the Airflow command line tool vs writing Python.</p>
<table class="table">
<caption>Command line vs Python</caption>
<thead>
<tr class="header">
<th>Command line</th>
<th>Python</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Start Airflow processes</td>
<td>Create a DAGs</td>
</tr>
<tr class="even">
<td>Manually run DAGs / tasks</td>
<td>Edit individual prop of DAG</td>
</tr>
<tr class="odd">
<td>Review logging information</td>
<td></td>
</tr>
</tbody>
</table>
<p>In general, the airflow command line program is used to start Airflow processes (ie, webserver or scheduler), manually run DAGs or tasks, and review logging information. Python code itself is usually used in the creation and editing of a DAG, not to mention the actual data processing code itself.</p>
</section>
<section id="exercises-1" class="level2">
<h2 class="anchored" data-anchor-id="exercises-1">Exercises</h2>
<section id="exercise-1-defining-a-simple-dag" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1-defining-a-simple-dag">Exercise 1: Defining a simple DAG</h3>
<p>You’ve spent some time reviewing the Airflow components and are interested in testing out your own workflows. To start you decide to define the default arguments and create a DAG object for your workflow.</p>
<p>The DateTime object has been imported for you.</p>
<ol type="1">
<li>Import the Airflow DAG object. Note that it is case-sensitive.</li>
<li>Define the default_args dictionary with a key owner and a value of ‘dsmith’. Add a start_date of January 14, 2020 to default_args using the value 1 for the month of January. Add a retries count of 2 to default_args.</li>
<li>Instantiate the DAG object to a variable called etl_dag with a DAG named example_etl. Add the default_args dictionary to the appropriate argument.</li>
</ol>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="co"># Import the DAG object</span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb6-4"><a href="#cb6-4"></a></span>
<span id="cb6-5"><a href="#cb6-5"></a><span class="co"># Define the default_args dictionary</span></span>
<span id="cb6-6"><a href="#cb6-6"></a>default_args <span class="op">=</span> {</span>
<span id="cb6-7"><a href="#cb6-7"></a>  <span class="st">'owner'</span>       : <span class="st">'dsmith'</span>,</span>
<span id="cb6-8"><a href="#cb6-8"></a>  <span class="st">'start_date'</span>  : datetime(<span class="dv">2020</span>, <span class="dv">1</span>, <span class="dv">14</span>),</span>
<span id="cb6-9"><a href="#cb6-9"></a>  <span class="st">'retries'</span>     : <span class="dv">2</span></span>
<span id="cb6-10"><a href="#cb6-10"></a>}</span>
<span id="cb6-11"><a href="#cb6-11"></a></span>
<span id="cb6-12"><a href="#cb6-12"></a><span class="co"># Instantiate the DAG object</span></span>
<span id="cb6-13"><a href="#cb6-13"></a>etl_dag <span class="op">=</span> DAG(</span>
<span id="cb6-14"><a href="#cb6-14"></a>    <span class="st">'example_etl'</span>, </span>
<span id="cb6-15"><a href="#cb6-15"></a>    default_args<span class="op">=</span>default_args</span>
<span id="cb6-16"><a href="#cb6-16"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="exercise-2-working-with-dags-and-the-airflow-shell" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-working-with-dags-and-the-airflow-shell">Exercise 2: Working with DAGs and the Airflow shell</h3>
<p>While working with Airflow, sometimes it can be tricky to remember what DAGs are defined and what they do. You want to gain some further knowledge of the Airflow shell command so you’d like to see what options are available.</p>
<p>Multiple DAGs are already defined for you. How many DAGs are present in the Airflow system from the command-line?</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="op">!</span>airflow dags <span class="bu">list</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Please confirm database upgrade (or wait 4 seconds to skip it). Are you sure? [y/N]
No data found</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="section-3-airflow-web-interface" class="level1">
<h1>Section 3: Airflow web interface</h1>
<p>The Airflow web UI is made up of several primary page groups useful in developing and administering workflows on the Airflow platform.</p>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note that for this course, we’ll only be focusing on a few pages but it’s helpful to click around the various options and get familiar with what’s available. The DAGs view of the Airflow UI is the page we’ll spend most of our time.</p>
</div>
</div>
</div>
<section id="dags-view-dags" class="level2">
<h2 class="anchored" data-anchor-id="dags-view-dags">DAGs view DAGs</h2>
<p>It provides a quick status of the number of DAGs / workflows available.</p>
<p><img src="../imgs/0X117.png" class="img-fluid"></p>
<p><img src="../imgs/0X121.png" class="img-fluid"></p>
<p>It shows us the schedule for the DAG (in date or cron format).</p>
<p><img src="../imgs/0X125.png" class="img-fluid"></p>
<p>We can see the owner of the DAG.</p>
<p><img src="../imgs/0X129.png" class="img-fluid"></p>
<p>which of the most recent tasks have run,</p>
<p><img src="../imgs/0X133.png" class="img-fluid"></p>
<p>when the last run started,</p>
<p><img src="../imgs/0X137.png" class="img-fluid"></p>
<p>and the last three DAG runs.</p>
<p><img src="../imgs/0X141.png" class="img-fluid"></p>
<p>The links area on the right gives us quick access to many of the DAG specific views.</p>
<p><img src="../imgs/0X145.png" class="img-fluid"></p>
<p>Don’t worry about those for now - instead we’ll click on the “example_dag” link which takes us to our DAG detail page.</p>
<p><img src="../imgs/0X149.png" class="img-fluid"></p>
</section>
<section id="dag-detail-view" class="level2">
<h2 class="anchored" data-anchor-id="dag-detail-view">DAG detail view</h2>
<p>The DAG detail view gives us specific access to information about the DAG itself, including several views of information (Graph, Tree, and Code) illustrating the tasks and dependencies in the code. We also get access to the Task duration, task tries, timings, a Gantt chart view, and specific details about the DAG. We have the ability to trigger the DAG (to start), refresh our view, and delete the DAG if we desire. The detail view defaults to the Tree view, showing the specific named tasks, which operators are in use, and any dependencies between tasks. The circles in front of the words represent the state of the task / DAG. In the case of our specific DAG, we see that we have one task called generate_random_number.</p>
<p><img src="../imgs/0X153.png" class="img-fluid"></p>
</section>
<section id="dag-graph-view" class="level2">
<h2 class="anchored" data-anchor-id="dag-graph-view">DAG graph view</h2>
<p>The DAG graph view arranges the tasks and dependencies in a chart format - this provides another view into the flow of the DAG. You can see the operators in use and the state of the tasks at any point in time. The tree and graph view provide different information depending on what you’d like to know. Try moving between them when examining a DAG to obtain further details. For this view we again see that we have a task called generate_random_number. We can also see that it is of the type BashOperator in the middle left of the image.</p>
<p><img src="../imgs/0X159.png" class="img-fluid"></p>
</section>
<section id="dag-code-view" class="level2">
<h2 class="anchored" data-anchor-id="dag-code-view">DAG code view</h2>
<p>The DAG code view does exactly as it sounds - it provides a copy of the Python code that makes up the DAG. The code view provides easy access to exactly what defines the DAG without clicking in various portions of the UI. As you use Airflow, you’ll determine which tools work best for you. It is worth noting that the code view is read-only. Any DAG code changes must be done via the actual DAG script. In this view, we can finally see the code making up the generate_random_number task and that it runs the bash command echo $RANDOM.</p>
<p><img src="../imgs/0X165.png" class="img-fluid"></p>
</section>
<section id="logs" class="level2">
<h2 class="anchored" data-anchor-id="logs">Logs</h2>
<p>The Logs page, under the Browse menu option, provides troubleshooting and audit ability while using Airflow. This includes items such as starting the Airflow webserver, viewing the graph or tree nodes, creating users, starting DAGs, etc. When using Airflow, look at the logs often to become more familiar with the types of information included, and also what happens behind the scenes of an Airflow install.</p>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note that you’ll often refer to the Event type present on the Logs view when searching (such as graph, tree, cli scheduler).</p>
</div>
</div>
</div>
<p><img src="../imgs/0X171.png" class="img-fluid"></p>
</section>
<section id="web-ui-vs-command-line" class="level2">
<h2 class="anchored" data-anchor-id="web-ui-vs-command-line">Web UI vs command line</h2>
<p>In most circumstances, you can choose between using the Airflow web UI or the command line tool based on your preference. The web UI is often easier to use overall. The command line tool may be simpler to access depending on settings (via SSH, etc.)</p>
</section>
<section id="exercises-2" class="level2">
<h2 class="anchored" data-anchor-id="exercises-2">Exercises</h2>
<section id="exercise-1-examining-dags-with-the-airflow-ui" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1-examining-dags-with-the-airflow-ui">Exercise 1: Examining DAGs with the Airflow UI</h3>
<p>You’ve become familiar with the basics of an Airflow DAG and the basics of interacting with Airflow on the command-line. Your boss would like you to show others on your team how to examine any available DAGs. In this instance, she would like to know which operator is NOT in use with the DAG called update_state, as your team is trying to verify the components used in production workflows.</p>
<p>Remember that the Airflow UI allows various methods to view the state of DAGs. The Tree View lists the tasks and any ordering between them in a tree structure, with the ability to compress / expand the nodes. The Graph View shows any tasks and their dependencies in a graph structure, along with the ability to access further details about task runs. The Code view provides full access to the Python code that makes up the DAG.</p>
<p>Remember to select the operator NOT used in this DAG.</p>
<p><img src="../imgs/Exercise_3_1.png" class="img-fluid"></p>
<ul class="task-list">
<li><input type="checkbox" disabled="">BashOperator</li>
<li><input type="checkbox" disabled="">PythonOperator</li>
<li><input type="checkbox" disabled="">JdbcOperator</li>
<li><input type="checkbox" disabled="">SimpleHttpOperator</li>
</ul>
</section>
</section>
</section>
<section id="section-4-airflow-operators" class="level1">
<h1>Section 4: Airflow operators</h1>
<p>Airflow operators represent a single task in a workflow. This can be any type of task from running a command, sending an email, running a Python script, and so on. Typically Airflow operators run independently - meaning that all resources needed to complete the task are contained within the operator. Generally, Airflow operators do not share information between each other. This is to simplify workflows and allow Airflow to run the tasks in the most efficient manner. It is possible to share information between operators, but the details of how are beyond this course. Airflow contains many various operators to perform different tasks. For example, the DummyOperator can be used to represent a task for troubleshooting or a task that has not yet been implemented.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="co">## Arguments to be passed to each operator</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>default_args <span class="op">=</span> {</span>
<span id="cb9-3"><a href="#cb9-3"></a>    <span class="st">'owner'</span>         : <span class="st">'jdoe'</span>,</span>
<span id="cb9-4"><a href="#cb9-4"></a>    <span class="st">'email'</span>         : <span class="st">'jdoe@email.com'</span>,</span>
<span id="cb9-5"><a href="#cb9-5"></a>    <span class="st">'start_date'</span>    : datetime(<span class="dv">2020</span>, <span class="dv">1</span>, <span class="dv">20</span>)</span>
<span id="cb9-6"><a href="#cb9-6"></a>}</span>
<span id="cb9-7"><a href="#cb9-7"></a></span>
<span id="cb9-8"><a href="#cb9-8"></a><span class="co">## Create a DAG object</span></span>
<span id="cb9-9"><a href="#cb9-9"></a>dag <span class="op">=</span> DAG(</span>
<span id="cb9-10"><a href="#cb9-10"></a>    <span class="st">'example_dag'</span>, </span>
<span id="cb9-11"><a href="#cb9-11"></a>    default_args <span class="op">=</span> default_args</span>
<span id="cb9-12"><a href="#cb9-12"></a>)</span>
<span id="cb9-13"><a href="#cb9-13"></a></span>
<span id="cb9-14"><a href="#cb9-14"></a><span class="co">## Define tasks/operators</span></span>
<span id="cb9-15"><a href="#cb9-15"></a>DummyOperator(</span>
<span id="cb9-16"><a href="#cb9-16"></a>    task_id <span class="op">=</span> <span class="st">'dummy_task'</span>, </span>
<span id="cb9-17"><a href="#cb9-17"></a>    dag <span class="op">=</span> dag</span>
<span id="cb9-18"><a href="#cb9-18"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We are focusing on the BashOperator for this lesson but will look at the PythonOperator and several others later on.</p>
<section id="bashoperator" class="level2">
<h2 class="anchored" data-anchor-id="bashoperator">BashOperator</h2>
<p>The BashOperator executes a given Bash command or script.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a>BashOperator(    </span>
<span id="cb10-2"><a href="#cb10-2"></a>    task_id<span class="op">=</span><span class="st">'bash_example'</span>,    </span>
<span id="cb10-3"><a href="#cb10-3"></a>    bash_command<span class="op">=</span><span class="st">'echo "Example!"'</span>,    </span>
<span id="cb10-4"><a href="#cb10-4"></a>    dag<span class="op">=</span>ml_dag</span>
<span id="cb10-5"><a href="#cb10-5"></a>)</span>
<span id="cb10-6"><a href="#cb10-6"></a></span>
<span id="cb10-7"><a href="#cb10-7"></a>BashOperator(    </span>
<span id="cb10-8"><a href="#cb10-8"></a>    task_id<span class="op">=</span><span class="st">'bash_script_example'</span>,    </span>
<span id="cb10-9"><a href="#cb10-9"></a>    bash_command<span class="op">=</span><span class="st">'runcleanup.sh'</span>,    </span>
<span id="cb10-10"><a href="#cb10-10"></a>    dag<span class="op">=</span>ml_dag</span>
<span id="cb10-11"><a href="#cb10-11"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This command can be pretty much anything Bash is capable of that would make sense in a given workflow. The BashOperator requires three arguments: the task id which is the name that shows up in the UI, the bash command (the raw command or script), and the dag it belongs to. The BashOperator runs the command in a temporary directory that gets automatically cleaned up afterwards. It is possible to specify environment variables for the bash command to try to replicate running the task as you would on a local system. If you’re unfamiliar with environment variables, these are run-time settings interpreted by the shell. It provides flexibility while running scripts in a generalized way. The first example runs a bash command to echo Example exclamation mark to standard out. The second example uses a predefined bash script for its command, runcleanup.sh.</p>
</section>
<section id="bashoperator-examples" class="level2">
<h2 class="anchored" data-anchor-id="bashoperator-examples">BashOperator examples</h2>
<p>Before using the BashOperator, it must be imported:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="im">from</span> airflow.operators.bash_operator <span class="im">import</span> BashOperator</span>
<span id="cb11-2"><a href="#cb11-2"></a></span>
<span id="cb11-3"><a href="#cb11-3"></a>...</span>
<span id="cb11-4"><a href="#cb11-4"></a></span>
<span id="cb11-5"><a href="#cb11-5"></a>example_task <span class="op">=</span> BashOperator(</span>
<span id="cb11-6"><a href="#cb11-6"></a>    task_id <span class="op">=</span> <span class="st">'example'</span>,</span>
<span id="cb11-7"><a href="#cb11-7"></a>    bash_command <span class="op">=</span> <span class="st">'echo 1'</span>,</span>
<span id="cb11-8"><a href="#cb11-8"></a>    dag <span class="op">=</span> dag,</span>
<span id="cb11-9"><a href="#cb11-9"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The first example creates a BashOperator that takes a task_id, runs the bash command “echo 1”, and assigns the operator to the dag. ::: {.callout-caution collapse=“true” apperance=‘simple’} Note that we’ve previously defined the dag in an earlier exercise. :::</p>
<p>The second example is a BashOperator to run a quick data cleaning operation using cat and awk.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>bash_task <span class="op">=</span> BashOperator(</span>
<span id="cb12-2"><a href="#cb12-2"></a>    task_id <span class="op">=</span> <span class="st">'clean_addresses'</span>,</span>
<span id="cb12-3"><a href="#cb12-3"></a>    bash_command <span class="op">=</span> <span class="st">'cat addresses.txt | awk "NF==10" &gt; cleaned.txt'</span>,</span>
<span id="cb12-4"><a href="#cb12-4"></a>    dag <span class="op">=</span> dag,</span>
<span id="cb12-5"><a href="#cb12-5"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Don’t worry if you don’t understand exactly what this is doing. This is a common scenario when running workflows - you may not know exactly what a command does, but you can still run it in a reliable way.</p>
</section>
<section id="operator-gotchas" class="level2">
<h2 class="anchored" data-anchor-id="operator-gotchas">Operator gotchas</h2>
<p>There are some general gotchas when using Operators. The biggest is that individual operators are not guaranteed to run in the same location or environment. This means that just because one operator ran in a given directory with a certain setup, it does not necessarily mean that the next operator will have access to that same information. If this is required, you must explicitly set it up. You may need to set up environment variables, especially for the BashOperator.</p>
<blockquote class="blockquote">
<p>For example, it’s common in bash to use the tilde character to represent a home directory. This is not defined by default in Airflow.</p>
</blockquote>
<blockquote class="blockquote">
<p>Another example of an environment variable could be AWS credentials, database connectivity details, or other information specific to running a script.</p>
</blockquote>
<p>Finally, it can also be tricky to run tasks with any form of elevated privilege. This means that any access to resources must be setup for the specific user running the tasks. If you’re uncertain what elevated privileges are, think of running a command as root or the administrator on a system.</p>
</section>
<section id="exercises-3" class="level2">
<h2 class="anchored" data-anchor-id="exercises-3">Exercises</h2>
<section id="exericse-1-defining-a-bashoperator-task" class="level3">
<h3 class="anchored" data-anchor-id="exericse-1-defining-a-bashoperator-task">Exericse 1: Defining a BashOperator task</h3>
<p>The BashOperator allows you to specify any given Shell command or script and add it to an Airflow workflow. This can be a great start to implementing Airflow in your environment.</p>
<p>As such, you’ve been running some scripts manually to clean data (using a script called cleanup.sh) prior to delivery to your colleagues in the Data Analytics group. As you get more of these tasks assigned, you’ve realized it’s becoming difficult to keep up with running everything manually, much less dealing with errors or retries. You’d like to implement a simple script as an Airflow operator.</p>
<p>The Airflow DAG analytics_dag is already defined for you and has the appropriate configurations in place.</p>
<ul>
<li>Import the BashOperator object.</li>
<li>Define a BashOperator called cleanup with the task_id of cleanup_task.</li>
<li>Use the command cleanup.sh.</li>
<li>Add the operator to the DAG.</li>
</ul>
<div class="sourceCode" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a><span class="co"># Import the BashOperator</span></span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="im">from</span> airflow.operators.bash_operator <span class="im">import</span> BashOperator</span>
<span id="cb13-3"><a href="#cb13-3"></a></span>
<span id="cb13-4"><a href="#cb13-4"></a><span class="co"># Define the BashOperator </span></span>
<span id="cb13-5"><a href="#cb13-5"></a>cleanup <span class="op">=</span> BashOperator(</span>
<span id="cb13-6"><a href="#cb13-6"></a>    task_id<span class="op">=</span><span class="st">'cleanup_task'</span>,</span>
<span id="cb13-7"><a href="#cb13-7"></a>    <span class="co"># Define the bash_command</span></span>
<span id="cb13-8"><a href="#cb13-8"></a>    bash_command<span class="op">=</span><span class="st">'cleanup.sh'</span>,</span>
<span id="cb13-9"><a href="#cb13-9"></a>    <span class="co"># Add the task to the dag</span></span>
<span id="cb13-10"><a href="#cb13-10"></a>    dag<span class="op">=</span>analytics_dag,</span>
<span id="cb13-11"><a href="#cb13-11"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-2-multiple-bashoperators" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-multiple-bashoperators">Exercise 2: Multiple BashOperators</h3>
<p>Airflow DAGs can contain many operators, each performing their defined tasks.</p>
<p>You’ve successfully implemented one of your scripts as an Airflow task and have decided to continue migrating your individual scripts to a full Airflow DAG. You now want to add more components to the workflow. In addition to the cleanup.sh used in the previous exercise you have two more scripts, consolidate_data.sh and push_data.sh. These further process your data and copy to its final location.</p>
<p>The DAG analytics_dag is available as before, and your cleanup task is still defined. The BashOperator is already imported.</p>
<ul>
<li>Define a <code>BashOperator</code> called <code>consolidate</code>, to run <code>consolidate_data.sh</code> with a <code>task_id</code> of <code>consolidate_task</code>.</li>
<li>Add a final <code>BashOperator</code> called <code>push_data</code>, running <code>push_data.sh</code> and a <code>task_id</code> of <code>pushdata_task</code>.</li>
</ul>
<div class="sourceCode" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a><span class="co"># Define a second operator to run the `consolidate_data.sh` script</span></span>
<span id="cb14-2"><a href="#cb14-2"></a>consolidate <span class="op">=</span> BashOperator(</span>
<span id="cb14-3"><a href="#cb14-3"></a>    task_id <span class="op">=</span> <span class="st">'consolidate_task'</span>,</span>
<span id="cb14-4"><a href="#cb14-4"></a>    bash_command <span class="op">=</span> <span class="st">'consolidate_data.sh'</span>,</span>
<span id="cb14-5"><a href="#cb14-5"></a>    dag <span class="op">=</span> analytics_dag,</span>
<span id="cb14-6"><a href="#cb14-6"></a>)</span>
<span id="cb14-7"><a href="#cb14-7"></a></span>
<span id="cb14-8"><a href="#cb14-8"></a><span class="co"># Define a final operator to execute the `push_data.sh` script</span></span>
<span id="cb14-9"><a href="#cb14-9"></a>push_data <span class="op">=</span> BashOperator(</span>
<span id="cb14-10"><a href="#cb14-10"></a>    task_id <span class="op">=</span> <span class="st">'pushdata_task'</span>,</span>
<span id="cb14-11"><a href="#cb14-11"></a>    bash_command <span class="op">=</span> <span class="st">'push_data.sh'</span>,</span>
<span id="cb14-12"><a href="#cb14-12"></a>    dag <span class="op">=</span> analytics_dag,</span>
<span id="cb14-13"><a href="#cb14-13"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="section-5-airflow-tasks" class="level1">
<h1>Section 5: Airflow tasks</h1>
<p>Within Airflow, tasks are instantiated operators. It basically is a shortcut to refer to a given operator within a workflow. Tasks are usually assigned to a variable within Python code. Using a previous example, we assign the BashOperator to the variable example underscore task.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a>example_task <span class="op">=</span> BashOperator(</span>
<span id="cb15-2"><a href="#cb15-2"></a>    task_id <span class="op">=</span> <span class="st">'bash_example'</span>,</span>
<span id="cb15-3"><a href="#cb15-3"></a>    bash_command <span class="op">=</span> <span class="st">'echo "Example!"'</span>,</span>
<span id="cb15-4"><a href="#cb15-4"></a>    dag <span class="op">=</span> dag,</span>
<span id="cb15-5"><a href="#cb15-5"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note that within the Airflow tools, this task is referred by its task id, not the variable name.</p>
</div>
</div>
</div>
<section id="task-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="task-dependencies">Task dependencies</h2>
<p>Task dependencies in Airflow define an order of task completion. While not required, task dependencies are usually present. If task dependencies are not defined, task execution is handled by Airflow itself with no guarantees of order. Task dependencies are referred to as upstream or downstream tasks. An upstream task means that it must complete prior to any downstream tasks. Since Airflow 1.8, task dependencies are defined using the bitshift operators. The upstream operator is two greater-than symbols. The downstream operator is two less-than symbols.</p>
</section>
<section id="upstream-vs-downstream" class="level2">
<h2 class="anchored" data-anchor-id="upstream-vs-downstream">Upstream vs Downstream</h2>
<p>It’s easy to get confused on when to use an upstream or downstream operator. The simplest analogy is that upstream means before and downstream means after. This means that any upstream tasks would need to complete prior to any downstream ones.</p>
</section>
<section id="simple-task-dependency" class="level2">
<h2 class="anchored" data-anchor-id="simple-task-dependency">Simple task dependency</h2>
<p>Let’s look at a simple example involving two bash operators. We define our first task, and assign it to the variable task1. We then create our second task and assign it to the variable task2. Once each operator is defined and assigned to a variable, we can define the task order using the bitshift operators. In this case, we want to run task1 before task2.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a><span class="co"># Define the tasks</span></span>
<span id="cb16-2"><a href="#cb16-2"></a>task1 <span class="op">=</span> BashOperator(</span>
<span id="cb16-3"><a href="#cb16-3"></a>    task_id<span class="op">=</span><span class="st">'first_task'</span>,                     </span>
<span id="cb16-4"><a href="#cb16-4"></a>    bash_command<span class="op">=</span><span class="st">'echo 1'</span>,                     </span>
<span id="cb16-5"><a href="#cb16-5"></a>    dag<span class="op">=</span>example_dag)</span>
<span id="cb16-6"><a href="#cb16-6"></a></span>
<span id="cb16-7"><a href="#cb16-7"></a>task2 <span class="op">=</span> BashOperator(</span>
<span id="cb16-8"><a href="#cb16-8"></a>    task_id<span class="op">=</span><span class="st">'second_task'</span>,                     </span>
<span id="cb16-9"><a href="#cb16-9"></a>    bash_command<span class="op">=</span><span class="st">'echo 2'</span>,                     </span>
<span id="cb16-10"><a href="#cb16-10"></a>    dag<span class="op">=</span>example_dag)</span>
<span id="cb16-11"><a href="#cb16-11"></a>    </span>
<span id="cb16-12"><a href="#cb16-12"></a><span class="co"># Set first_task to run before second_task</span></span>
<span id="cb16-13"><a href="#cb16-13"></a>task1 <span class="op">&gt;&gt;</span> task2   <span class="co"># or task2 &lt;&lt; task1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The most readable method for this is using the upstream operator, two greater-than symbols, as task1 upstream operator task2. ::: {.callout-caution collapse=“true” apperance=‘simple’} Note that you could also define this in reverse using the downstream operator to accomplish the same thing. In this case, it’d be task2 two less-than symbols task1. :::</p>
</section>
<section id="task-dependencies-in-the-airflow-ui" class="level2">
<h2 class="anchored" data-anchor-id="task-dependencies-in-the-airflow-ui">Task dependencies in the Airflow UI</h2>
<p>Let’s take a look at what the Airflow UI shows for tasks and their dependencies. In this case, we’re looking at the graph view within the Airflow web interface. ::: {.callout-caution collapse=“true” apperance=‘simple’} Note that in the task area, our two tasks, first_task and second_task, are both present, but there is no order to the task execution. This is the DAG prior to setting the task dependency using the bitshift operator. :::</p>
<p><img src="../imgs/0X75.png" class="img-fluid"></p>
<p>Now let’s look again at the view with a defined order via the bitshift operators. The view is similar but we can see the order of tasks indicated by the directed arrow between first underscore task and second underscore task.</p>
<p><img src="../imgs/0X79.png" class="img-fluid"></p>
</section>
<section id="multiple-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="multiple-dependencies">Multiple dependencies</h2>
<p>Dependencies can be as complex as required to define the workflow to your needs. We can chain a dependency, in this case setting task1 upstream of task2 upstream of task3 upstream of task4. The Airflow graph view shows a dependency view indicating this order.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a>task1 <span class="op">&gt;&gt;</span> task2 <span class="op">&gt;&gt;</span> task3 <span class="op">&gt;&gt;</span> task4</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="../imgs/0X85.png" class="img-fluid"></p>
<p>You can also mix upstream and downstream bitshift operators in the same workflow. If we define task1 upstream of task2 then downstream of task3, we get a configuration different than what we might expect.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a>task1 <span class="op">&gt;&gt;</span> task2 <span class="op">&lt;&lt;</span> task3</span>
<span id="cb18-2"><a href="#cb18-2"></a></span>
<span id="cb18-3"><a href="#cb18-3"></a><span class="co">##&nbsp;or</span></span>
<span id="cb18-4"><a href="#cb18-4"></a>task1 <span class="op">&gt;&gt;</span> task2</span>
<span id="cb18-5"><a href="#cb18-5"></a>task3 <span class="op">&gt;&gt;</span> task2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="../imgs/1X86.png" class="img-fluid"></p>
<p>This creates a DAG where first underscore task and third underscore task must finish prior to second underscore task. This means we could define the same dependency graph on two lines, in a possibly clearer form. task1 upstream of task2. task3 upstream of task2.</p>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note that because we don’t require it, either task1 or task3 could run first depending on Airflow’s scheduling.</p>
</div>
</div>
</div>
</section>
<section id="exercises-4" class="level2">
<h2 class="anchored" data-anchor-id="exercises-4">Exercises</h2>
<section id="exercise-1-define-order-of-bashoperators" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1-define-order-of-bashoperators">Exercise 1: Define order of BashOperators</h3>
<p>Now that you’ve learned about the bitshift operators, it’s time to modify your workflow to include a pull step and to include the task ordering. You have three currently defined components, cleanup, consolidate, and push_data.</p>
<p>The DAG analytics_dag is available as before and the BashOperator is already imported.</p>
<ul>
<li>Define a BashOperator called pull_sales with a bash command of <code>wget https://salestracking/latestinfo?json</code>.</li>
<li>Set the pull_sales operator to run before the cleanup task.</li>
<li>Configure consolidate to run next, using the downstream operator.</li>
<li>Set push_data to run last using either bitshift operator.</li>
</ul>
<div class="sourceCode" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a><span class="co"># Define a new pull_sales task</span></span>
<span id="cb19-2"><a href="#cb19-2"></a>pull_sales <span class="op">=</span> BashOperator(</span>
<span id="cb19-3"><a href="#cb19-3"></a>    task_id <span class="op">=</span> <span class="st">'pullsales_task'</span>,</span>
<span id="cb19-4"><a href="#cb19-4"></a>     bash_command <span class="op">=</span> <span class="st">'wget https://salestracking/latestinfo?json'</span>,</span>
<span id="cb19-5"><a href="#cb19-5"></a>    dag <span class="op">=</span> analytics_dag,</span>
<span id="cb19-6"><a href="#cb19-6"></a>)</span>
<span id="cb19-7"><a href="#cb19-7"></a></span>
<span id="cb19-8"><a href="#cb19-8"></a><span class="co"># Set pull_sales to run prior to cleanup</span></span>
<span id="cb19-9"><a href="#cb19-9"></a>pull_sales <span class="op">&gt;&gt;</span> cleanup</span>
<span id="cb19-10"><a href="#cb19-10"></a></span>
<span id="cb19-11"><a href="#cb19-11"></a><span class="co"># Configure consolidate to run after cleanup</span></span>
<span id="cb19-12"><a href="#cb19-12"></a>cleanup <span class="op">&gt;&gt;</span> consolidate</span>
<span id="cb19-13"><a href="#cb19-13"></a></span>
<span id="cb19-14"><a href="#cb19-14"></a><span class="co"># Set push_data to run last</span></span>
<span id="cb19-15"><a href="#cb19-15"></a>consolidate <span class="op">&gt;&gt;</span> push_data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-2-determining-the-order-of-tasks" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-determining-the-order-of-tasks">Exercise 2: Determining the order of tasks</h3>
<p>While looking through a colleague’s workflow definition, you’re trying to decipher exactly in which order the defined tasks run. The code in question shows the following:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a>pull_data <span class="op">&lt;&lt;</span> initialize_process</span>
<span id="cb20-2"><a href="#cb20-2"></a>pull_data <span class="op">&gt;&gt;</span> clean <span class="op">&gt;&gt;</span> run_ml_pipeline</span>
<span id="cb20-3"><a href="#cb20-3"></a>generate_reports <span class="op">&lt;&lt;</span> run_ml_pipeline</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Order the tasks in the sequence defined by the bitshift code, with the first task to run on top and the last task to run on the bottom.</p>
<ol type="1">
<li>initialize_process</li>
<li>pull_data</li>
<li>clean</li>
<li>run_ml_pipeline</li>
<li>generate_reports</li>
</ol>
</section>
<section id="exercise-3-troubleshooting-dag-dependencies" class="level3">
<h3 class="anchored" data-anchor-id="exercise-3-troubleshooting-dag-dependencies">Exercise 3: Troubleshooting DAG dependencies</h3>
<p>You’ve created a DAG with intended dependencies based on your workflow but for some reason Airflow won’t load / execute the DAG. Try using the terminal to:</p>
<ul>
<li>List the DAGs.</li>
<li>Decipher the error message.</li>
<li>Use cat workspace/dags/codependent.py to view the Python code.</li>
<li>Determine which of the following lines should be removed from the Python code. You may want to consider the last line of the file.</li>
</ul>
<p><img src="../imgs/Exercise_5_3.png" class="img-fluid"></p>
<ul class="task-list">
<li><input type="checkbox" disabled="">task1 &gt;&gt; task2</li>
<li><input type="checkbox" disabled="">task2 &gt;&gt; task3</li>
<li><input type="checkbox" disabled="">task3 &gt;&gt; task1</li>
</ul>
</section>
</section>
</section>
<section id="section-6-additional-airflow-operators" class="level1">
<h1>Section 6: Additional Airflow operators</h1>
<section id="pythonoperator" class="level2">
<h2 class="anchored" data-anchor-id="pythonoperator">PythonOperator</h2>
<p>The PythonOperator is similar to the BashOperator, except that it runs a Python function or callable method. Much like the BashOperator, it requires a taskid, a dag entry, and most importantly a python underscore callable argument set to the name of the function in question. You can also pass arguments or keyword style arguments into the Python callable as needed. Our first example shows a simple printme function that writes a message to the task logs.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a><span class="im">from</span> airflow.operators.python_operator <span class="im">import</span> PythonOperator</span>
<span id="cb21-2"><a href="#cb21-2"></a></span>
<span id="cb21-3"><a href="#cb21-3"></a><span class="kw">def</span> printme():</span>
<span id="cb21-4"><a href="#cb21-4"></a>    <span class="bu">print</span>(<span class="st">"This goes in the logs!"</span>)</span>
<span id="cb21-5"><a href="#cb21-5"></a></span>
<span id="cb21-6"><a href="#cb21-6"></a>python_task <span class="op">=</span> PythonOperator(</span>
<span id="cb21-7"><a href="#cb21-7"></a>    task_id <span class="op">=</span> <span class="st">'simple_print'</span>,</span>
<span id="cb21-8"><a href="#cb21-8"></a>    python_callable <span class="op">=</span> printme,</span>
<span id="cb21-9"><a href="#cb21-9"></a>    dag <span class="op">=</span> example_dag,</span>
<span id="cb21-10"><a href="#cb21-10"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We must first import the PythonOperator from the airflow dot operators dot python underscore operator library. Afterwards, we create our function printme, which will write a quick log message when run. Once defined, we create the PythonOperator instance called python underscore task and add the necessary arguments.</p>
</section>
<section id="arguments" class="level2">
<h2 class="anchored" data-anchor-id="arguments">Arguments</h2>
<p>The PythonOperator supports adding arguments to a given task. This allows you to pass arguments that can then be passed to the Python function assigned to python callable. The PythonOperator supports both positional and keyword style arguments as options to the task. &gt; For this course, we’ll focus on using keyword arguments only for the sake of clarity.</p>
<p>To implement keyword arguments with the PythonOperator, we define an argument on the task called <code>op_kwargs</code>. This is a dictionary consisting of the named arguments for the intended Python function.</p>
</section>
<section id="op_kwargs-example" class="level2">
<h2 class="anchored" data-anchor-id="op_kwargs-example">op_kwargs example</h2>
<p>Let’s create a new function called sleep, which takes a length of time argument. It uses this argument to call the time dot sleep method. Once defined, we create a new task called sleep underscore task, with the taskid, dag, and python callable arguments added as before. This time we’ll add our op underscore kwargs dictionary with the length of time variable and the value of 5.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a><span class="co">## Function to sleep (needs argument to be passed)</span></span>
<span id="cb22-2"><a href="#cb22-2"></a><span class="kw">def</span> sleep(length_of_time):</span>
<span id="cb22-3"><a href="#cb22-3"></a>    time.sleep(length_of_time)</span>
<span id="cb22-4"><a href="#cb22-4"></a></span>
<span id="cb22-5"><a href="#cb22-5"></a>sleep_task <span class="op">=</span> PythonOperator(</span>
<span id="cb22-6"><a href="#cb22-6"></a>    task_id <span class="op">=</span> <span class="st">'sleep'</span>,</span>
<span id="cb22-7"><a href="#cb22-7"></a>    python_callable <span class="op">=</span> sleep,</span>
<span id="cb22-8"><a href="#cb22-8"></a>    <span class="co">## Pass argument to callable</span></span>
<span id="cb22-9"><a href="#cb22-9"></a>    op_kwargs <span class="op">=</span> {<span class="st">'length_of_time'</span>: <span class="dv">5</span>},</span>
<span id="cb22-10"><a href="#cb22-10"></a>    dag <span class="op">=</span> example_dag,</span>
<span id="cb22-11"><a href="#cb22-11"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note that the dictionary key must match the name of the function argument. If the dictionary contains an unexpected key, it will be passed to the Python function and typically cause an unexpected keyword argument error.</p>
</div>
</div>
</div>
</section>
<section id="emailoperator" class="level2">
<h2 class="anchored" data-anchor-id="emailoperator">EmailOperator</h2>
<p>There are many other operators available within the Airflow ecosystem. The primary operators are in the <code>airflow.operators</code> or <code>airflow.contrib.operators</code> libraries.</p>
<p>Another useful operator is the EmailOperator, which as expected sends an email from within an Airflow task. It can contain the typical components of an email, including HTML content and attachments. ::: {.callout-caution collapse=“true” apperance=‘simple’} Note that the Airflow system must be configured with the email server details to successfully send a message. :::</p>
</section>
<section id="emailoperator-example" class="level2">
<h2 class="anchored" data-anchor-id="emailoperator-example">EmailOperator example</h2>
<p>A quick example for sending an email would be sending a generated sales report upon completion of a workflow. We first must import the EmailOperator object from airflow dot operators dot email underscore operator. We can then create our EmailOperator instance with the task id, the to, subject, and content fields and a list of any files to attach.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a><span class="im">from</span> airflow.operators.email_operator <span class="im">import</span> EmailOperator</span>
<span id="cb23-2"><a href="#cb23-2"></a></span>
<span id="cb23-3"><a href="#cb23-3"></a>email_task <span class="op">=</span> EmailOperator(</span>
<span id="cb23-4"><a href="#cb23-4"></a>    task_id <span class="op">=</span> <span class="st">'email_sales_report'</span>,</span>
<span id="cb23-5"><a href="#cb23-5"></a>    to <span class="op">=</span> <span class="st">'sales_manager@example.com'</span>,</span>
<span id="cb23-6"><a href="#cb23-6"></a>    subject <span class="op">=</span> <span class="st">'Automated Sales Report'</span>,</span>
<span id="cb23-7"><a href="#cb23-7"></a>    html_content <span class="op">=</span> <span class="st">'Attached is the latest sales report'</span>,</span>
<span id="cb23-8"><a href="#cb23-8"></a>    files <span class="op">=</span> <span class="st">'latest_sales.xlsx'</span>,</span>
<span id="cb23-9"><a href="#cb23-9"></a>    dag <span class="op">=</span> example_dag</span>
<span id="cb23-10"><a href="#cb23-10"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>::: {.callout-caution collapse=“true” apperance=‘simple’} Note that in this case we assume the file latest underscore sales dot xlsx was previously generated - later in the course we’ll see how to verify that first. Finally we add it to our dag as usual.</p>
</section>
<section id="exercises-5" class="level2">
<h2 class="anchored" data-anchor-id="exercises-5">Exercises</h2>
<section id="exercise-1-using-the-pythonoperator" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1-using-the-pythonoperator">Exercise 1: Using the PythonOperator</h3>
<p>You’ve implemented several Airflow tasks using the BashOperator but realize that a couple of specific tasks would be better implemented using Python. You’ll implement a task to download and save a file to the system within Airflow.</p>
<p>The requests library is imported for you, and the DAG process_sales_dag is already defined.</p>
<ul>
<li>Define a function called pull_file with two parameters, URL and savepath.</li>
<li>Use the print() function and Python f-strings to write a message to the logs.</li>
<li>Import the necessary object to use the Python Operator.</li>
<li>Create a new task assigned to the variable pull_file_task, with the id pull_file.</li>
<li>Add the pull_file(URL, savepath) function defined previously to the operator.</li>
<li>Define the arguments needed for the task.</li>
</ul>
<div class="sourceCode" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a><span class="co"># Define the method</span></span>
<span id="cb24-2"><a href="#cb24-2"></a><span class="kw">def</span> pull_file(URL, savepath):</span>
<span id="cb24-3"><a href="#cb24-3"></a>    r <span class="op">=</span> requests.get(URL)</span>
<span id="cb24-4"><a href="#cb24-4"></a>    <span class="cf">with</span> <span class="bu">open</span>(savepath, <span class="st">'wb'</span>) <span class="im">as</span> f:</span>
<span id="cb24-5"><a href="#cb24-5"></a>        f.write(r.content)    </span>
<span id="cb24-6"><a href="#cb24-6"></a>    <span class="co"># Use the print method for logging</span></span>
<span id="cb24-7"><a href="#cb24-7"></a>    <span class="bu">print</span>(<span class="ss">f"File pulled from </span><span class="sc">{</span>URL<span class="sc">}</span><span class="ss"> and saved to </span><span class="sc">{</span>savepath<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb24-8"><a href="#cb24-8"></a></span>
<span id="cb24-9"><a href="#cb24-9"></a><span class="co">## Import the PythonOperator</span></span>
<span id="cb24-10"><a href="#cb24-10"></a><span class="im">from</span> airflow.operators.python_operator <span class="im">import</span> PythonOperator</span>
<span id="cb24-11"><a href="#cb24-11"></a></span>
<span id="cb24-12"><a href="#cb24-12"></a><span class="co"># Create the task</span></span>
<span id="cb24-13"><a href="#cb24-13"></a>pull_file_task <span class="op">=</span> PythonOperator(</span>
<span id="cb24-14"><a href="#cb24-14"></a>    task_id <span class="op">=</span> <span class="st">'pull_file'</span>,</span>
<span id="cb24-15"><a href="#cb24-15"></a>    <span class="co"># Add the callable</span></span>
<span id="cb24-16"><a href="#cb24-16"></a>    python_callable <span class="op">=</span> pull_file,</span>
<span id="cb24-17"><a href="#cb24-17"></a>    <span class="co"># Define the arguments</span></span>
<span id="cb24-18"><a href="#cb24-18"></a>    op_kwargs <span class="op">=</span> {</span>
<span id="cb24-19"><a href="#cb24-19"></a>        <span class="st">'URL'</span> : <span class="st">'http://dataserver/sales.json'</span>, </span>
<span id="cb24-20"><a href="#cb24-20"></a>        <span class="st">'savepath'</span> : <span class="st">'latestsales.json'</span>,</span>
<span id="cb24-21"><a href="#cb24-21"></a>    },</span>
<span id="cb24-22"><a href="#cb24-22"></a>    dag <span class="op">=</span> process_sales_dag</span>
<span id="cb24-23"><a href="#cb24-23"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-2-more-pythonoperators" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-more-pythonoperators">Exercise 2: More PythonOperators</h3>
<p>To continue implementing your workflow, you need to add another step to parse and save the changes of the downloaded file. The DAG <code>process_sales_dag</code> is defined and has the <code>pull_file</code> task already added. In this case, the Python function is already defined for you, <code>parse_file(inputfile, outputfile)</code>.</p>
<p>Note that often when implementing Airflow tasks, you won’t necessarily understand the individual steps given to you. As long as you understand how to wrap the steps within Airflow’s structure, you’ll be able to implement a desired workflow.</p>
<ul>
<li>Define the Python task to the variable parse_file_task with the id parse_file.</li>
<li>Add the parse_file(inputfile, outputfile) to the Operator.</li>
<li>Define the arguments to pass to the callable.</li>
<li>Add the task to the DAG.</li>
</ul>
<div class="sourceCode" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a><span class="co"># Add another Python task</span></span>
<span id="cb25-2"><a href="#cb25-2"></a>parse_file_task <span class="op">=</span> PythonOperator(</span>
<span id="cb25-3"><a href="#cb25-3"></a>    task_id<span class="op">=</span><span class="st">'parse_file'</span>,</span>
<span id="cb25-4"><a href="#cb25-4"></a>    <span class="co"># Set the function to call</span></span>
<span id="cb25-5"><a href="#cb25-5"></a>    python_callable <span class="op">=</span> parse_file,</span>
<span id="cb25-6"><a href="#cb25-6"></a>    <span class="co"># Add the arguments</span></span>
<span id="cb25-7"><a href="#cb25-7"></a>    op_kwargs <span class="op">=</span> {</span>
<span id="cb25-8"><a href="#cb25-8"></a>        <span class="st">'inputfile'</span>:<span class="st">'latestsales.json'</span>, </span>
<span id="cb25-9"><a href="#cb25-9"></a>        <span class="st">'outputfile'</span>:<span class="st">'parsedfile.json'</span>,</span>
<span id="cb25-10"><a href="#cb25-10"></a>    },</span>
<span id="cb25-11"><a href="#cb25-11"></a>    <span class="co"># Add the DAG</span></span>
<span id="cb25-12"><a href="#cb25-12"></a>    dag <span class="op">=</span> process_sales_dag,</span>
<span id="cb25-13"><a href="#cb25-13"></a>)</span>
<span id="cb25-14"><a href="#cb25-14"></a>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-3-emailoperator-and-dependencies" class="level3">
<h3 class="anchored" data-anchor-id="exercise-3-emailoperator-and-dependencies">Exercise 3: EmailOperator and dependencies</h3>
<p>Now that you’ve successfully defined the PythonOperators for your workflow, your manager would like to receive a copy of the parsed JSON file via email when the workflow completes. The previous tasks are still defined and the DAG <code>process_sales_dag</code> is configured.</p>
<ul>
<li>Import the class to send emails.</li>
<li>Define the Operator and add the appropriate arguments (to, subject, files).</li>
<li>Set the task order so the tasks run sequentially (Pull the file, parse the file, then email your manager).</li>
</ul>
<div class="sourceCode" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a><span class="co"># Import the Operator</span></span>
<span id="cb26-2"><a href="#cb26-2"></a><span class="im">from</span> airflow.operators.email_operator <span class="im">import</span> EmailOperator</span>
<span id="cb26-3"><a href="#cb26-3"></a></span>
<span id="cb26-4"><a href="#cb26-4"></a><span class="co"># Define the task</span></span>
<span id="cb26-5"><a href="#cb26-5"></a>email_manager_task <span class="op">=</span> EmailOperator(</span>
<span id="cb26-6"><a href="#cb26-6"></a>    task_id <span class="op">=</span> <span class="st">'email_manager'</span>,</span>
<span id="cb26-7"><a href="#cb26-7"></a>    to <span class="op">=</span> <span class="st">'manager@datacamp.com'</span>,</span>
<span id="cb26-8"><a href="#cb26-8"></a>    subject <span class="op">=</span> <span class="st">'Latest sales JSON'</span>,</span>
<span id="cb26-9"><a href="#cb26-9"></a>    html_content <span class="op">=</span> <span class="st">'Attached is the latest sales JSON file as requested.'</span>,</span>
<span id="cb26-10"><a href="#cb26-10"></a>    files <span class="op">=</span> <span class="st">'parsedfile.json'</span>,</span>
<span id="cb26-11"><a href="#cb26-11"></a>    dag <span class="op">=</span> process_sales_dag,</span>
<span id="cb26-12"><a href="#cb26-12"></a>)</span>
<span id="cb26-13"><a href="#cb26-13"></a></span>
<span id="cb26-14"><a href="#cb26-14"></a><span class="co"># Set the order of tasks</span></span>
<span id="cb26-15"><a href="#cb26-15"></a>pull_file_task <span class="op">&gt;&gt;</span> parse_file_task <span class="op">&gt;&gt;</span> email_manager_task</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="section-7-airflow-scheduling" class="level1">
<h1>Section 7: Airflow Scheduling</h1>
<p>When referring to scheduling in Airflow<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, we must first discuss a DAG run. This is an instance of a workflow at a given point in time. For example, it could be the currently running instance, or it could be one run last Tuesday at 3pm. A DAG can be run manually, or via the schedule interval parameter passed when the DAG is defined. Each DAG run maintains a state for itself and the tasks within. The DAGs can the following states:</p>
<div class="callout-note callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>running</p>
</div>
</div>
</div>
<div class="callout-important callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>failed</p>
</div>
</div>
</div>
<div class="callout-tip callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>success</p>
</div>
</div>
</div>
<p>The individual tasks can have these states or others as well (ie, queued, skipped).</p>
<section id="dag-runs-view" class="level2">
<h2 class="anchored" data-anchor-id="dag-runs-view">DAG Runs view</h2>
<p>Within the Airflow UI, you can view all DAG runs under the Browse: DAG Runs menu option. This provides the assorted details about any DAGs that have run within the current Airflow instance.</p>
<p><img src="../imgs/chapter2/0X146.png" class="img-fluid"></p>
<p>As mentioned, you can view the state of a DAG run within this page, illustrating whether the DAG run was successful or not.</p>
<p><img src="../imgs/chapter2/0X150.png" class="img-fluid"></p>
</section>
<section id="schedule-details" class="level2">
<h2 class="anchored" data-anchor-id="schedule-details">Schedule details</h2>
<p>When scheduling a DAG, there are many attributes to consider depending on your scheduling needs. The <code>start_date</code> value specifies the first time the DAG could be scheduled. This is typically defined with a Python datetime object. The <code>end_date</code> represents the last possible time to schedule the DAG. <code>max_tries</code> represents how many times to retry before fully failing the DAG run. The <code>schedule_interval</code> represents how often to schedule the DAG for execution. There are many nuances to this which we’ll cover in a moment.</p>
</section>
<section id="schedule-interval" class="level2">
<h2 class="anchored" data-anchor-id="schedule-interval">Schedule interval</h2>
<p>The schedule interval represents how often to schedule the DAG runs. The scheduling occurs between the start date and the potential end date. Note that this is not when the DAGs will absolutely run, but rather a minimum and maximum value of when they could be scheduled. The schedule interval can be defined by a couple methods - with a cron style syntax or via built-in presets.</p>
</section>
<section id="cron-syntax" class="level2">
<h2 class="anchored" data-anchor-id="cron-syntax">cron syntax</h2>
<p>The cron syntax<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> is the same as the format for scheduling jobs using the Unix cron tool.</p>
<p><img src="../imgs/chapter2/0X164.png" class="img-fluid"></p>
<p>It consists of five fields separated by a space, starting with the minute value (0 through 59), the hour (0 through 23), the day of the month (1 through 31), the month (1 through 12), and the day of week (0 through 6). An asterisk in any of the fields represents running for every interval (for example, an asterisk in the minute field means run every minute) A list of values can be given on a field via comma separated values.</p>
</section>
<section id="cron-examples" class="level2">
<h2 class="anchored" data-anchor-id="cron-examples">cron examples</h2>
<div class="sourceCode" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a><span class="dv">0</span> <span class="dv">12</span> <span class="op">*</span> <span class="op">*</span> <span class="op">*</span>              <span class="co"># Run daily at Noon (12:00)</span></span>
<span id="cb27-2"><a href="#cb27-2"></a><span class="op">*</span> <span class="op">*</span> <span class="dv">25</span> <span class="dv">2</span> <span class="op">*</span>              <span class="co"># Run once per minute, but only on February 25th</span></span>
<span id="cb27-3"><a href="#cb27-3"></a><span class="dv">0</span>,<span class="dv">15</span>,<span class="dv">30</span>,<span class="dv">45</span> <span class="op">*</span> <span class="op">*</span> <span class="op">*</span> <span class="op">*</span>      <span class="co"># Run every 15 minutes</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The cron entry 0 12 asterisk asterisk asterisk means run daily at Noon (12:00) asterisk asterisk 25 2 asterisk represents running once per minute, but only on February 25th. 0 comma 15 comma 30 comma 45 asterisk asterisk asterisk asterisk means to run every 15 minutes.</p>
</section>
<section id="airflow-scheduler-presets" class="level2">
<h2 class="anchored" data-anchor-id="airflow-scheduler-presets">Airflow scheduler presets</h2>
<p>Airflow has several presets, or shortcut syntax options representing often used time intervals.</p>
<table class="table">
<thead>
<tr class="header">
<th>Preset</th>
<th>cron equivalent</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="citation" data-cites="hour">@hour</span></td>
<td>0 * * * *</td>
</tr>
<tr class="even">
<td><span class="citation" data-cites="daily">@daily</span></td>
<td>0 0 * * *</td>
</tr>
<tr class="odd">
<td><span class="citation" data-cites="weekly">@weekly</span></td>
<td>0 0 * * 0</td>
</tr>
<tr class="even">
<td><span class="citation" data-cites="monthly">@monthly</span></td>
<td>0 0 1 * *</td>
</tr>
<tr class="odd">
<td><span class="citation" data-cites="yearly">@yearly</span></td>
<td>0 0 1 1 *</td>
</tr>
</tbody>
</table>
<p>The <span class="citation" data-cites="hourly">@hourly</span> preset means run once an hour at the beginning of the hour. It’s equivalent to 0 asterisk asterisk asterisk asterisk in cron. The <span class="citation" data-cites="daily">@daily</span>, <span class="citation" data-cites="weekly">@weekly</span>, <span class="citation" data-cites="monthly">@monthly</span>, and <span class="citation" data-cites="yearly">@yearly</span> presets behave similarly.</p>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note: “0 12 * * <em>” != “</em> 12 * * *”</p>
<p>“0 12 * * *” This cron expression specifies a specific minute and hour. It means the task should run at 12:00 PM (noon) every day. The 0 in the first position represents the minute, and 12 in the second position represents the hour.</p>
<p>“* 12 * * *” This cron expression uses an asterisk in the minute position, which means the task will run every minute of the 12th hour (noon) of every day. In other words, it will run once every minute between 12:00 PM and 12:59 PM.</p>
</div>
</div>
</div>
</section>
<section id="special-presets" class="level2">
<h2 class="anchored" data-anchor-id="special-presets">Special presets</h2>
<p>Airflow also has two special presets for schedule intervals.</p>
<ul>
<li><span class="citation" data-cites="none">@none</span> means don’t ever schedule the DAG and is used for manually triggered workflows.</li>
<li><span class="citation" data-cites="once">@once</span> means to only schedule a DAG once.</li>
</ul>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Scheduling DAGs has an important nuance to consider. When scheduling DAG runs, Airflow will use the start date as the earliest possible value, but not actually schedule anything until at least one schedule interval has passed beyond the start date. Given a start_date of February 25, 2020 and a <span class="citation" data-cites="daily">@daily</span> schedule interval, Airflow would then use the date of February 26, 2020 for the first run of the DAG. This can be tricky to consider when adding new DAG schedules, especially if they have longer schedule intervals.</p>
</div>
</div>
</div>
</section>
<section id="exercises-6" class="level2">
<h2 class="anchored" data-anchor-id="exercises-6">Exercises</h2>
<section id="exercise-1-schedule-a-dag-via-python" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1-schedule-a-dag-via-python">Exercise 1: Schedule a DAG via Python</h3>
<p>You’ve learned quite a bit about creating DAGs, but now you would like to schedule a specific DAG on a specific day of the week at a certain time. You’d like the code include this information in case a colleague needs to reinstall the DAG to a different server.</p>
<p>The Airflow DAG object and the appropriate datetime methods have been imported for you.</p>
<ul>
<li>Set the start date of the DAG to November 1, 2019.</li>
<li>Configure the retry_delay to 20 minutes. You will learn more about the timedelta object in Chapter 3. For now, you just need to know it expects an integer value.</li>
<li>Use the cron syntax to configure a schedule of every Wednesday at 12:30pm.</li>
</ul>
<div class="sourceCode" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a><span class="co"># Update the scheduling arguments as defined</span></span>
<span id="cb28-2"><a href="#cb28-2"></a>default_args <span class="op">=</span> {</span>
<span id="cb28-3"><a href="#cb28-3"></a>  <span class="st">'owner'</span>: <span class="st">'Engineering'</span>,</span>
<span id="cb28-4"><a href="#cb28-4"></a>  <span class="st">'start_date'</span>: datetime(<span class="dv">2019</span>, <span class="dv">11</span>, <span class="dv">1</span>),</span>
<span id="cb28-5"><a href="#cb28-5"></a>  <span class="st">'email'</span>: [<span class="st">'airflowresults@datacamp.com'</span>],</span>
<span id="cb28-6"><a href="#cb28-6"></a>  <span class="st">'email_on_failure'</span>: <span class="va">False</span>,</span>
<span id="cb28-7"><a href="#cb28-7"></a>  <span class="st">'email_on_retry'</span>: <span class="va">False</span>,</span>
<span id="cb28-8"><a href="#cb28-8"></a>  <span class="st">'retries'</span>: <span class="dv">3</span>,</span>
<span id="cb28-9"><a href="#cb28-9"></a>  <span class="st">'retry_delay'</span>: timedelta(minutes<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb28-10"><a href="#cb28-10"></a>}</span>
<span id="cb28-11"><a href="#cb28-11"></a></span>
<span id="cb28-12"><a href="#cb28-12"></a>dag <span class="op">=</span> DAG(</span>
<span id="cb28-13"><a href="#cb28-13"></a>    <span class="st">'update_dataflows'</span>, </span>
<span id="cb28-14"><a href="#cb28-14"></a>    default_args<span class="op">=</span>default_args, </span>
<span id="cb28-15"><a href="#cb28-15"></a>    schedule_interval <span class="op">=</span> <span class="st">'30 12 * * 3'</span>,</span>
<span id="cb28-16"><a href="#cb28-16"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-2-deciphering-airflow-schedules" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-deciphering-airflow-schedules">Exercise 2: Deciphering Airflow schedules</h3>
<p>Given the various options for Airflow’s schedule_interval, you’d like to verify that you understand exactly how intervals relate to each other, whether it’s a cron format, timedelta object, or a preset.</p>
<ul>
<li>Order the schedule intervals from least to greatest amount of time.</li>
</ul>
<p><img src="../imgs/chapter2/Exercise_7_2.png" class="img-fluid"></p>
</section>
<section id="exercise-3-troubleshooting-dag-runs" class="level3">
<h3 class="anchored" data-anchor-id="exercise-3-troubleshooting-dag-runs">Exercise 3: Troubleshooting DAG runs</h3>
<p>You’ve scheduled a DAG called process_sales which is set to run on the first day of the month and email your manager a copy of the report generated in the workflow. The start_date for the DAG is set to February 15, 2020. Unfortunately it’s now March 2nd and your manager did not receive the report and would like to know what happened.</p>
<p>Use the information you’ve learned about Airflow scheduling to determine what the issue is.</p>
<p><img src="../imgs/chapter2/Exercise_7_3.png" class="img-fluid"></p>
<ul class="task-list">
<li><input type="checkbox" disabled="">The <code>schedule_interval</code> has not yet passed since the <code>start_date</code>.</li>
<li><input type="checkbox" disabled="">The <code>email_manager_task</code> is not downstream of the other tasks.</li>
<li><input type="checkbox" disabled="">The DAG run has an error.</li>
<li><input type="checkbox" disabled="">The <code>op_kwargs</code> are incorrect for the <code>EmailOperator</code>.</li>
</ul>
</section>
</section>
</section>
<section id="section-8-airflow-sensors" class="level1">
<h1>Section 8: Airflow sensors</h1>
<p>A sensor is a special kind of operator that waits for a certain condition to be true. Some examples of conditions include waiting for the creation of a file, uploading a database record, or a specific response from a web request. With sensors, you can define how often to check for the condition(s) to be true. Since sensors are a type of operator, they are assigned to tasks just like normal operators. This means you can apply the bitshift dependencies to them as well.</p>
<section id="sensor-details" class="level2">
<h2 class="anchored" data-anchor-id="sensor-details">Sensor details</h2>
<p>All sensors are derived from the <code>airflow.sensors.base_sensor_operator</code> class. There are some default arguments available to all sensors, including mode, poke_interval, and timeout. The mode tells the sensor how to check for the condition and has two options, poke or reschedule.</p>
<ul>
<li><code>poke</code>: The default is poke, and means to continue checking until complete without giving up a worker slot.</li>
<li><code>reschedule</code>: Reschedule means to give up the worker slot and wait for another slot to become available.</li>
</ul>
<p>We’ll discuss worker slots in the next lesson, but for now consider a worker slot to be the capability to run a task.</p>
<ul>
<li><code>poke_interval</code>: The poke_interval is used in the poke mode, and tells Airflow how often to check for the condition. This is should be at least 1 minute to keep from overloading the Airflow scheduler.</li>
<li><code>timeout</code>: The timeout field is how long to wait (in seconds) before marking the sensor task as failed. To avoid issues, make sure your timeout is significantly shorter than your schedule interval.</li>
</ul>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note that as sensors are operators, they also include normal operator attributes such as task_id and dag.</p>
</div>
</div>
</div>
</section>
<section id="file-sensor" class="level2">
<h2 class="anchored" data-anchor-id="file-sensor">File sensor</h2>
<p>A useful sensor is the FileSensor, found in the <code>airflow.contrib.sensors</code> library. The FileSensor checks for the existence of a file at a certain location in the file system. It can also check for any files within a given directory. A quick example is importing the FileSensor object, then defining a task called file underscore sensor underscore task. We set the task_id and dag entries as usual.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a><span class="im">from</span> airflow.contrib.sensors.file_sensor <span class="im">import</span> FileSensor</span>
<span id="cb29-2"><a href="#cb29-2"></a></span>
<span id="cb29-3"><a href="#cb29-3"></a>file_sensor_task <span class="op">=</span> FileSensor(</span>
<span id="cb29-4"><a href="#cb29-4"></a>    task_id<span class="op">=</span><span class="st">'file_sense'</span>,</span>
<span id="cb29-5"><a href="#cb29-5"></a>    filepath<span class="op">=</span><span class="st">'salesdata.csv'</span>,</span>
<span id="cb29-6"><a href="#cb29-6"></a>    poke_interval<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb29-7"><a href="#cb29-7"></a>    dag<span class="op">=</span>sales_report_dag,</span>
<span id="cb29-8"><a href="#cb29-8"></a>)</span>
<span id="cb29-9"><a href="#cb29-9"></a>    </span>
<span id="cb29-10"><a href="#cb29-10"></a>init_sales_cleanup <span class="op">&gt;&gt;</span> file_sensor_task <span class="op">&gt;&gt;</span> generate_report</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <code>filepath</code> argument is set to <code>salesdata.csv</code>, looking for a file with this filename to exist before continuing. We set the <code>poke_interval</code> to 300 seconds, or to repeat the check every 5 minutes until true.</p>
<p>Finally, we use the bitshift operators to define the sensor’s dependencies within our DAG. In this case, we must run <code>init_sales_cleanup</code>, then wait for the <code>file_sensor_task</code> to finish, then we run <code>generate_report</code>.</p>
</section>
<section id="other-sensors" class="level2">
<h2 class="anchored" data-anchor-id="other-sensors">Other sensors</h2>
<p>There are many types of sensors available within Airflow.</p>
<ul>
<li><code>ExternalTaskSensor</code>: The ExternalTaskSensor waits for a task in a separate DAG to complete. This allows a loose connection to other workflow tasks without making any one workflow too complex.</li>
<li><code>HttpSensor</code>: The HttpSensor will request a web URL and allow you define the content to check for.</li>
<li><code>SqlSensor</code>: The SqlSensor runs a SQL query to check for content.</li>
</ul>
<p>Many other sensors are available in the <code>airflow.sensors</code> and <code>airflow.contrib.sensors</code> libraries.</p>
</section>
<section id="why-sensors" class="level2">
<h2 class="anchored" data-anchor-id="why-sensors">Why sensors?</h2>
<p>You may be wondering when to use a sensor vs an operator.</p>
<p>For the most part, you’ll want to use a normal operator unless you have any of the following requirements:</p>
<ul>
<li><p>You’re uncertain when a condition will be true.</p></li>
<li><p>If you know something will complete that day but it might vary by an hour or so, you can use a sensor to check until it is.</p></li>
<li><p>If you want to continue to check for a condition but not necessarily fail the entire DAG immediately. This provides some flexibility in defining your DAG.</p></li>
<li><p>Finally, if you want to repeatedly run a check without adding cycles to your DAG, sensors are a good choice.</p></li>
</ul>
</section>
<section id="exercises-7" class="level2">
<h2 class="anchored" data-anchor-id="exercises-7">Exercises</h2>
<section id="exercise-1-sensors-vs-operators" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1-sensors-vs-operators">Exercise 1: Sensors vs operators</h3>
<p>As you’ve just learned about sensors, you want to verify you understand what they have in common with normal operators and where they differ.</p>
<p>Move each entry into the Sensors, Operators, or Both bucket.</p>
<p><img src="../imgs/chapter3/Exercise_8_1.png" class="img-fluid"></p>
</section>
<section id="exercise-2-sensory-deprivation" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-sensory-deprivation">Exercise 2: Sensory deprivation</h3>
<p>You’ve recently taken over for another Airflow developer and are trying to learn about the various workflows defined within the system. You come across a DAG that you can’t seem to make run properly using any of the normal tools.</p>
<p>Try exploring the DAG for any information about what it might be looking for before continuing.</p>
<ul class="task-list">
<li><input type="checkbox" disabled="">The DAG is waiting for the file salesdata_ready.csv to be present.</li>
<li><input type="checkbox" disabled="">The DAG expects a response from the SimpleHttpOperator before starting.</li>
<li><input type="checkbox" disabled="">part1 needs a dependency added.</li>
</ul>
<p><img src="../imgs/chapter3/Exercise_8_2.png" class="img-fluid"></p>
</section>
</section>
</section>
<section id="section-9-airflow-executors" class="level1">
<h1>Section 9: Airflow executors</h1>
<section id="what-is-an-executor" class="level2">
<h2 class="anchored" data-anchor-id="what-is-an-executor">What is an executor?</h2>
<p>In Airflow, an executor is the component that actually runs the tasks defined within your workflows. Each executor has different capabilities and behaviors for running the set of tasks. Some may run a single task at a time on a local system, while others might split individual tasks among all the systems in a cluster. As mentioned in the previous lesson, this is often referred to as the number of worker slots available. We’ll discuss some of these in more detail soon, but a few examples of executors are: - SequentialExecutor - LocalExecutor - CeleryExecutor</p>
<p>This is not an exhaustive list, and you can also create your own executor if required (though we won’t cover that in this course).</p>
</section>
<section id="sequentialexecutor" class="level2">
<h2 class="anchored" data-anchor-id="sequentialexecutor">SequentialExecutor</h2>
<p>The SequentialExecutor is the default execution engine for Airflow. It runs only a single task at a time. This means having multiple workflows scheduled around the same timeframe may cause things to take longer than expected. The SequentialExecutor is useful for debugging as it’s fairly simple to follow the flow of tasks and it can also be used with some integrated development environments (though we won’t cover that here).</p>
<p>The most important aspect of the SequentialExecutor is that while it’s very functional for learning and testing, it’s not really recommended for production due to the limitations of task resources.</p>
</section>
<section id="localexecutor" class="level2">
<h2 class="anchored" data-anchor-id="localexecutor">LocalExecutor</h2>
<p>The LocalExecutor is another option for Airflow that runs entirely on a single system. It basically treats each task as a process on the local system, and is able to start as many concurrent tasks as desired / requested / and permitted by the system resources (ie, CPU cores, memory, etc). This concurrency is the parallelism of the system, and it is defined by the user in one of two ways - either unlimited, or limited to a certain number of simultaneous tasks.</p>
<p>Defined intelligently, the LocalExecutor is a good choice for a single production Airflow system and can utilize all the resources of a given host system.</p>
</section>
<section id="celeryexecutor" class="level2">
<h2 class="anchored" data-anchor-id="celeryexecutor">CeleryExecutor</h2>
<p>The last executor we’ll look at is the Celery executor. If you’re not familiar with Celery, it’s a general queuing system written in Python that allows multiple systems to communicate as a basic cluster. Using a CeleryExecutor, multiple Airflow systems can be configured as workers for a given set of workflows / tasks. You can add extra systems at any time to better balance workflows. The power of the CeleryExecutor is significantly more difficult to setup and configure. It requires a working Celery configuration prior to configuring Airflow, not to mention some method to share DAGs between the systems (ie, a git server, Network File System, etc). While it is more difficult to configure, the CeleryExecutor is a powerful choice for anyone working with a large number of DAGs and / or expects their processing needs to grow.</p>
</section>
<section id="determine-your-executor" class="level2">
<h2 class="anchored" data-anchor-id="determine-your-executor">Determine your executor</h2>
<p>Sometimes when developing Airflow workflows, you may want to know the executor being used. If you have access to the command line, you can determine this by: Looking at the appropriate <code>airflow.cfg</code> file. Search for the executor equal line, and it will specify the executor in use.</p>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note that we haven’t discussed the airflow.cfg file in depth as we assume a configured Airflow instance in this course. The airflow.cfg file is where most of the configuration and settings for the Airflow instance are defined, including the type of executor.</p>
</div>
</div>
</div>
</section>
<section id="determine-your-executor-2" class="level2">
<h2 class="anchored" data-anchor-id="determine-your-executor-2">Determine your executor #2</h2>
<p>You can also determine the executor by running airflow list_dags from the command line. Within the first few lines, you should see an entry for which executor is in use (In this case, it’s the SequentialExecutor).</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a><span class="op">!</span> cat <span class="op">~/</span>airflow<span class="op">/</span>airflow.cfg <span class="op">|</span> grep <span class="st">"executor = "</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>executor = SequentialExecutor</code></pre>
</div>
</div>
</section>
<section id="exercises-8" class="level2">
<h2 class="anchored" data-anchor-id="exercises-8">Exercises</h2>
<section id="exercise-1-determining-the-executor" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1-determining-the-executor">Exercise 1: Determining the executor</h3>
<p>While developing your DAGs in Airflow, you realize you’re not certain the configuration of the system. Using the commands you’ve learned, determine which of the following statements is true.</p>
<ul class="task-list">
<li><input type="checkbox" disabled="">This system can run 12 tasks at the same time.</li>
<li><input type="checkbox" disabled="">This system can run one task at a time.</li>
<li><input type="checkbox" disabled="">This system can run as many tasks as needed at a time.</li>
</ul>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1"></a><span class="op">!</span> cat <span class="op">~/</span>airflow<span class="op">/</span>airflow.cfg <span class="op">|</span> grep <span class="st">"executor = "</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>executor = SequentialExecutor</code></pre>
</div>
</div>
<p>The airflow.cfg file is configured to use the SequentialExecutor -&gt; one per time</p>
</section>
<section id="exercise-2-executor-implications" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-executor-implications">Exercise 2: Executor implications</h3>
<p>You’re learning quite a bit about running Airflow DAGs and are gaining some confidence at developing new workflows. That said, your manager has mentioned that on some days, the workflows are taking a lot longer to finish and asks you to investigate. She also mentions that the salesdata_ready.csv file is taking longer to generate these days and the time of day it is completed is variable.</p>
<p>This exercise requires information from the previous two lessons - remember the implications of the available arguments and modify the workflow accordingly.</p>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note that for this exercise, you’re expected to modify one line of code, not add any extra code.</p>
</div>
</div>
</div>
<ul>
<li>Determine the level of parallelism available on this system. You can do this by listing dags (airflow list_dags).</li>
<li>Look at the source for the DAG file and fix which entry is causing the problem.</li>
</ul>
<div class="sourceCode" id="cb34"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb34-1"><a href="#cb34-1"></a><span class="ex">airflow</span> dags list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="../imgs/chapter3/Exercise_9_2.png" class="img-fluid"></p>
<div class="sourceCode" id="cb35"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb35-2"><a href="#cb35-2"></a><span class="im">from</span> airflow.operators.bash_operator <span class="im">import</span> BashOperator</span>
<span id="cb35-3"><a href="#cb35-3"></a><span class="im">from</span> airflow.contrib.sensors.file_sensor <span class="im">import</span> FileSensor</span>
<span id="cb35-4"><a href="#cb35-4"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb35-5"><a href="#cb35-5"></a></span>
<span id="cb35-6"><a href="#cb35-6"></a>report_dag <span class="op">=</span> DAG(</span>
<span id="cb35-7"><a href="#cb35-7"></a>    dag_id <span class="op">=</span> <span class="st">'execute_report'</span>,</span>
<span id="cb35-8"><a href="#cb35-8"></a>    schedule_interval <span class="op">=</span> <span class="st">"0 0 * * *"</span></span>
<span id="cb35-9"><a href="#cb35-9"></a>)</span>
<span id="cb35-10"><a href="#cb35-10"></a></span>
<span id="cb35-11"><a href="#cb35-11"></a>precheck <span class="op">=</span> FileSensor(</span>
<span id="cb35-12"><a href="#cb35-12"></a>    task_id<span class="op">=</span><span class="st">'check_for_datafile'</span>,</span>
<span id="cb35-13"><a href="#cb35-13"></a>    filepath<span class="op">=</span><span class="st">'salesdata_ready.csv'</span>,</span>
<span id="cb35-14"><a href="#cb35-14"></a>    start_date<span class="op">=</span>datetime(<span class="dv">2020</span>,<span class="dv">2</span>,<span class="dv">20</span>),</span>
<span id="cb35-15"><a href="#cb35-15"></a>    mode<span class="op">=</span><span class="st">'poke'</span>,</span>
<span id="cb35-16"><a href="#cb35-16"></a>    dag<span class="op">=</span>report_dag</span>
<span id="cb35-17"><a href="#cb35-17"></a>)</span>
<span id="cb35-18"><a href="#cb35-18"></a></span>
<span id="cb35-19"><a href="#cb35-19"></a>generate_report_task <span class="op">=</span> BashOperator(</span>
<span id="cb35-20"><a href="#cb35-20"></a>    task_id<span class="op">=</span><span class="st">'generate_report'</span>,</span>
<span id="cb35-21"><a href="#cb35-21"></a>    bash_command<span class="op">=</span><span class="st">'generate_report.sh'</span>,</span>
<span id="cb35-22"><a href="#cb35-22"></a>    start_date<span class="op">=</span>datetime(<span class="dv">2020</span>,<span class="dv">2</span>,<span class="dv">20</span>),</span>
<span id="cb35-23"><a href="#cb35-23"></a>    dag<span class="op">=</span>report_dag</span>
<span id="cb35-24"><a href="#cb35-24"></a>)</span>
<span id="cb35-25"><a href="#cb35-25"></a></span>
<span id="cb35-26"><a href="#cb35-26"></a>precheck <span class="op">&gt;&gt;</span> generate_report_task</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>use FileSensor with mode=‘reschedule’ instead of ‘poke’</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb36-2"><a href="#cb36-2"></a><span class="im">from</span> airflow.operators.bash_operator <span class="im">import</span> BashOperator</span>
<span id="cb36-3"><a href="#cb36-3"></a><span class="im">from</span> airflow.contrib.sensors.file_sensor <span class="im">import</span> FileSensor</span>
<span id="cb36-4"><a href="#cb36-4"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb36-5"><a href="#cb36-5"></a></span>
<span id="cb36-6"><a href="#cb36-6"></a>report_dag <span class="op">=</span> DAG(</span>
<span id="cb36-7"><a href="#cb36-7"></a>    dag_id <span class="op">=</span> <span class="st">'execute_report'</span>,</span>
<span id="cb36-8"><a href="#cb36-8"></a>    schedule_interval <span class="op">=</span> <span class="st">"0 0 * * *"</span></span>
<span id="cb36-9"><a href="#cb36-9"></a>)</span>
<span id="cb36-10"><a href="#cb36-10"></a></span>
<span id="cb36-11"><a href="#cb36-11"></a>precheck <span class="op">=</span> FileSensor(</span>
<span id="cb36-12"><a href="#cb36-12"></a>    task_id<span class="op">=</span><span class="st">'check_for_datafile'</span>,</span>
<span id="cb36-13"><a href="#cb36-13"></a>    filepath<span class="op">=</span><span class="st">'salesdata_ready.csv'</span>,</span>
<span id="cb36-14"><a href="#cb36-14"></a>    start_date<span class="op">=</span>datetime(<span class="dv">2020</span>,<span class="dv">2</span>,<span class="dv">20</span>),</span>
<span id="cb36-15"><a href="#cb36-15"></a>    mode<span class="op">=</span><span class="st">'reschedule'</span>,</span>
<span id="cb36-16"><a href="#cb36-16"></a>    dag<span class="op">=</span>report_dag</span>
<span id="cb36-17"><a href="#cb36-17"></a>)</span>
<span id="cb36-18"><a href="#cb36-18"></a></span>
<span id="cb36-19"><a href="#cb36-19"></a>generate_report_task <span class="op">=</span> BashOperator(</span>
<span id="cb36-20"><a href="#cb36-20"></a>    task_id<span class="op">=</span><span class="st">'generate_report'</span>,</span>
<span id="cb36-21"><a href="#cb36-21"></a>    bash_command<span class="op">=</span><span class="st">'generate_report.sh'</span>,</span>
<span id="cb36-22"><a href="#cb36-22"></a>    start_date<span class="op">=</span>datetime(<span class="dv">2020</span>,<span class="dv">2</span>,<span class="dv">20</span>),</span>
<span id="cb36-23"><a href="#cb36-23"></a>    dag<span class="op">=</span>report_dag</span>
<span id="cb36-24"><a href="#cb36-24"></a>)</span>
<span id="cb36-25"><a href="#cb36-25"></a></span>
<span id="cb36-26"><a href="#cb36-26"></a>precheck <span class="op">&gt;&gt;</span> generate_report_task</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="section-10-debugging-and-troubleshooting-in-airflow" class="level1">
<h1>Section 10: Debugging and troubleshooting in Airflow</h1>
<section id="typical-issues" class="level2">
<h2 class="anchored" data-anchor-id="typical-issues">Typical issues…</h2>
<p>There are several common issues you may run across while working with Airflow - it helps to have an idea of what these might be and how best handle them. - The first common issue is a DAG or DAGs that won’t run on schedule. - The next is a DAG that simply won’t load into the system. - The last common scenario involves syntax errors.</p>
<p>Let’s look at these more closely.</p>
</section>
<section id="dag-wont-run-on-schedule" class="level2">
<h2 class="anchored" data-anchor-id="dag-wont-run-on-schedule">DAG won’t run on schedule</h2>
<p>The most common reason why a DAG won’t run on schedule is the scheduler is not running. Airflow contains several components that accomplish various aspects of the system. The Airflow scheduler handles DAG run and task scheduling. If it is not running, no new tasks can run. You’ll often see this error within the web UI if the scheduler component is not running.</p>
<p><img src="../imgs/chapter3/0X103.png" class="img-fluid"></p>
<p>You can easily fix this issue by running airflow scheduler from the command-line.</p>
</section>
<section id="dag-wont-run-on-schedule-1" class="level2">
<h2 class="anchored" data-anchor-id="dag-wont-run-on-schedule-1">DAG won’t run on schedule</h2>
<ul>
<li>As we’ve covered before, another common issue with scheduling is the scenario where at least one schedule interval period has not passed since either the start date or the last DAG run. There isn’t a specific fix for this, but you might want to modify the start date or schedule interval to meet your requirements.</li>
<li>The last scheduling issue you’ll often see is related to what we covered in the previous lesson - the executor does not have enough free slots to run tasks. There are basically three ways to alleviate this problem - by changing the executor type to something capable of more tasks (LocalExecutor or CeleryExecutor), by adding systems or system resources (RAM, CPUs), or finally by changing the scheduling of your DAGs.</li>
</ul>
</section>
<section id="dag-wont-load" class="level2">
<h2 class="anchored" data-anchor-id="dag-wont-load">DAG won’t load</h2>
<p>You’ll often see an issue where a new DAG will not appear in your DAG view of the web UI or in the airflow list_dags output. The first thing to check is that the python file is in the expected DAGs folder or directory. You can determine the current DAGs folder setting by examining the airflow.cfg file. The line dags underscore folder will indicate where Airflow expects to find your Python DAG files.</p>
<p><img src="../imgs/chapter3/0X112.png" class="img-fluid"></p>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note that the folder path must be an absolute path.</p>
</div>
</div>
</div>
</section>
<section id="syntax-errors" class="level2">
<h2 class="anchored" data-anchor-id="syntax-errors">Syntax errors</h2>
<p>Probably the most common reason a DAG workflow won’t appear in your DAG list is one or more syntax errors in your python code. These are sometimes difficult to find, especially in an editor not setup for Python / Airflow (such as a base Vim install). I tend to prefer using Vim with some Python tools loaded, or VSCode but it’s really up to your preference. There are two quick methods to check for these issues - airflow list_dags, and running your DAG script with python.</p>
</section>
<section id="airflow-list_dags" class="level2">
<h2 class="anchored" data-anchor-id="airflow-list_dags">airflow list_dags</h2>
<p>The first is to run airflow space list underscore dags.</p>
<p><img src="../imgs/chapter3/0X123.png" class="img-fluid"></p>
<p>As we’ve seen before, Airflow will output some debugging information and the list of DAGs it’s processed. If there are any errors, those will appear in the output, helping you to troubleshoot further.</p>
</section>
<section id="running-the-python-interpreter" class="level2">
<h2 class="anchored" data-anchor-id="running-the-python-interpreter">Running the Python interpreter</h2>
<p>Another method to verify Python syntax is to run the actual python3 interpreter against the file. You won’t see any output normally as there’s nothing for the interpreter to do, but it can check for any syntax errors in your code. If there are errors, you’ll get an appropriate error message. If there are no errors, you’ll be returned to the command prompt.</p>
<p><img src="../imgs/chapter3/0X129.png" class="img-fluid"></p>
</section>
<section id="exercises-9" class="level2">
<h2 class="anchored" data-anchor-id="exercises-9">Exercises</h2>
<section id="exercise-1-dags-in-the-bag" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1-dags-in-the-bag">Exercise 1: DAGs in the bag</h3>
<p>You’ve taken over managing an Airflow cluster that you did not setup and are trying to learn a bit more about the system. Which of the following is true?</p>
<p><img src="../imgs/chapter3/Exercise_10_1.png" class="img-fluid"></p>
<ul class="task-list">
<li><input type="checkbox" disabled="">The DAG is scheduled for hourly processing.</li>
<li><input type="checkbox" disabled="">The Airflow user does not have proper permissions.</li>
<li><input type="checkbox" disabled="" checked="">The <code>dags_folder</code> is set to <code>/home/repl/workspace/dags</code>.</li>
</ul>
</section>
<section id="exercise-2-missing-dag" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-missing-dag">Exercise 2: Missing DAG</h3>
<p>Your manager calls you before you’re about to leave for the evening and wants to know why a new DAG workflow she’s created isn’t showing up in the system. She needs this DAG called execute_report to appear in the system so she can properly schedule it for some tests before she leaves on a trip.</p>
<p>Airflow is configured using the ~/airflow/airflow.cfg file.</p>
<ul>
<li>Examine the DAG for any errors and fix those.</li>
<li>Determine if the DAG has loaded after fixing the errors.</li>
<li>If not, determine why the DAG has not loaded and fix the final issue.</li>
</ul>
<div class="sourceCode" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb37-2"><a href="#cb37-2"></a><span class="co"># from airflow.operators.bash_operator import BashOperator</span></span>
<span id="cb37-3"><a href="#cb37-3"></a><span class="im">from</span> airflow.contrib.sensors.file_sensor <span class="im">import</span> FileSensor</span>
<span id="cb37-4"><a href="#cb37-4"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb37-5"><a href="#cb37-5"></a></span>
<span id="cb37-6"><a href="#cb37-6"></a>report_dag <span class="op">=</span> DAG(</span>
<span id="cb37-7"><a href="#cb37-7"></a>    dag_id <span class="op">=</span> <span class="st">'execute_report'</span>,</span>
<span id="cb37-8"><a href="#cb37-8"></a>    schedule_interval <span class="op">=</span> <span class="st">"0 0 * * *"</span></span>
<span id="cb37-9"><a href="#cb37-9"></a>)</span>
<span id="cb37-10"><a href="#cb37-10"></a></span>
<span id="cb37-11"><a href="#cb37-11"></a>precheck <span class="op">=</span> FileSensor(</span>
<span id="cb37-12"><a href="#cb37-12"></a>    task_id<span class="op">=</span><span class="st">'check_for_datafile'</span>,</span>
<span id="cb37-13"><a href="#cb37-13"></a>    filepath<span class="op">=</span><span class="st">'salesdata_ready.csv'</span>,</span>
<span id="cb37-14"><a href="#cb37-14"></a>    start_date<span class="op">=</span>datetime(<span class="dv">2020</span>,<span class="dv">2</span>,<span class="dv">20</span>),</span>
<span id="cb37-15"><a href="#cb37-15"></a>    mode<span class="op">=</span><span class="st">'poke'</span>,</span>
<span id="cb37-16"><a href="#cb37-16"></a>    dag<span class="op">=</span>report_dag)</span>
<span id="cb37-17"><a href="#cb37-17"></a></span>
<span id="cb37-18"><a href="#cb37-18"></a>generate_report_task <span class="op">=</span> BashOperator(</span>
<span id="cb37-19"><a href="#cb37-19"></a>    task_id<span class="op">=</span><span class="st">'generate_report'</span>,</span>
<span id="cb37-20"><a href="#cb37-20"></a>    bash_command<span class="op">=</span><span class="st">'generate_report.sh'</span>,</span>
<span id="cb37-21"><a href="#cb37-21"></a>    start_date<span class="op">=</span>datetime(<span class="dv">2020</span>,<span class="dv">2</span>,<span class="dv">20</span>),</span>
<span id="cb37-22"><a href="#cb37-22"></a>    dag<span class="op">=</span>report_dag</span>
<span id="cb37-23"><a href="#cb37-23"></a>)</span>
<span id="cb37-24"><a href="#cb37-24"></a></span>
<span id="cb37-25"><a href="#cb37-25"></a>precheck <span class="op">&gt;&gt;</span> generate_report_task</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>remove the comment from the line 2</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb38-2"><a href="#cb38-2"></a><span class="im">from</span> airflow.operators.bash_operator <span class="im">import</span> BashOperator</span>
<span id="cb38-3"><a href="#cb38-3"></a><span class="im">from</span> airflow.contrib.sensors.file_sensor <span class="im">import</span> FileSensor</span>
<span id="cb38-4"><a href="#cb38-4"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb38-5"><a href="#cb38-5"></a></span>
<span id="cb38-6"><a href="#cb38-6"></a>report_dag <span class="op">=</span> DAG(</span>
<span id="cb38-7"><a href="#cb38-7"></a>    dag_id <span class="op">=</span> <span class="st">'execute_report'</span>,</span>
<span id="cb38-8"><a href="#cb38-8"></a>    schedule_interval <span class="op">=</span> <span class="st">"0 0 * * *"</span></span>
<span id="cb38-9"><a href="#cb38-9"></a>)</span>
<span id="cb38-10"><a href="#cb38-10"></a></span>
<span id="cb38-11"><a href="#cb38-11"></a>precheck <span class="op">=</span> FileSensor(</span>
<span id="cb38-12"><a href="#cb38-12"></a>    task_id<span class="op">=</span><span class="st">'check_for_datafile'</span>,</span>
<span id="cb38-13"><a href="#cb38-13"></a>    filepath<span class="op">=</span><span class="st">'salesdata_ready.csv'</span>,</span>
<span id="cb38-14"><a href="#cb38-14"></a>    start_date<span class="op">=</span>datetime(<span class="dv">2020</span>,<span class="dv">2</span>,<span class="dv">20</span>),</span>
<span id="cb38-15"><a href="#cb38-15"></a>    mode<span class="op">=</span><span class="st">'poke'</span>,</span>
<span id="cb38-16"><a href="#cb38-16"></a>    dag<span class="op">=</span>report_dag)</span>
<span id="cb38-17"><a href="#cb38-17"></a></span>
<span id="cb38-18"><a href="#cb38-18"></a>generate_report_task <span class="op">=</span> BashOperator(</span>
<span id="cb38-19"><a href="#cb38-19"></a>    task_id<span class="op">=</span><span class="st">'generate_report'</span>,</span>
<span id="cb38-20"><a href="#cb38-20"></a>    bash_command<span class="op">=</span><span class="st">'generate_report.sh'</span>,</span>
<span id="cb38-21"><a href="#cb38-21"></a>    start_date<span class="op">=</span>datetime(<span class="dv">2020</span>,<span class="dv">2</span>,<span class="dv">20</span>),</span>
<span id="cb38-22"><a href="#cb38-22"></a>    dag<span class="op">=</span>report_dag</span>
<span id="cb38-23"><a href="#cb38-23"></a>)</span>
<span id="cb38-24"><a href="#cb38-24"></a></span>
<span id="cb38-25"><a href="#cb38-25"></a>precheck <span class="op">&gt;&gt;</span> generate_report_task</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="section-11-slas" class="level1">
<h1>Section 11: SLAs</h1>
<p>You may be wondering, what is an SLA? SLA stands for Service Level Agreement. Within the business world, this is often an uptime or availability guarantee. Airflow treats it a bit differently - it’s considered the amount of time a task or a DAG should require to run. An SLA miss is any situation where a task or DAG does not meet the expected timing for the SLA. If an SLA is missed, an email alert is sent out per the system configuration and a note is made in the log. Any SLA miss can be viewed in the Browse, SLA Misses menu item of the web UI.</p>
<section id="sla-misses" class="level2">
<h2 class="anchored" data-anchor-id="sla-misses">SLA Misses</h2>
<p>To view any given SLA miss, you can access it in the web UI, via the Browse: SLA Misses link. It provides you general information about what task missed the SLA and when it failed. It also indicates if an email has been sent when the SLA failed.</p>
<p><img src="../imgs/chapter3/0X153.png" class="img-fluid"></p>
</section>
<section id="defining-slas" class="level2">
<h2 class="anchored" data-anchor-id="defining-slas">Defining SLAs</h2>
<p>There are several ways to define an SLA but we’ll only look at two for this course. The first is via an sla argument on the task itself. This takes a timedelta object with the amount of time to pass.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1"></a>task1 <span class="op">=</span> BashOperator(</span>
<span id="cb39-2"><a href="#cb39-2"></a>    task_id <span class="op">=</span> <span class="st">'sla_task'</span>,</span>
<span id="cb39-3"><a href="#cb39-3"></a>    bash_command <span class="op">=</span> <span class="st">'runcode.sh'</span>,</span>
<span id="cb39-4"><a href="#cb39-4"></a>    sla <span class="op">=</span> timedelta(seconds <span class="op">=</span> <span class="dv">30</span>),</span>
<span id="cb39-5"><a href="#cb39-5"></a>    dag <span class="op">=</span> dag,</span>
<span id="cb39-6"><a href="#cb39-6"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The second way is using the default_args dictionary and defining an sla key.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1"></a>default_args <span class="op">=</span> {</span>
<span id="cb40-2"><a href="#cb40-2"></a>    <span class="st">'sla'</span>: timedelta(minutes<span class="op">=</span><span class="dv">20</span>),</span>
<span id="cb40-3"><a href="#cb40-3"></a>    <span class="st">'start_date'</span>: datetime(<span class="dv">2020</span>,<span class="dv">2</span>,<span class="dv">20</span>)</span>
<span id="cb40-4"><a href="#cb40-4"></a>},</span>
<span id="cb40-5"><a href="#cb40-5"></a></span>
<span id="cb40-6"><a href="#cb40-6"></a>dag <span class="op">=</span> DAG(</span>
<span id="cb40-7"><a href="#cb40-7"></a>    <span class="st">'sla_dag'</span>, </span>
<span id="cb40-8"><a href="#cb40-8"></a>    default_args <span class="op">=</span> default_args</span>
<span id="cb40-9"><a href="#cb40-9"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The dictionary is then passed into the default_args argument of the DAG and applies to any tasks internally.</p>
</section>
<section id="timedelta-object" class="level2">
<h2 class="anchored" data-anchor-id="timedelta-object">timedelta object</h2>
<p>We haven’t covered the timedelta object yet so let’s look at some of the details. It’s found in the <code>datetime</code> library, along with the datetime object. Most easily accessed with an import statement of <code>from datetime import timedelta</code>. Takes arguments of days, seconds, minutes, hours, and weeks.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1"></a>timedelta(seconds<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb41-2"><a href="#cb41-2"></a>timedelta(weeks<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb41-3"><a href="#cb41-3"></a>timedelta(days<span class="op">=</span><span class="dv">4</span>, hours<span class="op">=</span><span class="dv">10</span>, minutes<span class="op">=</span><span class="dv">20</span>, seconds<span class="op">=</span><span class="dv">30</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>It also has milliseconds and microseconds available, but those wouldn’t apply to Airflow. To create the object, you simply call timedelta with the argument or arguments you wish to reference. To create a 30 second time delta, call it with seconds equals 30. Or weeks equals 2. Or you can combine it into a longer mix of any of the arguments you wish (in this case, 4 days, 10 hours, 20 minutes, and 30 seconds).</p>
</section>
<section id="general-reporting" class="level2">
<h2 class="anchored" data-anchor-id="general-reporting">General reporting</h2>
<p>For reporting purposes you can use email alerting built into Airflow. There are a couple ways to do this. Airflow has built-in options for sending messages:</p>
<ul>
<li>success</li>
<li>failure</li>
<li>error</li>
<li>retry</li>
</ul>
<p>These are handled via keys in the default_args dictionary that gets passed on DAG creation. The required component is the list of emails assigned to the email key. Then there are boolean options for email underscore on underscore failure, email underscore on underscore retry, and email underscore on underscore success.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1"></a>default_args <span class="op">=</span> {</span>
<span id="cb42-2"><a href="#cb42-2"></a>    <span class="st">'email'</span>: [<span class="st">'address@domain.com'</span>],</span>
<span id="cb42-3"><a href="#cb42-3"></a>    <span class="st">'email_on_failure'</span>: <span class="va">True</span>,</span>
<span id="cb42-4"><a href="#cb42-4"></a>    <span class="st">'email_on_retry'</span>: <span class="va">False</span>,</span>
<span id="cb42-5"><a href="#cb42-5"></a>    <span class="st">'email_on_success'</span>: <span class="va">True</span>,</span>
<span id="cb42-6"><a href="#cb42-6"></a>    ...</span>
<span id="cb42-7"><a href="#cb42-7"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In addition, we’ve already looked at the EmailOperator earlier but this is useful for sending emails outside of one of the defined Airflow options. Note that sending an email does require configuration within Airflow that is outside the scope of this course. The Airflow documentation provides information on how to set up the global email configuration.</p>
</section>
<section id="exercises-10" class="level2">
<h2 class="anchored" data-anchor-id="exercises-10">Exercises</h2>
<section id="exercise-1-defining-an-sla" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1-defining-an-sla">Exercise 1: Defining an SLA</h3>
<p>You’ve successfully implemented several Airflow workflows into production, but you don’t currently have any method of determining if a workflow takes too long to run. After consulting with your manager and your team, you decide to implement an SLA at the DAG level on a test workflow.</p>
<p>All appropriate Airflow libraries have been imported for you.</p>
<ul>
<li>Import the timedelta object.</li>
<li>Define an SLA of 30 minutes.</li>
<li>Add the SLA to the DAG.</li>
</ul>
<div class="sourceCode" id="cb43"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1"></a><span class="co"># Import the timedelta object</span></span>
<span id="cb43-2"><a href="#cb43-2"></a><span class="im">from</span> datetime <span class="im">import</span> timedelta</span>
<span id="cb43-3"><a href="#cb43-3"></a></span>
<span id="cb43-4"><a href="#cb43-4"></a><span class="co"># Create the dictionary entry</span></span>
<span id="cb43-5"><a href="#cb43-5"></a>default_args <span class="op">=</span> {</span>
<span id="cb43-6"><a href="#cb43-6"></a>  <span class="st">'start_date'</span>: datetime(<span class="dv">2020</span>, <span class="dv">2</span>, <span class="dv">20</span>),</span>
<span id="cb43-7"><a href="#cb43-7"></a>  <span class="st">'sla'</span>: timedelta(minutes<span class="op">=</span><span class="dv">30</span>),</span>
<span id="cb43-8"><a href="#cb43-8"></a>}</span>
<span id="cb43-9"><a href="#cb43-9"></a></span>
<span id="cb43-10"><a href="#cb43-10"></a><span class="co"># Add to the DAG</span></span>
<span id="cb43-11"><a href="#cb43-11"></a>test_dag <span class="op">=</span> DAG(</span>
<span id="cb43-12"><a href="#cb43-12"></a>  <span class="st">'test_workflow'</span>,</span>
<span id="cb43-13"><a href="#cb43-13"></a>  default_args<span class="op">=</span>default_args,</span>
<span id="cb43-14"><a href="#cb43-14"></a>  schedule_interval<span class="op">=</span><span class="st">'@None'</span>,</span>
<span id="cb43-15"><a href="#cb43-15"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-2-defining-a-task-sla" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-defining-a-task-sla">Exercise 2: Defining a task SLA</h3>
<p>After completing the SLA on the entire workflow, you realize you really only need the SLA timing on a specific task instead of the full workflow.</p>
<p>The appropriate Airflow libraries are imported for you.</p>
<ul>
<li>Import the timedelta object.</li>
<li>Add a 3 hour SLA to the task object</li>
</ul>
<div class="sourceCode" id="cb44"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1"></a><span class="co"># Import the timedelta object</span></span>
<span id="cb44-2"><a href="#cb44-2"></a><span class="im">from</span> datetime <span class="im">import</span> timedelta</span>
<span id="cb44-3"><a href="#cb44-3"></a></span>
<span id="cb44-4"><a href="#cb44-4"></a>test_dag <span class="op">=</span> DAG(</span>
<span id="cb44-5"><a href="#cb44-5"></a>    <span class="st">'test_workflow'</span>, </span>
<span id="cb44-6"><a href="#cb44-6"></a>    start_date<span class="op">=</span>datetime(<span class="dv">2020</span>,<span class="dv">2</span>,<span class="dv">20</span>), </span>
<span id="cb44-7"><a href="#cb44-7"></a>    schedule_interval<span class="op">=</span><span class="st">'@None'</span></span>
<span id="cb44-8"><a href="#cb44-8"></a>)</span>
<span id="cb44-9"><a href="#cb44-9"></a></span>
<span id="cb44-10"><a href="#cb44-10"></a><span class="co"># Create the task with the SLA</span></span>
<span id="cb44-11"><a href="#cb44-11"></a>task1 <span class="op">=</span> BashOperator(</span>
<span id="cb44-12"><a href="#cb44-12"></a>    task_id <span class="op">=</span> <span class="st">'first_task'</span>,</span>
<span id="cb44-13"><a href="#cb44-13"></a>    sla <span class="op">=</span> timedelta(hours <span class="op">=</span> <span class="dv">3</span>),</span>
<span id="cb44-14"><a href="#cb44-14"></a>    bash_command <span class="op">=</span> <span class="st">'initialize_data.sh'</span>,</span>
<span id="cb44-15"><a href="#cb44-15"></a>    dag <span class="op">=</span> test_dag</span>
<span id="cb44-16"><a href="#cb44-16"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-3-generate-and-email-a-report" class="level3">
<h3 class="anchored" data-anchor-id="exercise-3-generate-and-email-a-report">Exercise 3: Generate and email a report</h3>
<p>Airflow provides the ability to automate almost any style of workflow. You would like to receive a report from Airflow when tasks complete without requiring constant monitoring of the UI or log files. You decide to use the email functionality within Airflow to provide this message.</p>
<p>All the typical Airflow components have been imported for you, and a DAG is already defined as dag.</p>
<ul>
<li>Define the proper operator for the email_report task.</li>
<li>Fill the missing details for the Operator. Use the file named monthly_report.pdf.</li>
<li>Set the email_report task to occur after the generate_report task.</li>
</ul>
<div class="sourceCode" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1"></a><span class="co"># Define the email task</span></span>
<span id="cb45-2"><a href="#cb45-2"></a>email_report <span class="op">=</span> EmailOperator(</span>
<span id="cb45-3"><a href="#cb45-3"></a>        task_id <span class="op">=</span> <span class="st">'email_report'</span>,</span>
<span id="cb45-4"><a href="#cb45-4"></a>        to <span class="op">=</span> <span class="st">'airflow@datacamp.com'</span>,</span>
<span id="cb45-5"><a href="#cb45-5"></a>        subject <span class="op">=</span> <span class="st">'Airflow Monthly Report'</span>,</span>
<span id="cb45-6"><a href="#cb45-6"></a>        html_content <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb45-7"><a href="#cb45-7"></a><span class="st">        Attached is your monthly workflow report - please refer to it for more detail</span></span>
<span id="cb45-8"><a href="#cb45-8"></a><span class="st">        """</span>,</span>
<span id="cb45-9"><a href="#cb45-9"></a>        files <span class="op">=</span> [<span class="st">'monthly_report.pdf'</span>],</span>
<span id="cb45-10"><a href="#cb45-10"></a>        dag <span class="op">=</span> report_dag,</span>
<span id="cb45-11"><a href="#cb45-11"></a>)</span>
<span id="cb45-12"><a href="#cb45-12"></a></span>
<span id="cb45-13"><a href="#cb45-13"></a><span class="co"># Set the email task to run after the report is generated</span></span>
<span id="cb45-14"><a href="#cb45-14"></a>email_report <span class="op">&lt;&lt;</span> generate_report</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-4-adding-status-emails" class="level3">
<h3 class="anchored" data-anchor-id="exercise-4-adding-status-emails">Exercise 4: Adding status emails</h3>
<p>You’ve worked through most of the Airflow configuration for setting up your workflows, but you realize you’re not getting any notifications when DAG runs complete or fail. You’d like to setup email alerting for the success and failure cases, but you want to send it to two addresses.</p>
<ul>
<li>Edit the execute_report_dag.py workflow.</li>
<li>Add the emails airflowalerts@datacamp.com and airflowadmin@datacamp.com to the appropriate key in default_args.</li>
<li>Set the failure email option to True.</li>
<li>Configure the success email to send you messages as well.</li>
</ul>
<div class="sourceCode" id="cb46"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb46-2"><a href="#cb46-2"></a><span class="im">from</span> airflow.operators.bash_operator <span class="im">import</span> BashOperator</span>
<span id="cb46-3"><a href="#cb46-3"></a><span class="im">from</span> airflow.contrib.sensors.file_sensor <span class="im">import</span> FileSensor</span>
<span id="cb46-4"><a href="#cb46-4"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb46-5"><a href="#cb46-5"></a></span>
<span id="cb46-6"><a href="#cb46-6"></a>default_args<span class="op">=</span>{</span>
<span id="cb46-7"><a href="#cb46-7"></a>    <span class="st">'email'</span>: [</span>
<span id="cb46-8"><a href="#cb46-8"></a>        <span class="st">'airflowalerts@datacamp.com'</span>,</span>
<span id="cb46-9"><a href="#cb46-9"></a>        <span class="st">'airflowadmin@datacamp.com'</span>,</span>
<span id="cb46-10"><a href="#cb46-10"></a>        ...</span>
<span id="cb46-11"><a href="#cb46-11"></a>    ],</span>
<span id="cb46-12"><a href="#cb46-12"></a>    <span class="st">'email_on_failure'</span>: <span class="va">True</span>,</span>
<span id="cb46-13"><a href="#cb46-13"></a>    <span class="st">'email_on_success'</span>: <span class="va">True</span>,</span>
<span id="cb46-14"><a href="#cb46-14"></a>}</span>
<span id="cb46-15"><a href="#cb46-15"></a></span>
<span id="cb46-16"><a href="#cb46-16"></a>report_dag <span class="op">=</span> DAG(</span>
<span id="cb46-17"><a href="#cb46-17"></a>    dag_id <span class="op">=</span> <span class="st">'execute_report'</span>,</span>
<span id="cb46-18"><a href="#cb46-18"></a>    schedule_interval <span class="op">=</span> <span class="st">"0 0 * * *"</span>,</span>
<span id="cb46-19"><a href="#cb46-19"></a>    default_args <span class="op">=</span> default_args</span>
<span id="cb46-20"><a href="#cb46-20"></a>)</span>
<span id="cb46-21"><a href="#cb46-21"></a></span>
<span id="cb46-22"><a href="#cb46-22"></a>precheck <span class="op">=</span> FileSensor(</span>
<span id="cb46-23"><a href="#cb46-23"></a>    task_id <span class="op">=</span> <span class="st">'check_for_datafile'</span>,</span>
<span id="cb46-24"><a href="#cb46-24"></a>    filepath <span class="op">=</span> <span class="st">'salesdata_ready.csv'</span>,</span>
<span id="cb46-25"><a href="#cb46-25"></a>    start_date <span class="op">=</span> datetime(<span class="dv">2020</span>,<span class="dv">2</span>,<span class="dv">20</span>),</span>
<span id="cb46-26"><a href="#cb46-26"></a>    mode <span class="op">=</span> <span class="st">'reschedule'</span>,</span>
<span id="cb46-27"><a href="#cb46-27"></a>    dag <span class="op">=</span> report_dag</span>
<span id="cb46-28"><a href="#cb46-28"></a>)</span>
<span id="cb46-29"><a href="#cb46-29"></a></span>
<span id="cb46-30"><a href="#cb46-30"></a>generate_report_task <span class="op">=</span> BashOperator(</span>
<span id="cb46-31"><a href="#cb46-31"></a>    task_id <span class="op">=</span> <span class="st">'generate_report'</span>,</span>
<span id="cb46-32"><a href="#cb46-32"></a>    bash_command <span class="op">=</span> <span class="st">'generate_report.sh'</span>,</span>
<span id="cb46-33"><a href="#cb46-33"></a>    start_date <span class="op">=</span> datetime(<span class="dv">2020</span>,<span class="dv">2</span>,<span class="dv">20</span>),</span>
<span id="cb46-34"><a href="#cb46-34"></a>    dag <span class="op">=</span> report_dag,</span>
<span id="cb46-35"><a href="#cb46-35"></a>)</span>
<span id="cb46-36"><a href="#cb46-36"></a></span>
<span id="cb46-37"><a href="#cb46-37"></a>precheck <span class="op">&gt;&gt;</span> generate_report_task</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="section-12-working-with-templates" class="level1">
<h1>Section 12: Working with templates</h1>
<section id="what-are-templates" class="level2">
<h2 class="anchored" data-anchor-id="what-are-templates">What are templates?</h2>
<p>You may be wondering what templates are and what they do in the case of Airflow.</p>
<ul>
<li>Templates allow substitution of information during a DAG run. In other words, every time a DAG with templated information is executed, information is interpreted and included with the DAG run.</li>
<li>Templates provide added flexibility when defining tasks. We’ll see examples of this shortly.</li>
<li>Templates are created using the Jinja templating language. A full explanation of <code>Jinja</code> is out of scope for this course, but we’ll cover some basics in the coming slides.</li>
</ul>
</section>
<section id="non-templated-bashoperator-example" class="level2">
<h2 class="anchored" data-anchor-id="non-templated-bashoperator-example">Non-Templated BashOperator example</h2>
<p>Before we get specifically into a templated example, let’s consider what we would do for the following requirement. Your manager has asked you to simply echo the word “Reading” and a list of files to a log / output / etc. If we were to do this with what we currently know about Airflow, we would likely create multiple tasks using the BashOperator. Our first task would setup the task with the intended bash command - in this case echo Reading file1 dot txt, as an argument to the BashOperator.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1"></a>t1 <span class="op">=</span> BashOperator(</span>
<span id="cb47-2"><a href="#cb47-2"></a>    task_id <span class="op">=</span> <span class="st">'first_task'</span>,</span>
<span id="cb47-3"><a href="#cb47-3"></a>    bash_command <span class="op">=</span> <span class="st">'echo "Reading file1.txt"'</span>,</span>
<span id="cb47-4"><a href="#cb47-4"></a>    dag <span class="op">=</span> dag,</span>
<span id="cb47-5"><a href="#cb47-5"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If we had a second file, we would create a second task using the bash command echo Reading file2 dot txt.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1"></a>t2 <span class="op">=</span> BashOperator(</span>
<span id="cb48-2"><a href="#cb48-2"></a>    task_id <span class="op">=</span> <span class="st">'second_task'</span>,</span>
<span id="cb48-3"><a href="#cb48-3"></a>    bash_command <span class="op">=</span> <span class="st">'echo "Reading file2.txt"'</span>,</span>
<span id="cb48-4"><a href="#cb48-4"></a>    dag <span class="op">=</span> dag,</span>
<span id="cb48-5"><a href="#cb48-5"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This type of code would continue for the entire list of files. Consider what this would look like if we had 5, 10, or even 100+ files we needed to process. There would be a lot of repetitive code. Not to mention what if you needed to change the command being used / etc.</p>
</section>
<section id="templated-bashoperator-example" class="level2">
<h2 class="anchored" data-anchor-id="templated-bashoperator-example">Templated BashOperator example</h2>
<p>Let’s take a look at how we would accomplish the same behavior with templates. First, we need to create a variable containing our template - which is really just a string with some specialized formatting.</p>
<p>Our string is the actual bash command echo and instead of the file name, we’re using two open curly braces, the term params dot filename, and then two closing curly braces. The curly braces when used in this manner represent information to be substituted. This will make more sense in a moment. If you’ve done any web development or worked with any reporting tools, you’ve likely worked with something similar. Next, we create our Airflow task as we have previously. We assign a task_id and dag argument as usual, but our bashcommand looks a little different. We set the bashcommand to use the templated command string we defined earlier. We also have an additional argument called params. In this case, params is a dictionary containing a single key filename with the value file1 dot txt. Now, if you look back at the templated command, you’ll notice that the term in the curly braces is params.filename.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1"></a>templated_command <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb49-2"><a href="#cb49-2"></a><span class="st">    echo "Reading </span><span class="sc">{{</span><span class="st"> params.filename </span><span class="sc">}}</span><span class="st">"</span></span>
<span id="cb49-3"><a href="#cb49-3"></a><span class="st">"""</span></span>
<span id="cb49-4"><a href="#cb49-4"></a>t_i <span class="op">=</span> BashOperator(</span>
<span id="cb49-5"><a href="#cb49-5"></a>    task_id <span class="op">=</span> <span class="st">'templated_task'</span>,</span>
<span id="cb49-6"><a href="#cb49-6"></a>    bash_command <span class="op">=</span> templated_command,</span>
<span id="cb49-7"><a href="#cb49-7"></a>    params <span class="op">=</span> {</span>
<span id="cb49-8"><a href="#cb49-8"></a>        <span class="st">'filename'</span>: <span class="st">'file1.txt'</span>,</span>
<span id="cb49-9"><a href="#cb49-9"></a>    },</span>
<span id="cb49-10"><a href="#cb49-10"></a>    dag <span class="op">=</span> dag,</span>
<span id="cb49-11"><a href="#cb49-11"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>At runtime, Airflow will execute the BashOperator by reading the templated command and replacing params dot filename with the value stored in the params dictionary for the filename key. In other words, it would pass the BashOperator echo Reading file1 dot txt. The actual log output would be Reading file1 dot txt (after the BashOperator executed the command).</p>
</section>
<section id="templated-bashoperator-example-continued" class="level2">
<h2 class="anchored" data-anchor-id="templated-bashoperator-example-continued">Templated BashOperator example (continued)</h2>
<p>Now, let’s consider one way to use templates for our earlier task of outputting Reading file1 dot txt and Reading file2 dot txt.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1"></a>templated_command<span class="op">=</span><span class="st">"""  </span></span>
<span id="cb50-2"><a href="#cb50-2"></a><span class="st">    echo "Reading </span><span class="sc">{{</span><span class="st"> params.filename </span><span class="sc">}}</span><span class="st">"</span></span>
<span id="cb50-3"><a href="#cb50-3"></a><span class="st">"""</span></span>
<span id="cb50-4"><a href="#cb50-4"></a>t1 <span class="op">=</span> BashOperator(</span>
<span id="cb50-5"><a href="#cb50-5"></a>    task_id<span class="op">=</span><span class="st">'template_task'</span>,</span>
<span id="cb50-6"><a href="#cb50-6"></a>    bash_command<span class="op">=</span>templated_command,</span>
<span id="cb50-7"><a href="#cb50-7"></a>    params<span class="op">=</span>{<span class="st">'filename'</span>: <span class="st">'file1.txt'</span>}</span>
<span id="cb50-8"><a href="#cb50-8"></a>    dag<span class="op">=</span>example_dag</span>
<span id="cb50-9"><a href="#cb50-9"></a>)</span>
<span id="cb50-10"><a href="#cb50-10"></a></span>
<span id="cb50-11"><a href="#cb50-11"></a>t2 <span class="op">=</span> BashOperator(</span>
<span id="cb50-12"><a href="#cb50-12"></a>    task_id<span class="op">=</span><span class="st">'template_task'</span>,</span>
<span id="cb50-13"><a href="#cb50-13"></a>    bash_command<span class="op">=</span>templated_command,</span>
<span id="cb50-14"><a href="#cb50-14"></a>    params<span class="op">=</span>{<span class="st">'filename'</span>: <span class="st">'file2.txt'</span>}</span>
<span id="cb50-15"><a href="#cb50-15"></a>    dag<span class="op">=</span>example_dag</span>
<span id="cb50-16"><a href="#cb50-16"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>First, we create our templated command as before. Next, create the first task and pass the params dict with a filename key and the value file1 dot txt. To pass another entry, we can create a second task and modify the params dict accordingly. This time the filename would contain file2 dot txt and Airflow would substitute that value instead. The resulting output would be as expected.</p>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note, you may be wondering what templates do for you here. You’ll see more in the coming exercises and lessons.</p>
</div>
</div>
</div>
</section>
<section id="exercises-11" class="level2">
<h2 class="anchored" data-anchor-id="exercises-11">Exercises</h2>
<section id="exercise-1-creating-a-templated-bashoperator" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1-creating-a-templated-bashoperator">Exercise 1: Creating a templated BashOperator</h3>
<p>You’ve successfully created a BashOperator that cleans a given data file by executing a script called <code>cleandata.sh</code>. This works, but unfortunately requires the script to be run only for the current day. Some of your data sources are occasionally behind by a couple of days and need to be run manually.</p>
<p>You successfully modify the <code>cleandata.sh</code> script to take one argument - the date in YYYYMMDD format. Your testing works at the command-line, but you now need to implement this into your Airflow DAG. For now, use the term <code>{{ ds_nodash }}</code> in your template - you’ll see exactly what this is means later on.</p>
<ul>
<li>Create a templated command to execute the <code>cleandata.sh</code> script with the current execution date given by Airflow. Assign this command to a variable called <code>templated_command</code>.</li>
<li>Modify the BashOperator to use the templated command.</li>
</ul>
<div class="sourceCode" id="cb51"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb51-2"><a href="#cb51-2"></a><span class="im">from</span> airflow.operators.bash_operator <span class="im">import</span> BashOperator</span>
<span id="cb51-3"><a href="#cb51-3"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb51-4"><a href="#cb51-4"></a></span>
<span id="cb51-5"><a href="#cb51-5"></a>default_args <span class="op">=</span> {</span>
<span id="cb51-6"><a href="#cb51-6"></a>  <span class="st">'start_date'</span>: datetime(<span class="dv">2020</span>, <span class="dv">4</span>, <span class="dv">15</span>),</span>
<span id="cb51-7"><a href="#cb51-7"></a>}</span>
<span id="cb51-8"><a href="#cb51-8"></a></span>
<span id="cb51-9"><a href="#cb51-9"></a>cleandata_dag <span class="op">=</span> DAG(</span>
<span id="cb51-10"><a href="#cb51-10"></a>    <span class="st">'cleandata'</span>,</span>
<span id="cb51-11"><a href="#cb51-11"></a>    default_args <span class="op">=</span> default_args,</span>
<span id="cb51-12"><a href="#cb51-12"></a>    schedule_interval <span class="op">=</span> <span class="st">'@daily'</span></span>
<span id="cb51-13"><a href="#cb51-13"></a>)</span>
<span id="cb51-14"><a href="#cb51-14"></a></span>
<span id="cb51-15"><a href="#cb51-15"></a><span class="co"># Create a templated command to execute</span></span>
<span id="cb51-16"><a href="#cb51-16"></a>templated_command <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb51-17"><a href="#cb51-17"></a><span class="st">    bash </span><span class="sc">{{</span><span class="st"> params.filename </span><span class="sc">}}</span><span class="st"> </span><span class="sc">{{</span><span class="st"> ds_nodash </span><span class="sc">}}</span></span>
<span id="cb51-18"><a href="#cb51-18"></a><span class="st">"""</span></span>
<span id="cb51-19"><a href="#cb51-19"></a></span>
<span id="cb51-20"><a href="#cb51-20"></a><span class="co"># Modify clean_task to use the templated command</span></span>
<span id="cb51-21"><a href="#cb51-21"></a>clean_task <span class="op">=</span> BashOperator(</span>
<span id="cb51-22"><a href="#cb51-22"></a>    task_id <span class="op">=</span> <span class="st">'cleandata_task'</span>,</span>
<span id="cb51-23"><a href="#cb51-23"></a>    bash_command <span class="op">=</span> templated_command,</span>
<span id="cb51-24"><a href="#cb51-24"></a>    params <span class="op">=</span> {</span>
<span id="cb51-25"><a href="#cb51-25"></a>        <span class="st">'filename'</span>: <span class="st">'cleandata.sh'</span>, </span>
<span id="cb51-26"><a href="#cb51-26"></a>    },</span>
<span id="cb51-27"><a href="#cb51-27"></a>    dag <span class="op">=</span> cleandata_dag,</span>
<span id="cb51-28"><a href="#cb51-28"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-2-templates-with-multiple-arguments" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-templates-with-multiple-arguments">Exercise 2: Templates with multiple arguments</h3>
<p>You wish to build upon your previous DAG and modify the code to support two arguments - the date in YYYYMMDD format, and a file name passed to the cleandata.sh script.</p>
<ul>
<li>Modify the templated command to handle a second argument called filename.</li>
<li>Change the first BashOperator to pass the filename salesdata.txt to the command.</li>
<li>Add a new BashOperator called clean_task2 to use a second filename supportdata.txt.</li>
<li>Set clean_task2 downstream of clean_task.</li>
</ul>
<div class="sourceCode" id="cb52"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb52-2"><a href="#cb52-2"></a><span class="im">from</span> airflow.operators.bash_operator <span class="im">import</span> BashOperator</span>
<span id="cb52-3"><a href="#cb52-3"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb52-4"><a href="#cb52-4"></a></span>
<span id="cb52-5"><a href="#cb52-5"></a>default_args  <span class="op">=</span>  {</span>
<span id="cb52-6"><a href="#cb52-6"></a>  <span class="st">'start_date'</span>: datetime(<span class="dv">2020</span>, <span class="dv">4</span>, <span class="dv">15</span>),</span>
<span id="cb52-7"><a href="#cb52-7"></a>}</span>
<span id="cb52-8"><a href="#cb52-8"></a></span>
<span id="cb52-9"><a href="#cb52-9"></a>cleandata_dag <span class="op">=</span> DAG(</span>
<span id="cb52-10"><a href="#cb52-10"></a>    <span class="st">'cleandata'</span>,</span>
<span id="cb52-11"><a href="#cb52-11"></a>    default_args <span class="op">=</span> default_args,</span>
<span id="cb52-12"><a href="#cb52-12"></a>    schedule_interval <span class="op">=</span> <span class="st">'@daily'</span>)</span>
<span id="cb52-13"><a href="#cb52-13"></a></span>
<span id="cb52-14"><a href="#cb52-14"></a><span class="co"># Modify the templated command to handle a</span></span>
<span id="cb52-15"><a href="#cb52-15"></a><span class="co"># second argument called filename.</span></span>
<span id="cb52-16"><a href="#cb52-16"></a>templated_command <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb52-17"><a href="#cb52-17"></a><span class="st">  bash cleandata.sh </span><span class="sc">{{</span><span class="st"> ds_nodash </span><span class="sc">}}</span><span class="st"> </span><span class="sc">{{</span><span class="st"> params.filename </span><span class="sc">}}</span></span>
<span id="cb52-18"><a href="#cb52-18"></a><span class="st">"""</span></span>
<span id="cb52-19"><a href="#cb52-19"></a></span>
<span id="cb52-20"><a href="#cb52-20"></a><span class="co"># Modify clean_task to pass the new argument</span></span>
<span id="cb52-21"><a href="#cb52-21"></a>clean_task <span class="op">=</span> BashOperator(</span>
<span id="cb52-22"><a href="#cb52-22"></a>    task_id <span class="op">=</span> <span class="st">'cleandata_task'</span>,                      </span>
<span id="cb52-23"><a href="#cb52-23"></a>    bash_command <span class="op">=</span> templated_command,                         </span>
<span id="cb52-24"><a href="#cb52-24"></a>    params <span class="op">=</span> {</span>
<span id="cb52-25"><a href="#cb52-25"></a>        <span class="st">'filename'</span>: <span class="st">'salesdata.txt'</span>,</span>
<span id="cb52-26"><a href="#cb52-26"></a>    },                      </span>
<span id="cb52-27"><a href="#cb52-27"></a>    dag <span class="op">=</span> cleandata_dag</span>
<span id="cb52-28"><a href="#cb52-28"></a>)</span>
<span id="cb52-29"><a href="#cb52-29"></a></span>
<span id="cb52-30"><a href="#cb52-30"></a><span class="co"># Create a new BashOperator clean_task2</span></span>
<span id="cb52-31"><a href="#cb52-31"></a>clean_task2 <span class="op">=</span> BashOperator(</span>
<span id="cb52-32"><a href="#cb52-32"></a>    task_id <span class="op">=</span> <span class="st">'cleandata_task2'</span>,</span>
<span id="cb52-33"><a href="#cb52-33"></a>    bash_command <span class="op">=</span> templated_command,</span>
<span id="cb52-34"><a href="#cb52-34"></a>    params <span class="op">=</span> {</span>
<span id="cb52-35"><a href="#cb52-35"></a>        <span class="st">'filename'</span>: <span class="st">'supportdata.txt'</span>,</span>
<span id="cb52-36"><a href="#cb52-36"></a>    },</span>
<span id="cb52-37"><a href="#cb52-37"></a>    dag <span class="op">=</span> cleandata_dag,</span>
<span id="cb52-38"><a href="#cb52-38"></a>)</span>
<span id="cb52-39"><a href="#cb52-39"></a>                           </span>
<span id="cb52-40"><a href="#cb52-40"></a><span class="co"># Set the operator dependencies</span></span>
<span id="cb52-41"><a href="#cb52-41"></a>clean_task <span class="op">&gt;&gt;</span> clean_task2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="section-13-more-templates" class="level1">
<h1>Section 13: More Templates</h1>
<p>In our last lesson we were given the task of taking a list of filenames and printing “Reading filename” to the log or output. In our templated version, we created a templated command that substituted the filename value in place of params dot filename. We also used two tasks with different filename values to demonstrate one way to use templates without changing the actual bash command.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1"></a>templated_command <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb53-2"><a href="#cb53-2"></a><span class="st">    echo "Reading </span><span class="sc">{{</span><span class="st"> params.filename </span><span class="sc">}}</span><span class="st">"</span></span>
<span id="cb53-3"><a href="#cb53-3"></a><span class="st">"""</span></span>
<span id="cb53-4"><a href="#cb53-4"></a></span>
<span id="cb53-5"><a href="#cb53-5"></a>t1 <span class="op">=</span> BashOperator(</span>
<span id="cb53-6"><a href="#cb53-6"></a>    task_id <span class="op">=</span> <span class="st">'template_task'</span>,</span>
<span id="cb53-7"><a href="#cb53-7"></a>    bash_command <span class="op">=</span> templated_command,</span>
<span id="cb53-8"><a href="#cb53-8"></a>    params <span class="op">=</span> {</span>
<span id="cb53-9"><a href="#cb53-9"></a>        <span class="st">'filename'</span>: <span class="st">'file1.txt'</span>,</span>
<span id="cb53-10"><a href="#cb53-10"></a>    },</span>
<span id="cb53-11"><a href="#cb53-11"></a>    dag <span class="op">=</span> example_dag,</span>
<span id="cb53-12"><a href="#cb53-12"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Now, let’s consider another way to perform the substitution.</p>
<section id="more-advanced-template" class="level2">
<h2 class="anchored" data-anchor-id="more-advanced-template">More advanced template</h2>
<p>Jinja templates can be considerably more powerful than we’ve used so far. It is possible to use a for construct to allow us to iterate over a list and output content accordingly. Let’s change our templated command to the following. We start with an open curly brace and the percent symbol, then use a normal python command of for filename in params dot filenames then percent close brace. Then we modify our output line to be echo Reading open curly braces filename close curly braces. We then use a Jinja entry to represent the end of the for loop, open curly brace percent endfor percent close curly brace.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1"></a>templated_command<span class="op">=</span><span class="st">"""</span></span>
<span id="cb54-2"><a href="#cb54-2"></a><span class="st">{</span><span class="sc">% f</span><span class="st">or filename in params.filenames %}  </span></span>
<span id="cb54-3"><a href="#cb54-3"></a><span class="st">    echo "Reading </span><span class="sc">{{</span><span class="st"> filename </span><span class="sc">}}</span><span class="st">"</span></span>
<span id="cb54-4"><a href="#cb54-4"></a><span class="st">{</span><span class="sc">% e</span><span class="st">ndfor %}</span></span>
<span id="cb54-5"><a href="#cb54-5"></a><span class="st">"""</span></span>
<span id="cb54-6"><a href="#cb54-6"></a>t1 <span class="op">=</span> BashOperator(</span>
<span id="cb54-7"><a href="#cb54-7"></a>    task_id <span class="op">=</span> <span class="st">'template_task'</span>,</span>
<span id="cb54-8"><a href="#cb54-8"></a>    bash_command <span class="op">=</span> templated_command,</span>
<span id="cb54-9"><a href="#cb54-9"></a>    params <span class="op">=</span> {<span class="st">'filenames'</span>: [<span class="st">'file1.txt'</span>, <span class="st">'file2.txt'</span>]}</span>
<span id="cb54-10"><a href="#cb54-10"></a>    dag <span class="op">=</span> example_dag,</span>
<span id="cb54-11"><a href="#cb54-11"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note that this is required to define the end of the loop, as opposed to Python’s typical whitespace indention. Now let’s look at our BashOperator task. It looks similar except we’ve modified the params key to be filenames, and the value is now a list with two strings, file1 dot txt and file2 dot txt. When Airflow executes the BashOperator, it will iterate over the entries in the filenames list and substitute them in accordingly. Our output is the same as before, with a single task instead of two. Consider too the difference in code if you had 100 files in the list?</p>
</div>
</div>
</div>
</section>
<section id="variables" class="level2">
<h2 class="anchored" data-anchor-id="variables">Variables</h2>
<p>As part of the templating system, Airflow provides a set of built-in runtime variables. These provide assorted information about DAG runs, individual tasks, and even the system configuration.</p>
<table class="table">
<colgroup>
<col style="width: 49%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>&nbsp;Description</th>
<th>What does</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Exe. date: {{ ds }}</td>
<td>YYYY-MM-DD</td>
</tr>
<tr class="even">
<td>Exe. date, no dashes: {{ ds_nodash }}</td>
<td>&nbsp;YYYYMMDD</td>
</tr>
<tr class="odd">
<td>Previous exe. date: {{ prev_ds }}</td>
<td>YYYY-MM-DD</td>
</tr>
<tr class="even">
<td>Previous exe. date, no dashes: {{ prev_ds_nodash }}</td>
<td>YYYYMMDD</td>
</tr>
<tr class="odd">
<td>DAG object: {{ dag }}</td>
<td>DAG(‘example_dag’)</td>
</tr>
<tr class="even">
<td>Airflow configuration: {{ conf }}</td>
<td>{‘core’: {‘task_log_reader’: ’file.task_runner…}}</td>
</tr>
</tbody>
</table>
<p>Template examples include the execution date, which is ds in the double curly brace pairs. It returns the date in a 4 digit year dash 2 digit month dash 2 digit day format. There’s also a ds underscore nodash variety to get the same info without dashes.</p>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note that this is a string, not a python datetime object.</p>
</div>
</div>
</div>
<p>Another variable available is the prev underscore ds, which gives the date of the previous DAG run in the same format as ds. The nodash variety is here as well. You can also access the full DAG object using the dag variable. Or you can use the conf object to access the current Airflow configuration within code. There are many more variables available - you can refer to the documentation for more information<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
<div class="cell" data-execution_count="15">
<div id="airflow_templates_variables" class="cell-output cell-output-display">
<table class="table table-sm table-striped">
<colgroup>
<col style="width: 18%">
<col style="width: 12%">
<col style="width: 69%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Variable</th>
<th style="text-align: left;">Type</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">{{ data_interval_start }}</td>
<td style="text-align: left;">pendulum.DateTime</td>
<td style="text-align: left;">Start of the data interval. Added in version 2.2.</td>
</tr>
<tr class="even">
<td style="text-align: left;">{{ data_interval_end }}</td>
<td style="text-align: left;">pendulum.DateTime</td>
<td style="text-align: left;">End of the data interval. Added in version 2.2.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">{{ ds }}</td>
<td style="text-align: left;">str</td>
<td style="text-align: left;">The DAG run’s logical date as YYYY-MM-DD. Same as {{ dag_run.logical_date</td>
</tr>
<tr class="even">
<td style="text-align: left;">{{ ds_nodash }}</td>
<td style="text-align: left;">str</td>
<td style="text-align: left;">Same as {{ dag_run.logical_date</td>
</tr>
<tr class="odd">
<td style="text-align: left;">{{ ts }}</td>
<td style="text-align: left;">str</td>
<td style="text-align: left;">Same as {{ dag_run.logical_date</td>
</tr>
<tr class="even">
<td style="text-align: left;">{{ ts_nodash_with_tz }}</td>
<td style="text-align: left;">str</td>
<td style="text-align: left;">Same as {{ dag_run.logical_date</td>
</tr>
<tr class="odd">
<td style="text-align: left;">{{ ts_nodash }}</td>
<td style="text-align: left;">str</td>
<td style="text-align: left;">Same as {{ dag_run.logical_date</td>
</tr>
<tr class="even">
<td style="text-align: left;">{{ prev_data_interval_start_success }}</td>
<td style="text-align: left;">pendulum.DateTime</td>
<td style="text-align: left;">None</td>
</tr>
<tr class="odd">
<td style="text-align: left;">{{ prev_data_interval_end_success }}</td>
<td style="text-align: left;">pendulum.DateTime</td>
<td style="text-align: left;">None</td>
</tr>
<tr class="even">
<td style="text-align: left;">{{ prev_start_date_success }}</td>
<td style="text-align: left;">pendulum.DateTime</td>
<td style="text-align: left;">None</td>
</tr>
<tr class="odd">
<td style="text-align: left;">{{ dag }}</td>
<td style="text-align: left;">DAG</td>
<td style="text-align: left;">The currently running DAG. You can read more about DAGs in DAGs.</td>
</tr>
<tr class="even">
<td style="text-align: left;">{{ task }}</td>
<td style="text-align: left;">BaseOperator</td>
<td style="text-align: left;">The currently running BaseOperator. You can read more about Tasks in Operators</td>
</tr>
<tr class="odd">
<td style="text-align: left;">{{ macros }}</td>
<td style="text-align: left;">nan</td>
<td style="text-align: left;">A reference to the macros package. See Macros below.</td>
</tr>
<tr class="even">
<td style="text-align: left;">{{ task_instance }}</td>
<td style="text-align: left;">TaskInstance</td>
<td style="text-align: left;">The currently running TaskInstance.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">{{ ti }}</td>
<td style="text-align: left;">TaskInstance</td>
<td style="text-align: left;">Same as {{ task_instance }}.</td>
</tr>
<tr class="even">
<td style="text-align: left;">{{ params }}</td>
<td style="text-align: left;">dict[str, Any]</td>
<td style="text-align: left;">The user-defined params. This can be overridden by the mapping passed to trigger_dag -c if dag_run_conf_overrides_params is enabled in airflow.cfg.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">{{ var.value }}</td>
<td style="text-align: left;">nan</td>
<td style="text-align: left;">Airflow variables. See Airflow Variables in Templates below.</td>
</tr>
<tr class="even">
<td style="text-align: left;">{{ var.json }}</td>
<td style="text-align: left;">nan</td>
<td style="text-align: left;">Airflow variables. See Airflow Variables in Templates below.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">{{ conn }}</td>
<td style="text-align: left;">nan</td>
<td style="text-align: left;">Airflow connections. See Airflow Connections in Templates below.</td>
</tr>
<tr class="even">
<td style="text-align: left;">{{ task_instance_key_str }}</td>
<td style="text-align: left;">str</td>
<td style="text-align: left;">A unique, human-readable key to the task instance. The format is {dag_id}<strong>{task_id}</strong>{ds_nodash}.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">{{ conf }}</td>
<td style="text-align: left;">AirflowConfigParser</td>
<td style="text-align: left;">The full configuration object representing the content of your airflow.cfg. See airflow.configuration.conf.</td>
</tr>
<tr class="even">
<td style="text-align: left;">{{ run_id }}</td>
<td style="text-align: left;">str</td>
<td style="text-align: left;">The currently running DagRun run ID.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">{{ dag_run }}</td>
<td style="text-align: left;">DagRun</td>
<td style="text-align: left;">The currently running DagRun.</td>
</tr>
<tr class="even">
<td style="text-align: left;">{{ test_mode }}</td>
<td style="text-align: left;">bool</td>
<td style="text-align: left;">Whether the task instance was run by the airflow test CLI.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">{{ expanded_ti_count }}</td>
<td style="text-align: left;">int</td>
<td style="text-align: left;">None</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="macros" class="level2">
<h2 class="anchored" data-anchor-id="macros">Macros</h2>
<p>In addition to the other Airflow variables, there is also a macros variable. The macros package provides a reference to various useful objects or methods for Airflow templates.</p>
<table class="table">
<thead>
<tr class="header">
<th>Macros object</th>
<th>Python object</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>{{ macros.datetime}}</td>
<td>&nbsp;datetime.datetime</td>
</tr>
<tr class="even">
<td>{{ macros.timedelta}}</td>
<td>datetime.timedelta</td>
</tr>
<tr class="odd">
<td>{{ macros.uuid}}</td>
<td>uuid.UUID</td>
</tr>
<tr class="even">
<td>{{ macros.ds_add(ds, days)}}</td>
<td>&nbsp;datetime</td>
</tr>
</tbody>
</table>
<p>Some examples of these include the macros dot datetime, which is the Python datetime dot datetime object. The macros dot timedelta template references the timedelta object. A macros dot uuid is the same as Python’s uuid object. Finally, there are also some added functions available, such as macros dot ds underscore add. It provides an easy way to perform date math within a template. It takes two arguments, a YYYYMMDD datestring and an integer representing the number of days to add (or subtract if the number is negative). Our example here would return April 20, 2020. These are not all the available macros objects - refer to the Airflow documentation for more info.</p>
</section>
<section id="exercises-12" class="level2">
<h2 class="anchored" data-anchor-id="exercises-12">Exercises</h2>
<section id="exercise-1-using-lists-with-templates" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1-using-lists-with-templates">Exercise 1: Using lists with templates</h3>
<p>Once again, you decide to make some modifications to the design of your <code>cleandata</code> workflow. This time, you realize that you need to run the command <code>cleandata.sh</code> with the date argument and the file argument as before, except now you have a list of 30 files. You do not want to create 30 tasks, so your job is to modify the code to support running the argument for 30 or more files.</p>
<p>The Python list of files is already created for you, simply called filelist.</p>
<ul>
<li>Modify the templated command to iterate over a list of filenames.</li>
<li>Pass the filelist to the templated command in the operator.</li>
</ul>
<div class="sourceCode" id="cb55"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb55-2"><a href="#cb55-2"></a><span class="im">from</span> airflow.operators.bash_operator <span class="im">import</span> BashOperator</span>
<span id="cb55-3"><a href="#cb55-3"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb55-4"><a href="#cb55-4"></a></span>
<span id="cb55-5"><a href="#cb55-5"></a>filelist <span class="op">=</span> [<span class="ss">f'file</span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">.txt'</span> <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">30</span>)]</span>
<span id="cb55-6"><a href="#cb55-6"></a></span>
<span id="cb55-7"><a href="#cb55-7"></a>default_args <span class="op">=</span> {</span>
<span id="cb55-8"><a href="#cb55-8"></a>  <span class="st">'start_date'</span>: datetime(<span class="dv">2020</span>, <span class="dv">4</span>, <span class="dv">15</span>),</span>
<span id="cb55-9"><a href="#cb55-9"></a>}</span>
<span id="cb55-10"><a href="#cb55-10"></a></span>
<span id="cb55-11"><a href="#cb55-11"></a>cleandata_dag <span class="op">=</span> DAG(<span class="st">'cleandata'</span>,</span>
<span id="cb55-12"><a href="#cb55-12"></a>                    default_args<span class="op">=</span>default_args,</span>
<span id="cb55-13"><a href="#cb55-13"></a>                    schedule_interval<span class="op">=</span><span class="st">'@daily'</span>)</span>
<span id="cb55-14"><a href="#cb55-14"></a></span>
<span id="cb55-15"><a href="#cb55-15"></a><span class="co"># Modify the template to handle multiple files in a </span></span>
<span id="cb55-16"><a href="#cb55-16"></a><span class="co"># single run.</span></span>
<span id="cb55-17"><a href="#cb55-17"></a>templated_command <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb55-18"><a href="#cb55-18"></a><span class="st">  &lt;</span><span class="sc">% f</span><span class="st">or filename in params.filenames %&gt;</span></span>
<span id="cb55-19"><a href="#cb55-19"></a><span class="st">  bash cleandata.sh </span><span class="sc">{{</span><span class="st"> ds_nodash </span><span class="sc">}}</span><span class="st"> </span><span class="sc">{{</span><span class="st"> filename </span><span class="sc">}}</span><span class="st">;</span></span>
<span id="cb55-20"><a href="#cb55-20"></a><span class="st">  &lt;</span><span class="sc">% e</span><span class="st">ndfor %&gt;</span></span>
<span id="cb55-21"><a href="#cb55-21"></a><span class="st">"""</span></span>
<span id="cb55-22"><a href="#cb55-22"></a></span>
<span id="cb55-23"><a href="#cb55-23"></a><span class="co"># Modify clean_task to use the templated command</span></span>
<span id="cb55-24"><a href="#cb55-24"></a>clean_task <span class="op">=</span> BashOperator(task_id<span class="op">=</span><span class="st">'cleandata_task'</span>,</span>
<span id="cb55-25"><a href="#cb55-25"></a>                          bash_command<span class="op">=</span>templated_command,</span>
<span id="cb55-26"><a href="#cb55-26"></a>                          params<span class="op">=</span>{<span class="st">'filenames'</span>: filelist},</span>
<span id="cb55-27"><a href="#cb55-27"></a>                          dag<span class="op">=</span>cleandata_dag)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-2-understanding-parameter-options" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-understanding-parameter-options">Exercise 2: Understanding parameter options</h3>
<p>You’ve used a few different methods to add templates to your workflows. Considering the differences between options, why would you want to create individual tasks (ie, BashOperators) with specific parameters vs a list of files?</p>
<p>For example, why would you choose</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1"></a>t1 <span class="op">=</span> BashOperator(task_id<span class="op">=</span><span class="st">'task1'</span>, bash_command<span class="op">=</span>templated_command, params<span class="op">=</span>{<span class="st">'filename'</span>: <span class="st">'file1.txt'</span>}, dag<span class="op">=</span>dag)</span>
<span id="cb56-2"><a href="#cb56-2"></a>t2 <span class="op">=</span> BashOperator(task_id<span class="op">=</span><span class="st">'task2'</span>, bash_command<span class="op">=</span>templated_command, params<span class="op">=</span>{<span class="st">'filename'</span>: <span class="st">'file2.txt'</span>}, dag<span class="op">=</span>dag)</span>
<span id="cb56-3"><a href="#cb56-3"></a>t3 <span class="op">=</span> BashOperator(task_id<span class="op">=</span><span class="st">'task3'</span>, bash_command<span class="op">=</span>templated_command, params<span class="op">=</span>{<span class="st">'filename'</span>: <span class="st">'file3.txt'</span>}, dag<span class="op">=</span>dag)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>over using a loop form such as</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1"></a>t1 <span class="op">=</span> BashOperator(</span>
<span id="cb57-2"><a href="#cb57-2"></a>    task_id <span class="op">=</span> <span class="st">'task1'</span>,                   </span>
<span id="cb57-3"><a href="#cb57-3"></a>    bash_command <span class="op">=</span> templated_command,                   </span>
<span id="cb57-4"><a href="#cb57-4"></a>    params <span class="op">=</span> {<span class="st">'filenames'</span>: [<span class="st">'file1.txt'</span>, <span class="st">'file2.txt'</span>, <span class="st">'file3.txt'</span>]},                  </span>
<span id="cb57-5"><a href="#cb57-5"></a>    dag <span class="op">=</span> dag</span>
<span id="cb57-6"><a href="#cb57-6"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Possible Answers</p>
<ul class="task-list">
<li><input type="checkbox" disabled="">Using a loop form is slower.</li>
<li><input type="checkbox" disabled="" checked="">Using specific tasks allows better monitoring of task state and possible parallel execution.</li>
<li><input type="checkbox" disabled="">The params object can only handle lists of a few items.</li>
</ul>
</section>
<section id="exercise-3-sending-templated-emails" class="level3">
<h3 class="anchored" data-anchor-id="exercise-3-sending-templated-emails">Exercise 3: Sending templated emails</h3>
<p>While reading through the Airflow documentation, you realize that various operations can use templated fields to provide added flexibility. You come across the docs for the EmailOperator and see that the content can be set to a template. You want to make use of this functionality to provide more detailed information regarding the output of a DAG run.</p>
<ul>
<li>Create a Python string that represents the email content you wish to send. Use the substitutions for the current date string (with dashes) and a variable called username.</li>
<li>Create the EmailOperator task using the template string for the html_content.</li>
<li>Set the subject field to a macro call using macros.uuid.uuid4(). This simply provides a string of a universally unique identifier as the subject field.</li>
<li>Assign the params dictionary as appropriate with the username of testemailuser.</li>
</ul>
<div class="sourceCode" id="cb58"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb58-2"><a href="#cb58-2"></a><span class="im">from</span> airflow.operators.email_operator <span class="im">import</span> EmailOperator</span>
<span id="cb58-3"><a href="#cb58-3"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb58-4"><a href="#cb58-4"></a></span>
<span id="cb58-5"><a href="#cb58-5"></a><span class="co"># Create the string representing the html email content</span></span>
<span id="cb58-6"><a href="#cb58-6"></a>html_email_str <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb58-7"><a href="#cb58-7"></a><span class="st">Date: </span><span class="sc">{{</span><span class="st"> ds </span><span class="sc">}}</span></span>
<span id="cb58-8"><a href="#cb58-8"></a><span class="st">Username: </span><span class="sc">{{</span><span class="st"> params.username </span><span class="sc">}}</span></span>
<span id="cb58-9"><a href="#cb58-9"></a><span class="st">"""</span></span>
<span id="cb58-10"><a href="#cb58-10"></a></span>
<span id="cb58-11"><a href="#cb58-11"></a>email_dag <span class="op">=</span> DAG(</span>
<span id="cb58-12"><a href="#cb58-12"></a>    <span class="st">'template_email_test'</span>,                </span>
<span id="cb58-13"><a href="#cb58-13"></a>    default_args <span class="op">=</span> {</span>
<span id="cb58-14"><a href="#cb58-14"></a>        <span class="st">'start_date'</span>: datetime(<span class="dv">2020</span>, <span class="dv">4</span>, <span class="dv">15</span>),</span>
<span id="cb58-15"><a href="#cb58-15"></a>    },</span>
<span id="cb58-16"><a href="#cb58-16"></a>    schedule_interval <span class="op">=</span> <span class="st">'@weekly'</span>,</span>
<span id="cb58-17"><a href="#cb58-17"></a>)</span>
<span id="cb58-18"><a href="#cb58-18"></a></span>
<span id="cb58-19"><a href="#cb58-19"></a>email_task <span class="op">=</span> EmailOperator(</span>
<span id="cb58-20"><a href="#cb58-20"></a>    task_id <span class="op">=</span> <span class="st">'email_task'</span>,</span>
<span id="cb58-21"><a href="#cb58-21"></a>    to <span class="op">=</span> <span class="st">'testuser@datacamp.com'</span>,</span>
<span id="cb58-22"><a href="#cb58-22"></a>    subject <span class="op">=</span> <span class="st">"</span><span class="sc">{{</span><span class="st"> macros.uuid.uuid4() </span><span class="sc">}}</span><span class="st">"</span>,</span>
<span id="cb58-23"><a href="#cb58-23"></a>    html_content <span class="op">=</span> html_email_str,</span>
<span id="cb58-24"><a href="#cb58-24"></a>    params <span class="op">=</span> {</span>
<span id="cb58-25"><a href="#cb58-25"></a>        <span class="st">'username'</span>: <span class="st">'testemailuser'</span>,</span>
<span id="cb58-26"><a href="#cb58-26"></a>    },</span>
<span id="cb58-27"><a href="#cb58-27"></a>    dag <span class="op">=</span> email_dag</span>
<span id="cb58-28"><a href="#cb58-28"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="section-14-branching" class="level1">
<h1>Section 14: Branching</h1>
<p>Branching provides the ability for conditional logic within Airflow. Basically, this means that tasks can be selectively executed or skipped depending on the result of an Operator. By default, we’re using the BranchPythonOperator. There are other branching operators available and as with everything else in Airflow, you can write your own if needed. This is however outside the scope of this course.</p>
<p>We import the BranchPythonOperator <code>from airflow.operators.python_operator import BranchPythonOperator</code>. The BranchPythonOperator works by running a function (the python underscore callable as with the normal PythonOperator). The function returns the name (or names) of the task_ids to run. This is best seen with an example.</p>
<section id="branching-example" class="level2">
<h2 class="anchored" data-anchor-id="branching-example">Branching example</h2>
<p>For our branching example, let’s assume we’ve already defined our DAG and imported all the necessary libraries. Our first task is to create the function used with the python_callable for the BranchPythonOperator.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1"></a><span class="kw">def</span> branch_test(<span class="op">**</span>kwargs):</span>
<span id="cb59-2"><a href="#cb59-2"></a>    <span class="cf">if</span> <span class="bu">int</span>(kwargs[<span class="st">'ds_nodash'</span>]) <span class="op">%</span> <span class="dv">2</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb59-3"><a href="#cb59-3"></a>        <span class="cf">return</span> <span class="st">'even_day_task'</span></span>
<span id="cb59-4"><a href="#cb59-4"></a>    <span class="cf">else</span>:</span>
<span id="cb59-5"><a href="#cb59-5"></a>        <span class="cf">return</span> <span class="st">'odd_day_task'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You’ll note that the asterisk asterisk kwargs argument is the only component passed in. Remember that this is a reference to a keyword dictionary passed into the function. In the function we first access the ds underscore nodash key from the kwargs dictionary. If you remember from our previous lesson, this is the template variable used to return the date in YYYYMMDD format. We take this value, convert it to an integer, and then run a check if modulus 2 equals 0. Basically, we’re checking if a number is fully divisible by 2. If so, it’s even, otherwise, it’s odd. As such, we return either even underscore day underscore task, or odd underscore day underscore task.</p>
</section>
<section id="branching-example-1" class="level2">
<h2 class="anchored" data-anchor-id="branching-example-1">Branching example</h2>
<p>The next part of our code creates the BranchPythonOperator. This is like the normal PythonOperator, except we pass in the provide underscore context argument and set it to True. This is the component that tells Airflow to provide access to the runtime variables and macros to the function. This is what gets referenced via the kwargs dictionary object in the function definition.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1"></a>branch_task <span class="op">=</span> BranchPythonOperator(</span>
<span id="cb60-2"><a href="#cb60-2"></a>    task_id <span class="op">=</span> <span class="st">'branch_task'</span>,</span>
<span id="cb60-3"><a href="#cb60-3"></a>    python_callable <span class="op">=</span> branch_test,</span>
<span id="cb60-4"><a href="#cb60-4"></a>    provide_context <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb60-5"><a href="#cb60-5"></a>    dag <span class="op">=</span> dag,</span>
<span id="cb60-6"><a href="#cb60-6"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Now we don’t show the code here, but let’s assume we’ve created two tasks for even days, and two tasks for odd numbered days.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1"></a>task_even <span class="op">=</span> PythonOperator(...)</span>
<span id="cb61-2"><a href="#cb61-2"></a>task_uneven <span class="op">=</span> PythonOperator(...)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Finally, we need to set the dependencies. We want the branch task to run first, then the even day task or the odd day task depending on the result of the branch task. We need to set the dependencies using the bitshift operators.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1"></a>start_task <span class="op">&gt;&gt;</span> branch_task <span class="op">&gt;&gt;</span> even_day_task <span class="op">&gt;&gt;</span> even_day_task2branch_task <span class="op">&gt;&gt;</span> odd_day_task <span class="op">&gt;&gt;</span> odd_day_task2</span>
<span id="cb62-2"><a href="#cb62-2"></a>branch_task <span class="op">&gt;&gt;</span> odd_day_task <span class="op">&gt;&gt;</span> odd_day_task2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>First, we configure the dependency order for start task, branch task, then even day task and even day task2. Now we need to set the dependency order for the odd day tasks. As we’ve already defined the dependency for the start and branch tasks, we can set odd day task to follow the branch task, and the odd day task2 to follow that. You may be wondering why you’d set these dependencies if one set is not going to run. If you didn’t set these dependencies, all the tasks would run as normal, regardless of what the branch operator returned.</p>
</section>
<section id="branching-graph-view" class="level2">
<h2 class="anchored" data-anchor-id="branching-graph-view">Branching graph view</h2>
<p>Let’s look at the DAG in the graph view of the Airflow UI.</p>
<p><img src="../imgs/chapter4/0X93.png" class="img-fluid"></p>
<p>You’ll notice that we have a start task upstream of the branch task. The branch task then shows two paths, one to the odd day tasks, and the other to the even day tasks.</p>
</section>
<section id="branching-even-days" class="level2">
<h2 class="anchored" data-anchor-id="branching-even-days">Branching even days</h2>
<p>Let’s look first at what happens if we run on an even numbered day.</p>
<p><img src="../imgs/chapter4/0X99.png" class="img-fluid"></p>
<p>The start task executes as normal, then the branch task checks the ds_nodash value and determines this is an even day. It returns the value even underscore day underscore task, which is then executed by Airflow followed by the even day task2.</p>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>Note that the odd day tasks are marked in light pink, which refers to them being skipped.</p>
</div>
</div>
</div>
</section>
<section id="branching-odd-days" class="level2">
<h2 class="anchored" data-anchor-id="branching-odd-days">Branching odd days</h2>
<p>For completeness, let’s look at the output from a run on an odd day.</p>
<p><img src="../imgs/chapter4/0X105.png" class="img-fluid"></p>
<p>The process is the same, except that the branch task selects odd day task instead and the even branch is marked skipped.</p>
</section>
<section id="exercises-13" class="level2">
<h2 class="anchored" data-anchor-id="exercises-13">Exercises</h2>
<section id="exercise-1-define-a-branchpythonoperator" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1-define-a-branchpythonoperator">Exercise 1: Define a BranchPythonOperator</h3>
<p>After learning about the power of conditional logic within Airflow, you wish to test out the BranchPythonOperator. You’d like to run a different code path if the current execution date represents a new year (ie, 2020 vs 2019).</p>
<p>The DAG is defined for you, along with the tasks in question. Your current task is to implement the BranchPythonOperator.</p>
<ul>
<li>In the function year_check, configure the code to determine if the year of the current execution date is different than the previous execution date (ie, is the year different between the appropriate Airflow template variables.)</li>
<li>Finish the BranchPythonOperator by adding the appropriate arguments.</li>
<li>Set the dependencies on current_year_task and new_year_task.</li>
</ul>
<div class="sourceCode" id="cb63"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1"></a><span class="co"># Create a function to determine if years are different</span></span>
<span id="cb63-2"><a href="#cb63-2"></a><span class="kw">def</span> year_check(<span class="op">**</span>kwargs):</span>
<span id="cb63-3"><a href="#cb63-3"></a>    current_year <span class="op">=</span> <span class="bu">int</span>(kwargs[<span class="st">'ds_nodash'</span>][<span class="dv">0</span>:<span class="dv">4</span>])</span>
<span id="cb63-4"><a href="#cb63-4"></a>    previous_year <span class="op">=</span> <span class="bu">int</span>(kwargs[<span class="st">'prev_ds_nodash'</span>][<span class="dv">0</span>:<span class="dv">4</span>])</span>
<span id="cb63-5"><a href="#cb63-5"></a>    <span class="cf">if</span> current_year <span class="op">==</span> previous_year:</span>
<span id="cb63-6"><a href="#cb63-6"></a>        <span class="cf">return</span> <span class="st">'current_year_task'</span></span>
<span id="cb63-7"><a href="#cb63-7"></a>    <span class="cf">else</span>:</span>
<span id="cb63-8"><a href="#cb63-8"></a>        <span class="cf">return</span> <span class="st">'new_year_task'</span></span>
<span id="cb63-9"><a href="#cb63-9"></a></span>
<span id="cb63-10"><a href="#cb63-10"></a><span class="co"># Define the BranchPythonOperator</span></span>
<span id="cb63-11"><a href="#cb63-11"></a>branch_task <span class="op">=</span> BranchPythonOperator(task_id<span class="op">=</span><span class="st">'branch_task'</span>, dag<span class="op">=</span>branch_dag,</span>
<span id="cb63-12"><a href="#cb63-12"></a>                                   python_callable<span class="op">=</span>year_check, provide_context<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb63-13"><a href="#cb63-13"></a><span class="co"># Define the dependencies</span></span>
<span id="cb63-14"><a href="#cb63-14"></a>branch_dag <span class="op">&gt;&gt;</span> current_year_task</span>
<span id="cb63-15"><a href="#cb63-15"></a>branch_dag <span class="op">&gt;&gt;</span> new_year_task</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-2-branch-troubleshooting" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-branch-troubleshooting">Exercise 2: Branch troubleshooting</h3>
<p>While working with a workflow defined by a colleague, you notice that a branching operator executes, but there’s never any change in the DAG results. You realize that regardless of the state defined by the branching operator, all other tasks complete, even as some should be skipped.</p>
<p>Use what you’ve learned to determine the most likely reason that the branching operator is ineffective.</p>
<ul class="task-list">
<li><input type="checkbox" disabled="">The <code>branch_test</code> method does not return the correct value.</li>
<li><input type="checkbox" disabled="">The DAG does not run often enough for the callable to work properly.</li>
<li><input type="checkbox" disabled="" checked="">The dependency is missing between the <code>branch_task</code> and <code>even_day_task</code> and <code>odd_day_task</code>.</li>
</ul>
<p><img src="../imgs/chapter4/Exercise_14_2.png" class="img-fluid"></p>
</section>
</section>
</section>
<section id="section-15-creating-a-production-pipeline" class="level1">
<h1>Section 15: Creating a production pipeline</h1>
<section id="running-dags-tasks" class="level2">
<h2 class="anchored" data-anchor-id="running-dags-tasks">Running DAGs &amp; Tasks</h2>
<p>You may remember way back in chapter 1, we discussed how to run a task. If not, here’s a quick reminder - use airflow run dag id task id and execution date from the command line.</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb64-1"><a href="#cb64-1"></a><span class="ex">airflow</span> run <span class="op">&lt;</span>dag_id<span class="op">&gt;</span> <span class="op">&lt;</span>task_id<span class="op">&gt;</span> <span class="op">&lt;</span>execution_date<span class="op">&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This will execute a specific DAG task as though it were running on the date specified.</p>
<p>To run a full DAG, you can use the airflow trigger underscore dag dash e then the execution date and dag_id.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb65-1"><a href="#cb65-1"></a><span class="ex">airflow</span> trigger_dag <span class="at">-e</span> <span class="op">&lt;</span>execution_date<span class="op">&gt;</span> <span class="op">&lt;</span>dag_id<span class="op">&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This executes the full DAG as though it were running on the specified date.</p>
</section>
<section id="operators-reminder" class="level2">
<h2 class="anchored" data-anchor-id="operators-reminder">Operators reminder</h2>
<p>We’ve been working with operators and sensors through most of this course, but let’s take a quick look at some of the most common ones we’ve used.</p>
<ul>
<li>The BashOperator behaves like most operators, but expects a <code>bash_command</code> parameter which is a string of the command to be run.</li>
<li>The PythonOperator requires a <code>python_callable</code> argument with the name of the Python function to execute.
<ul>
<li>The BranchPythonOperator is similar to the PythonOperator, but the <code>python_callable</code> must be a function that accepts a <code>**kwargs</code> entry. As such, the <code>provide_context = True</code> attribute must be set to true.</li>
</ul></li>
<li>The FileSensor requires a <code>filepath</code> argument of a string, and might need mode or <code>poke_interval</code> attributes.</li>
</ul>
<p>You can refer to previous chapters for further detail if required.</p>
</section>
<section id="template-reminders" class="level2">
<h2 class="anchored" data-anchor-id="template-reminders">Template reminders</h2>
<p>A quick reminder is that many objects in Airflow can use templates. Only certain fields can accept templated strings while others do not. It can be tricky to remember which ones support templates on what fields. One way to check is to use the built-in python documentation via a live python interpreter. To use this method, open a python3 interpreter at the command line.</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb66-1"><a href="#cb66-1"></a><span class="ex">python</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Import any necessary libraries (ie, the BashOperator) At the prompt, run help with the name of the Airflow object as the lone argument.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1"></a><span class="im">from</span> airflow.operators.bash <span class="im">import</span> BashOperator</span>
<span id="cb67-2"><a href="#cb67-2"></a></span>
<span id="cb67-3"><a href="#cb67-3"></a><span class="bu">help</span>(BashOperator)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Look for a line referencing template underscore fields. This line will specify if and which fields can use templated strings.</p>
</section>
<section id="template-documentation-example" class="level2">
<h2 class="anchored" data-anchor-id="template-documentation-example">Template documentation example</h2>
<p>This is an example of checking for help in the python interpreter. Notice the output with the template fields entry - in this case, the bash underscore command and the env fields can accept templated values.</p>
<p><img src="../imgs/chapter4/1X139.png" class="img-fluid"></p>
<div class="callout-caution callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container" data-apperance="simple">
<p>A final note before working through our last exercises - as a data engineer, your job is not to necessarily understand every component of a workflow. You may not fully understand all of a machine learning process, or perhaps how an Apache Spark job works. Your task is to implement any of those tasks in a repeatable and reliable fashion. Let’s practice implementing workflows for the last time in this course now.</p>
</div>
</div>
</div>
</section>
<section id="exercises-14" class="level2">
<h2 class="anchored" data-anchor-id="exercises-14">Exercises</h2>
<section id="exercise-1-creating-a-production-pipeline-1" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1-creating-a-production-pipeline-1">Exercise 1: Creating a production pipeline #1</h3>
<p>You’ve learned a lot about how Airflow works - now it’s time to implement your workflow into a production pipeline consisting of many objects including sensors and operators. Your boss is interested in seeing this workflow become automated and able to provide SLA reporting as it provides some extra leverage for closing a deal the sales staff is working on. The sales prospect has indicated that once they see updates in an automated fashion, they’re willing to sign-up for the indicated data service.</p>
<p>From what you’ve learned about the process, you know that there is sales data that will be uploaded to the system. Once the data is uploaded, a new file should be created to kick off the full processing, but something isn’t working correctly.</p>
<p>Refer to the source code of the DAG to determine if anything extra needs to be added.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb68-2"><a href="#cb68-2"></a><span class="im">from</span> airflow.contrib.sensors.file_sensor <span class="im">import</span> FileSensor</span>
<span id="cb68-3"><a href="#cb68-3"></a></span>
<span id="cb68-4"><a href="#cb68-4"></a><span class="co"># Import the needed operators</span></span>
<span id="cb68-5"><a href="#cb68-5"></a><span class="im">from</span> airflow.operators.____ <span class="im">import</span> ____</span>
<span id="cb68-6"><a href="#cb68-6"></a>____</span>
<span id="cb68-7"><a href="#cb68-7"></a><span class="im">from</span> datetime <span class="im">import</span> date, datetime</span>
<span id="cb68-8"><a href="#cb68-8"></a></span>
<span id="cb68-9"><a href="#cb68-9"></a><span class="kw">def</span> process_data(<span class="op">**</span>context):</span>
<span id="cb68-10"><a href="#cb68-10"></a>  <span class="bu">file</span> <span class="op">=</span> <span class="bu">open</span>(<span class="st">'/home/repl/workspace/processed_data.tmp'</span>, <span class="st">'w'</span>)</span>
<span id="cb68-11"><a href="#cb68-11"></a>  <span class="bu">file</span>.write(<span class="ss">f'Data processed on </span><span class="sc">{</span>date<span class="sc">.</span>today()<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb68-12"><a href="#cb68-12"></a>  <span class="bu">file</span>.close()</span>
<span id="cb68-13"><a href="#cb68-13"></a></span>
<span id="cb68-14"><a href="#cb68-14"></a>    </span>
<span id="cb68-15"><a href="#cb68-15"></a>dag <span class="op">=</span> DAG(dag_id<span class="op">=</span><span class="st">'etl_update'</span>, default_args<span class="op">=</span>{<span class="st">'start_date'</span>: datetime(<span class="dv">2020</span>,<span class="dv">4</span>,<span class="dv">1</span>)})</span>
<span id="cb68-16"><a href="#cb68-16"></a></span>
<span id="cb68-17"><a href="#cb68-17"></a>sensor <span class="op">=</span> FileSensor(task_id<span class="op">=</span><span class="st">'sense_file'</span>, </span>
<span id="cb68-18"><a href="#cb68-18"></a>                    filepath<span class="op">=</span><span class="st">'/home/repl/workspace/startprocess.txt'</span>,</span>
<span id="cb68-19"><a href="#cb68-19"></a>                    poke_interval<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb68-20"><a href="#cb68-20"></a>                    timeout<span class="op">=</span><span class="dv">15</span>,</span>
<span id="cb68-21"><a href="#cb68-21"></a>                    dag<span class="op">=</span>dag)</span>
<span id="cb68-22"><a href="#cb68-22"></a></span>
<span id="cb68-23"><a href="#cb68-23"></a>bash_task <span class="op">=</span> BashOperator(task_id<span class="op">=</span><span class="st">'cleanup_tempfiles'</span>, </span>
<span id="cb68-24"><a href="#cb68-24"></a>                         bash_command<span class="op">=</span><span class="st">'rm -f /home/repl/*.tmp'</span>,</span>
<span id="cb68-25"><a href="#cb68-25"></a>                         dag<span class="op">=</span>dag)</span>
<span id="cb68-26"><a href="#cb68-26"></a></span>
<span id="cb68-27"><a href="#cb68-27"></a>python_task <span class="op">=</span> PythonOperator(task_id<span class="op">=</span><span class="st">'run_processing'</span>, </span>
<span id="cb68-28"><a href="#cb68-28"></a>                             python_callable<span class="op">=</span>process_data,</span>
<span id="cb68-29"><a href="#cb68-29"></a>                             dag<span class="op">=</span>dag)</span>
<span id="cb68-30"><a href="#cb68-30"></a></span>
<span id="cb68-31"><a href="#cb68-31"></a>sensor <span class="op">&gt;&gt;</span> bash_task <span class="op">&gt;&gt;</span> python_task</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Update the DAG in pipeline.py to import the needed operators.</li>
</ul>
<p>Solution</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb69-2"><a href="#cb69-2"></a><span class="im">from</span> airflow.contrib.sensors.file_sensor <span class="im">import</span> FileSensor</span>
<span id="cb69-3"><a href="#cb69-3"></a><span class="im">from</span> airflow.operators.bash_operator <span class="im">import</span> BashOperator</span>
<span id="cb69-4"><a href="#cb69-4"></a><span class="im">from</span> airflow.operators.python_operator <span class="im">import</span> PythonOperator</span>
<span id="cb69-5"><a href="#cb69-5"></a><span class="im">from</span> dags.process <span class="im">import</span> process_data</span>
<span id="cb69-6"><a href="#cb69-6"></a><span class="im">from</span> datetime <span class="im">import</span> timedelta, datetime</span>
<span id="cb69-7"><a href="#cb69-7"></a></span>
<span id="cb69-8"><a href="#cb69-8"></a><span class="co"># Update the default arguments and apply them to the DAG</span></span>
<span id="cb69-9"><a href="#cb69-9"></a>default_args <span class="op">=</span> {</span>
<span id="cb69-10"><a href="#cb69-10"></a>  <span class="st">'start_date'</span>: datetime(<span class="dv">2019</span>,<span class="dv">1</span>,<span class="dv">1</span>),</span>
<span id="cb69-11"><a href="#cb69-11"></a>  <span class="st">'sla'</span>: timedelta(minutes<span class="op">=</span><span class="dv">90</span>),</span>
<span id="cb69-12"><a href="#cb69-12"></a>}</span>
<span id="cb69-13"><a href="#cb69-13"></a></span>
<span id="cb69-14"><a href="#cb69-14"></a>dag <span class="op">=</span> DAG(</span>
<span id="cb69-15"><a href="#cb69-15"></a>    dag_id <span class="op">=</span> <span class="st">'etl_update'</span>, </span>
<span id="cb69-16"><a href="#cb69-16"></a>    default_args <span class="op">=</span> default_args, </span>
<span id="cb69-17"><a href="#cb69-17"></a>)</span>
<span id="cb69-18"><a href="#cb69-18"></a></span>
<span id="cb69-19"><a href="#cb69-19"></a>sensor <span class="op">=</span> FileSensor(</span>
<span id="cb69-20"><a href="#cb69-20"></a>    task_id <span class="op">=</span> <span class="st">'sense_file'</span>, </span>
<span id="cb69-21"><a href="#cb69-21"></a>    filepath <span class="op">=</span> <span class="st">'/home/repl/workspace/startprocess.txt'</span>,</span>
<span id="cb69-22"><a href="#cb69-22"></a>    poke_interval <span class="op">=</span> <span class="dv">45</span>,</span>
<span id="cb69-23"><a href="#cb69-23"></a>    dag <span class="op">=</span> dag</span>
<span id="cb69-24"><a href="#cb69-24"></a>)</span>
<span id="cb69-25"><a href="#cb69-25"></a></span>
<span id="cb69-26"><a href="#cb69-26"></a>bash_task <span class="op">=</span> BashOperator(</span>
<span id="cb69-27"><a href="#cb69-27"></a>    task_id <span class="op">=</span> <span class="st">'cleanup_tempfiles'</span>, </span>
<span id="cb69-28"><a href="#cb69-28"></a>    bash_command <span class="op">=</span> <span class="st">'rm -f /home/repl/*.tmp'</span>,</span>
<span id="cb69-29"><a href="#cb69-29"></a>    dag <span class="op">=</span> dag</span>
<span id="cb69-30"><a href="#cb69-30"></a>)</span>
<span id="cb69-31"><a href="#cb69-31"></a></span>
<span id="cb69-32"><a href="#cb69-32"></a>python_task <span class="op">=</span> PythonOperator(</span>
<span id="cb69-33"><a href="#cb69-33"></a>    task_id <span class="op">=</span> <span class="st">'run_processing'</span>, </span>
<span id="cb69-34"><a href="#cb69-34"></a>    python_callable <span class="op">=</span> process_data,</span>
<span id="cb69-35"><a href="#cb69-35"></a>    provide_context <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb69-36"><a href="#cb69-36"></a>    dag <span class="op">=</span> dag,</span>
<span id="cb69-37"><a href="#cb69-37"></a>)</span>
<span id="cb69-38"><a href="#cb69-38"></a></span>
<span id="cb69-39"><a href="#cb69-39"></a>sensor <span class="op">&gt;&gt;</span> bash_task <span class="op">&gt;&gt;</span> python_task</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Run the <code>sense_file</code> task from the command line and look for any errors. Use the command <code>airflow test</code> and the appropriate arguments to run the command. For the last argument, use a <code>-1</code> instead of a specific date.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../imgs/chapter4/Exercise_15_1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">The file is not found and timeout is triggered after 15 seconds. we have first to create the file</figcaption><p></p>
</figure>
</div>
<ul>
<li>Determine why the sense_file task does not complete and remedy this using the editor.</li>
<li>Re-test the sense_file task and verify the problem is fixed.</li>
</ul>
</section>
<section id="exercise-2-creating-a-production-pipeline-2" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-creating-a-production-pipeline-2">Exercise 2: Creating a production pipeline #2</h3>
<p>Continuing on your last workflow, you’d like to add some additional functionality, specifically adding some SLAs to the code and modifying the sensor components.</p>
<p>Refer to the source code of the DAG to determine if anything extra needs to be added. The default_args dictionary has been defined for you, though it may require further modification.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb70-2"><a href="#cb70-2"></a><span class="im">from</span> airflow.contrib.sensors.file_sensor <span class="im">import</span> FileSensor</span>
<span id="cb70-3"><a href="#cb70-3"></a><span class="im">from</span> airflow.operators.bash_operator <span class="im">import</span> BashOperator</span>
<span id="cb70-4"><a href="#cb70-4"></a><span class="im">from</span> airflow.operators.python_operator <span class="im">import</span> PythonOperator</span>
<span id="cb70-5"><a href="#cb70-5"></a><span class="im">from</span> dags.process <span class="im">import</span> process_data</span>
<span id="cb70-6"><a href="#cb70-6"></a><span class="im">from</span> datetime <span class="im">import</span> timedelta, datetime</span>
<span id="cb70-7"><a href="#cb70-7"></a></span>
<span id="cb70-8"><a href="#cb70-8"></a><span class="co"># Update the default arguments and apply them to the DAG</span></span>
<span id="cb70-9"><a href="#cb70-9"></a>default_args <span class="op">=</span> {</span>
<span id="cb70-10"><a href="#cb70-10"></a>  <span class="st">'start_date'</span>: datetime(<span class="dv">2019</span>,<span class="dv">1</span>,<span class="dv">1</span>),</span>
<span id="cb70-11"><a href="#cb70-11"></a>  ____</span>
<span id="cb70-12"><a href="#cb70-12"></a>}</span>
<span id="cb70-13"><a href="#cb70-13"></a></span>
<span id="cb70-14"><a href="#cb70-14"></a>dag <span class="op">=</span> DAG(dag_id<span class="op">=</span><span class="st">'etl_update'</span>, default_args<span class="op">=</span>default_args)</span>
<span id="cb70-15"><a href="#cb70-15"></a></span>
<span id="cb70-16"><a href="#cb70-16"></a>sensor <span class="op">=</span> FileSensor(task_id<span class="op">=</span><span class="st">'sense_file'</span>, </span>
<span id="cb70-17"><a href="#cb70-17"></a>                    filepath<span class="op">=</span><span class="st">'/home/repl/workspace/startprocess.txt'</span>,</span>
<span id="cb70-18"><a href="#cb70-18"></a>                    ____,</span>
<span id="cb70-19"><a href="#cb70-19"></a>                    dag<span class="op">=</span>dag)</span>
<span id="cb70-20"><a href="#cb70-20"></a></span>
<span id="cb70-21"><a href="#cb70-21"></a>bash_task <span class="op">=</span> BashOperator(task_id<span class="op">=</span><span class="st">'cleanup_tempfiles'</span>, </span>
<span id="cb70-22"><a href="#cb70-22"></a>                         bash_command<span class="op">=</span><span class="st">'rm -f /home/repl/*.tmp'</span>,</span>
<span id="cb70-23"><a href="#cb70-23"></a>                         dag<span class="op">=</span>dag)</span>
<span id="cb70-24"><a href="#cb70-24"></a></span>
<span id="cb70-25"><a href="#cb70-25"></a>python_task <span class="op">=</span> PythonOperator(task_id<span class="op">=</span><span class="st">'run_processing'</span>, </span>
<span id="cb70-26"><a href="#cb70-26"></a>                             python_callable<span class="op">=</span>process_data,</span>
<span id="cb70-27"><a href="#cb70-27"></a>                             ____</span>
<span id="cb70-28"><a href="#cb70-28"></a>                             dag<span class="op">=</span>dag)</span>
<span id="cb70-29"><a href="#cb70-29"></a></span>
<span id="cb70-30"><a href="#cb70-30"></a>sensor <span class="op">&gt;&gt;</span> bash_task <span class="op">&gt;&gt;</span> python_task</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Add an SLA of 90 minutes to the DAG.</li>
<li>Update the FileSensor object to check for files every 45 seconds.</li>
<li>Modify the python_task to send Airflow variables to the callable. Note that the callable is configured to accept the variables using the provide_context argument.</li>
</ul>
<div class="sourceCode" id="cb71"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb71-2"><a href="#cb71-2"></a><span class="im">from</span> airflow.contrib.sensors.file_sensor <span class="im">import</span> FileSensor</span>
<span id="cb71-3"><a href="#cb71-3"></a><span class="im">from</span> airflow.operators.bash_operator <span class="im">import</span> BashOperator</span>
<span id="cb71-4"><a href="#cb71-4"></a><span class="im">from</span> airflow.operators.python_operator <span class="im">import</span> PythonOperator</span>
<span id="cb71-5"><a href="#cb71-5"></a><span class="im">from</span> dags.process <span class="im">import</span> process_data</span>
<span id="cb71-6"><a href="#cb71-6"></a><span class="im">from</span> datetime <span class="im">import</span> timedelta, datetime</span>
<span id="cb71-7"><a href="#cb71-7"></a></span>
<span id="cb71-8"><a href="#cb71-8"></a><span class="co"># Update the default arguments and apply them to the DAG</span></span>
<span id="cb71-9"><a href="#cb71-9"></a>default_args <span class="op">=</span> {</span>
<span id="cb71-10"><a href="#cb71-10"></a>  <span class="st">'start_date'</span>: datetime(<span class="dv">2019</span>,<span class="dv">1</span>,<span class="dv">1</span>),</span>
<span id="cb71-11"><a href="#cb71-11"></a>  <span class="st">'sla'</span>: timedelta(minutes<span class="op">=</span><span class="dv">90</span>),</span>
<span id="cb71-12"><a href="#cb71-12"></a>}</span>
<span id="cb71-13"><a href="#cb71-13"></a></span>
<span id="cb71-14"><a href="#cb71-14"></a>dag <span class="op">=</span> DAG(</span>
<span id="cb71-15"><a href="#cb71-15"></a>    dag_id<span class="op">=</span><span class="st">'etl_update'</span>, </span>
<span id="cb71-16"><a href="#cb71-16"></a>    default_args<span class="op">=</span>default_args, </span>
<span id="cb71-17"><a href="#cb71-17"></a>)</span>
<span id="cb71-18"><a href="#cb71-18"></a></span>
<span id="cb71-19"><a href="#cb71-19"></a>sensor <span class="op">=</span> FileSensor(</span>
<span id="cb71-20"><a href="#cb71-20"></a>    task_id<span class="op">=</span><span class="st">'sense_file'</span>, </span>
<span id="cb71-21"><a href="#cb71-21"></a>    filepath<span class="op">=</span><span class="st">'/home/repl/workspace/startprocess.txt'</span>,</span>
<span id="cb71-22"><a href="#cb71-22"></a>    poke_interval<span class="op">=</span><span class="dv">45</span>,</span>
<span id="cb71-23"><a href="#cb71-23"></a>    dag<span class="op">=</span>dag</span>
<span id="cb71-24"><a href="#cb71-24"></a>)</span>
<span id="cb71-25"><a href="#cb71-25"></a></span>
<span id="cb71-26"><a href="#cb71-26"></a>bash_task <span class="op">=</span> BashOperator(</span>
<span id="cb71-27"><a href="#cb71-27"></a>    task_id<span class="op">=</span><span class="st">'cleanup_tempfiles'</span>, </span>
<span id="cb71-28"><a href="#cb71-28"></a>    bash_command<span class="op">=</span><span class="st">'rm -f /home/repl/*.tmp'</span>,</span>
<span id="cb71-29"><a href="#cb71-29"></a>    dag<span class="op">=</span>dag</span>
<span id="cb71-30"><a href="#cb71-30"></a>)</span>
<span id="cb71-31"><a href="#cb71-31"></a></span>
<span id="cb71-32"><a href="#cb71-32"></a>python_task <span class="op">=</span> PythonOperator(</span>
<span id="cb71-33"><a href="#cb71-33"></a>    task_id<span class="op">=</span><span class="st">'run_processing'</span>, </span>
<span id="cb71-34"><a href="#cb71-34"></a>    python_callable<span class="op">=</span>process_data,</span>
<span id="cb71-35"><a href="#cb71-35"></a>    provide_context <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb71-36"><a href="#cb71-36"></a>    dag<span class="op">=</span>dag</span>
<span id="cb71-37"><a href="#cb71-37"></a>)</span>
<span id="cb71-38"><a href="#cb71-38"></a></span>
<span id="cb71-39"><a href="#cb71-39"></a>sensor <span class="op">&gt;&gt;</span> bash_task <span class="op">&gt;&gt;</span> python_task</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-3-adding-the-final-changes-to-your-pipeline" class="level3">
<h3 class="anchored" data-anchor-id="exercise-3-adding-the-final-changes-to-your-pipeline">Exercise 3: Adding the final changes to your pipeline</h3>
<p>To finish up your workflow, your manager asks that you add a conditional logic check to send a sales report via email, only if the day is a weekday. Otherwise, no email should be sent. In addition, the email task should be templated to include the date and a project name in the content.</p>
<p>The branch callable is already defined for you.</p>
<ul>
<li>Import the necessary operators.</li>
<li>Configure the EmailOperator to provide the specific data to the callable.</li>
<li>Complete the branch callable as necessary to point to the email_report_task or no_email_task.</li>
<li>Configure the branch operator to properly check for the condition.</li>
</ul>
<div class="sourceCode" id="cb72"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1"></a><span class="im">from</span> airflow.models <span class="im">import</span> DAG</span>
<span id="cb72-2"><a href="#cb72-2"></a><span class="im">from</span> airflow.contrib.sensors.file_sensor <span class="im">import</span> FileSensor</span>
<span id="cb72-3"><a href="#cb72-3"></a><span class="im">from</span> airflow.operators.bash_operator <span class="im">import</span> BashOperator</span>
<span id="cb72-4"><a href="#cb72-4"></a><span class="im">from</span> airflow.operators.python_operator <span class="im">import</span> PythonOperator</span>
<span id="cb72-5"><a href="#cb72-5"></a><span class="im">from</span> airflow.operators.python_operator <span class="im">import</span> BranchPythonOperator</span>
<span id="cb72-6"><a href="#cb72-6"></a><span class="im">from</span> airflow.operators.dummy_operator <span class="im">import</span> DummyOperator</span>
<span id="cb72-7"><a href="#cb72-7"></a><span class="im">from</span> airflow.operators.email_operator <span class="im">import</span> EmailOperator</span>
<span id="cb72-8"><a href="#cb72-8"></a><span class="im">from</span> dags.process <span class="im">import</span> process_data</span>
<span id="cb72-9"><a href="#cb72-9"></a><span class="im">from</span> datetime <span class="im">import</span> datetime, timedelta</span>
<span id="cb72-10"><a href="#cb72-10"></a></span>
<span id="cb72-11"><a href="#cb72-11"></a><span class="co"># Update the default arguments and apply them to the DAG.</span></span>
<span id="cb72-12"><a href="#cb72-12"></a></span>
<span id="cb72-13"><a href="#cb72-13"></a>default_args <span class="op">=</span> {</span>
<span id="cb72-14"><a href="#cb72-14"></a>  <span class="st">'start_date'</span>: datetime(<span class="dv">2019</span>,<span class="dv">1</span>,<span class="dv">1</span>),</span>
<span id="cb72-15"><a href="#cb72-15"></a>  <span class="st">'sla'</span>: timedelta(minutes<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb72-16"><a href="#cb72-16"></a>}</span>
<span id="cb72-17"><a href="#cb72-17"></a>    </span>
<span id="cb72-18"><a href="#cb72-18"></a>dag <span class="op">=</span> DAG(dag_id<span class="op">=</span><span class="st">'etl_update'</span>, default_args<span class="op">=</span>default_args)</span>
<span id="cb72-19"><a href="#cb72-19"></a></span>
<span id="cb72-20"><a href="#cb72-20"></a>sensor <span class="op">=</span> FileSensor(</span>
<span id="cb72-21"><a href="#cb72-21"></a>  task_id<span class="op">=</span><span class="st">'sense_file'</span>, </span>
<span id="cb72-22"><a href="#cb72-22"></a>  filepath<span class="op">=</span><span class="st">'/home/repl/workspace/startprocess.txt'</span>,</span>
<span id="cb72-23"><a href="#cb72-23"></a>  poke_interval<span class="op">=</span><span class="dv">45</span>,</span>
<span id="cb72-24"><a href="#cb72-24"></a>  dag<span class="op">=</span>dag</span>
<span id="cb72-25"><a href="#cb72-25"></a>)</span>
<span id="cb72-26"><a href="#cb72-26"></a></span>
<span id="cb72-27"><a href="#cb72-27"></a>bash_task <span class="op">=</span> BashOperator(</span>
<span id="cb72-28"><a href="#cb72-28"></a>  task_id<span class="op">=</span><span class="st">'cleanup_tempfiles'</span>, </span>
<span id="cb72-29"><a href="#cb72-29"></a>  bash_command<span class="op">=</span><span class="st">'rm -f /home/repl/*.tmp'</span>,</span>
<span id="cb72-30"><a href="#cb72-30"></a>  dag<span class="op">=</span>dag</span>
<span id="cb72-31"><a href="#cb72-31"></a>)</span>
<span id="cb72-32"><a href="#cb72-32"></a></span>
<span id="cb72-33"><a href="#cb72-33"></a>python_task <span class="op">=</span> PythonOperator(</span>
<span id="cb72-34"><a href="#cb72-34"></a>  task_id<span class="op">=</span><span class="st">'run_processing'</span>, </span>
<span id="cb72-35"><a href="#cb72-35"></a>  python_callable<span class="op">=</span>process_data,</span>
<span id="cb72-36"><a href="#cb72-36"></a>  provide_context<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb72-37"><a href="#cb72-37"></a>  dag<span class="op">=</span>dag</span>
<span id="cb72-38"><a href="#cb72-38"></a>)</span>
<span id="cb72-39"><a href="#cb72-39"></a></span>
<span id="cb72-40"><a href="#cb72-40"></a></span>
<span id="cb72-41"><a href="#cb72-41"></a>email_subject<span class="op">=</span><span class="st">"""</span></span>
<span id="cb72-42"><a href="#cb72-42"></a><span class="st">  Email report for </span><span class="sc">{{</span><span class="st"> params.department </span><span class="sc">}}</span><span class="st"> on </span><span class="sc">{{</span><span class="st"> ds_nodash </span><span class="sc">}}</span></span>
<span id="cb72-43"><a href="#cb72-43"></a><span class="st">"""</span></span>
<span id="cb72-44"><a href="#cb72-44"></a></span>
<span id="cb72-45"><a href="#cb72-45"></a></span>
<span id="cb72-46"><a href="#cb72-46"></a>email_report_task <span class="op">=</span> EmailOperator(</span>
<span id="cb72-47"><a href="#cb72-47"></a>  task_id<span class="op">=</span><span class="st">'email_report_task'</span>,</span>
<span id="cb72-48"><a href="#cb72-48"></a>  to<span class="op">=</span><span class="st">'sales@mycompany.com'</span>,</span>
<span id="cb72-49"><a href="#cb72-49"></a>  subject<span class="op">=</span>email_subject,</span>
<span id="cb72-50"><a href="#cb72-50"></a>  html_content<span class="op">=</span><span class="st">''</span>,</span>
<span id="cb72-51"><a href="#cb72-51"></a>  params<span class="op">=</span>{<span class="st">'department'</span>: <span class="st">'Data subscription services'</span>},</span>
<span id="cb72-52"><a href="#cb72-52"></a>  dag<span class="op">=</span>dag</span>
<span id="cb72-53"><a href="#cb72-53"></a>)</span>
<span id="cb72-54"><a href="#cb72-54"></a></span>
<span id="cb72-55"><a href="#cb72-55"></a></span>
<span id="cb72-56"><a href="#cb72-56"></a>no_email_task <span class="op">=</span> DummyOperator(task_id<span class="op">=</span><span class="st">'no_email_task'</span>, dag<span class="op">=</span>dag)</span>
<span id="cb72-57"><a href="#cb72-57"></a></span>
<span id="cb72-58"><a href="#cb72-58"></a></span>
<span id="cb72-59"><a href="#cb72-59"></a><span class="kw">def</span> check_weekend(<span class="op">**</span>kwargs):</span>
<span id="cb72-60"><a href="#cb72-60"></a>    dt <span class="op">=</span> datetime.strptime(kwargs[<span class="st">'execution_date'</span>],<span class="st">"%Y-%m-</span><span class="sc">%d</span><span class="st">"</span>)</span>
<span id="cb72-61"><a href="#cb72-61"></a>    <span class="co"># If dt.weekday() is 0-4, it's Monday - Friday. If 5 or 6, it's Sat / Sun.</span></span>
<span id="cb72-62"><a href="#cb72-62"></a>    <span class="cf">if</span> (dt.weekday() <span class="op">&lt;</span> <span class="dv">5</span>):</span>
<span id="cb72-63"><a href="#cb72-63"></a>        <span class="cf">return</span> <span class="st">'email_report_task'</span></span>
<span id="cb72-64"><a href="#cb72-64"></a>    <span class="cf">else</span>:</span>
<span id="cb72-65"><a href="#cb72-65"></a>        <span class="cf">return</span> <span class="st">'no_email_task'</span></span>
<span id="cb72-66"><a href="#cb72-66"></a>    </span>
<span id="cb72-67"><a href="#cb72-67"></a>    </span>
<span id="cb72-68"><a href="#cb72-68"></a>branch_task <span class="op">=</span> BranchPythonOperator(</span>
<span id="cb72-69"><a href="#cb72-69"></a>  task_id<span class="op">=</span><span class="st">'check_if_weekend'</span>,</span>
<span id="cb72-70"><a href="#cb72-70"></a>  python_callable <span class="op">=</span> check_weekend,</span>
<span id="cb72-71"><a href="#cb72-71"></a>  provide_context<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb72-72"><a href="#cb72-72"></a>  dag<span class="op">=</span>dag</span>
<span id="cb72-73"><a href="#cb72-73"></a>)</span>
<span id="cb72-74"><a href="#cb72-74"></a>    </span>
<span id="cb72-75"><a href="#cb72-75"></a>sensor <span class="op">&gt;&gt;</span> bash_task <span class="op">&gt;&gt;</span> python_task</span>
<span id="cb72-76"><a href="#cb72-76"></a></span>
<span id="cb72-77"><a href="#cb72-77"></a>python_task <span class="op">&gt;&gt;</span> branch_task <span class="op">&gt;&gt;</span> [email_report_task, no_email_task]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="congratulations" class="level1">
<h1>Congratulations!</h1>
<p>Congratulations on successfully completing this introduction to Airflow. We’ve covered a lot of ground since the first chapter and you should be pleased to have come this far. Let’s take a moment to review what we’ve learned and cover some next steps.</p>
<section id="what-weve-learned" class="level2">
<h2 class="anchored" data-anchor-id="what-weve-learned">What we’ve learned</h2>
<p>Let’s review everything we’ve worked with during this course. We started with learning about workflows and DAGs in Airflow. We’ve learned what an operator is and how to use several of the available ones. We learned about tasks and how they are defined by various types of operators. In addition, we learned about dependencies between tasks and how to set them with bitshift operators. We’ve used sensors to react to workflow conditions and state. We’ve scheduled DAGs in various ways. We used SLAs and alerting to maintain visibility on our workflows. We learned about the power of templating in our workflows for maximum flexibility when defining tasks. We’ve learned how to use branching to add conditional logic to our DAGs. Finally, we’ve learned about the Airflow interfaces (command line and UI), about Airflow executors, and a bit about how to debug and troubleshoot various issues with Airflow and our own workflows.</p>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next steps</h2>
<p>A few suggestions for next steps include setting up your own environment for practice. You can follow the installation instructions in the Airflow documentation or use a cloud-based Airflow service. Look into other operators or sensors - there are operators available for Amazon’s S3, Postgresql operators, HDFS sensors, and so forth. Experiment with dependencies with a large number of tasks. Consider how you expect the workflow to progress and always try to leave as much up to the scheduler as possible to achieve the best performance. Given the length of the course, there is only so much we could cover and we left out some important parts of Airflow such as XCom, connections, and managing the UI further. Refer to the documentation for more ideas. Finally and most importantly, keep building workflows. When you’re uncertain how something works, try to build an example that covers what you’d like to accomplish. Look at the views within the Airflow UI to better understand how the system interprets your DAG code. The more you experiment, the better your understanding will grow.</p>
</section>
<section id="thank-you" class="level2">
<h2 class="anchored" data-anchor-id="thank-you">Thank you!</h2>
<p>Finally, thank you for taking this course and giving me the opportunity to introduce you to Airflow. Good luck on your future learning opportunities!</p>


</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>https://en.m.wikipedia.org/wiki/Directed_acyclic_graph<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>https://airflow.apache.org/docs/stable/scheduler.html<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>https://bradymholt.github.io/cron-expression-descriptor/<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>https://airflow.apache.org/docs/stable/macros-ref.html<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
    var links = window.document.querySelectorAll('a:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center"><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
  </div>
</footer>



</body></html>